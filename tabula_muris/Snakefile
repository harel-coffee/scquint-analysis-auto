import anndata
from Bio.Seq import Seq
from collections import Counter, defaultdict
import csv
import itertools
import numpy as np
import os
import pandas as pd
import re
import scanpy as sc
import scipy.sparse as sp_sparse
from scipy.stats import chi2_contingency, spearmanr
from shutil import copyfile
from sklearn.decomposition import PCA, NMF
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, f1_score, roc_auc_score
from sklearn.model_selection import train_test_split
from statsmodels.stats.multitest import multipletests
import umap.umap_ as umap
UMAP = umap.UMAP
from textwrap import wrap
import matplotlib
import matplotlib.pyplot as plt
import seaborn as sns

from scquint.differential_splicing import run_differential_splicing
from scquint.dimensionality_reduction import run_pca
from scquint.utils import (filter_min_cells_per_cluster,
                            filter_min_cells_per_feature, filter_singletons,
                            group_normalize, relabel,
                            run_differential_expression)

matplotlib.use('pdf')
#sns.set_palette("muted")
sns.set(style="white")

configfile: 'config.yaml'


# TODO: this should go into an independent prepare_metadata.py script
# obs_file = "GSM4505405_tabula-muris-senis-facs-official-raw-obj-metadata.csv"
# obs = pd.read_csv(obs_file, ",", index_col=0)
# if np.isin('3m', obs.age.values):
#     obs.loc[obs.age=='3m', 'my_id'] = obs[obs.age=='3m'].index.str.split('.').str[:2].str.join('_')
# if np.isin('18m', obs.age.values):
#     obs.loc[obs.age=='18m', 'my_id'] = (obs[obs.age=='18m'].index.str.split('_').str[:2].str.join('_'))
# if np.isin('21m', obs.age.values):
#     obs.loc[obs.age=='21m', 'my_id'] = (obs[obs.age=='21m'].index.str.split('_').str[:2].str.join('_'))
# if np.isin('24m', obs.age.values):
#     obs.loc[obs.age=='24m', 'my_id'] = (obs[obs.age=='24m'].index.str.split('_').str[:3]
#                                        .str.join('.').str.split('.').str[:2].str.join('_'))
#obs = obs.set_index("my_id")

genome_fasta_path = config["genome_fasta_path"]
full_gtf_path = config["gtf_path"]
chrom_sizes_path = config["chrom_sizes_path"]
encode_blacklist_path = config["encode_blacklist_path"]
sjdb_path = config["sjdb_path"]  # maybe should be created in this workflow
groupings = ["nontransitive", "transitive", "gene"]

sample_info = pd.read_csv("obs.txt.gz", "\t", index_col=0)
sample_ids = sample_info.index.values
print("len(sample_ids): ", len(sample_ids))
sample_info.loc[:, "cell_type"] = sample_info.cell_ontology_class.str.replace(" ", "_").str.replace("-", "_")
sample_info["plate_id"] = sample_info.index.str.split("_").str[1]

#sample_ids_subset = sorted(sample_info[(sample_info.tissue=="Mammary_Gland")&(sample_info["mouse.id"]=="3_56_F")].index.values)
#sample_ids_subset = sorted(sample_info[(sample_info.tissue=="Mammary_Gland")&(sample_info["mouse.id"]=="3_38_F")].index.values)
sample_ids_subset = sorted(sample_info[sample_info.tissue=="Mammary_Gland"].index.values)
print("len(sample_ids_subset): ", len(sample_ids_subset))

# zcat GSE109774_list_of_SRR_accessions_and_raw_filenames.txt.gz | cut -f 2,3 | cut -d "-" -f 1-2 | sed 's/-/_/g' > srr_cell_pairs.txt
sample_srr = pd.read_csv("srr_cell_pairs.txt", '\t', header=None, names=['srr', 'cell'])
sample_srr = sample_srr[sample_srr.cell.isin(sample_ids)]

#genes_bam_merge = {
#    "Foxp1": {
#        "region": ["chr6", 98888459, 99713014],
#        "cell_types": ["late_pro_B_cell", "precursor_B_cell", "immature_B_cell", "naive_B_cell"],
#    },
#}


quantifications_mg_individual = ["gene-expression", "kallisto", "bins-nmf", "introns-shared-acceptor"]

motif1 = "AAGCAGTGGTATCAACGCAGAGT"
motif2 = "ACTTTTTTTTTTTTTTTTTTTTTTTTTTTTTT"
motif3 = "AAGCAGTGGTATCAACGCAGAGTACGGG"
motif1_rc = str(Seq(motif1).reverse_complement())
motif2_rc = str(Seq(motif2).reverse_complement())
motif3_rc = str(Seq(motif3).reverse_complement())

sample_info["cell_type"] = sample_info.cell_ontology_class.str.replace(" ", "_").str.replace("-", "_")

tissues = sample_info.tissue.unique()
cell_types = sample_info.cell_type.unique()
tissue_cell_type_pairs = []
tissue_cell_type_pairs_including_singletons = []
for tissue in tissues:
    tissue_cell_type_counts = sample_info[sample_info.tissue==tissue].cell_type.value_counts()
    tissue_cell_types = [ct for ct in sample_info[sample_info.tissue==tissue].cell_type.unique()
                         if tissue_cell_type_counts[ct] >= 100]
    tissue_cell_type_pairs_including_singletons += [[tissue, cell_type]
                                                    for cell_type in tissue_cell_types]
    if len(tissue_cell_types) < 2:
        continue
    tissue_cell_type_pairs += [[tissue, cell_type]
                               for cell_type in tissue_cell_types]
print(len(tissue_cell_type_pairs), len(tissue_cell_type_pairs_including_singletons))


flatten = lambda l: [item for sublist in l for item in sublist]



labels = ["cell_ontology_class", "mouse.id", "sex", "plate_id", "tissue"]


introns_to_plot = [
    "chr6:99260420-99266347",
]

genes_to_plot = [
    "ENSMUSG00000030067",
]


cell_type_order = ["(1) pro-B", "(2) pre-B", "(3) immature B", "(4) naive B"]


rule all:
    input:
        "output/adata_cellxgene.h5ad",
        expand("output/coverage_track/tct/{tct[0]}/{tct[1]}/coverage.bw", tct=tissue_cell_type_pairs_including_singletons),
        "output/differential_splicing/tissue_cell_type/Marrow/merged_significant_all.svg",
        #'output/differential_splicing/tissue_cell_type/marker_introns.svg',
        "output/dimensionality_reduction/marrow/classification_score.svg",
        expand("output/plots/{gene}.svg", gene=genes_to_plot),
        expand("output/plots/{intron}.svg", intron=introns_to_plot),
        expand("output/differential_splicing/tissue_cell_type/{tct[0]}/{tct[1]}/splicing.significant.tsv", tct=tissue_cell_type_pairs),
        expand("output/comparison/marrow_b/{label}.svg", label=labels),
        "output/comparison/mg_3_38_F/cell_ontology_class.svg",
        expand("output/differential_splicing/tissue_cell_type/{tissue}/merged_significant_all.svg", tissue=pd.unique([t for t, ct in tissue_cell_type_pairs])),
        expand("output/coverage_track/mg_basal_individual_plate/3_38_F/{plate}/coverage.bw", plate=["B002433", "B002432", "B002438"]),
        expand(
            'output/differential_splicing/mg_basal_individual_plate/{individual}/{quantification}/splicing.clusters.csv',
            individual=["3_38_F"],
            quantification=["gene-expression"],
        )
        "output/coverage_track/mg_basal_individual_plate/3_56_F/B000167/coverage.bw",
        "output/coverage_track/mg_basal_individual_plate/3_56_F/B000166/coverage.bw",
        expand("output/bam_regions/Foxp1/{cell_type}/merged.bam", cell_type=genes_bam_merge["Foxp1"]["cell_types"]),


rule download:
    output: temp('output/srr/{srr}.sra')
    priority: 100
    shell: """
    prefetch -o {output} {wildcards.srr}
    """


rule fastq_dump:
    input:
        'output/srr/{srr}.sra'
    output:
        temp('output/srr/{srr}_1.fastq.gz'),
        temp('output/srr/{srr}_2.fastq.gz')
    shell: """
    cd output/srr && (fastq-dump --gzip --split-files {wildcards.srr}.sra || rm {wildcards.srr}.sra)
    """


def get_input_merge_fastq(wildcards):
    return expand('output/srr/{{sra}}_{number}.fastq.gz'.format(number=wildcards.number),
                  sra=sample_srr.srr[sample_srr.cell==wildcards.sample_id].values)


rule merge_fastq:
   input: get_input_merge_fastq
   output: temp('output/fastq_raw/{sample_id}_{number}.fastq.gz')
   shell: 'cat {input} > {output}'


rule trim_adapters:
    input:
        "output/fastq_raw/{sample_id}_1.fastq.gz",
        "output/fastq_raw/{sample_id}_2.fastq.gz",
    output:
        "output/fastq/{sample_id}_R1.fastq.gz",
        "output/fastq/{sample_id}_R2.fastq.gz",
    shell:
        "cutadapt -g {motif1} -g {motif2} -g {motif3} -a {motif1_rc} -a {motif2_rc} -a {motif3_rc} -G {motif1} -G {motif2} -G {motif3} -A {motif1_rc} -A {motif2_rc} -A {motif3_rc} -m30 -n 4 -o {output[0]} -p {output[1]} {input[0]} {input[1]}"


rule make_fastq_paths:
    input:
        expand("output/fastq/{sample_id}_R{pair}.fastq.gz", sample_id=sample_ids, pair=[1, 2]),
    output:
        "output/fastq_paths.txt"
    run:
        df = pd.DataFrame(sample_ids, columns=["sample_id"])
        base_path = os.path.join(os.getcwd(), "output/fastq/")
        df["fastq_1"] = base_path + df.sample_id + "_R1.fastq.gz"
        df["fastq_2"] = base_path + df.sample_id + "_R2.fastq.gz"
        df.to_csv(output[0], "\t", index=False, header=False)


rule read_mapping:
    input:
        "output/fastq_paths.txt",
        full_gtf_path
    threads: workflow.cores
    priority: 100
    output:
        expand("output/mapping/mapping_second_pass/{sample_id}/Aligned.rmdup.out.bam", sample_id=sample_ids)
    shell:
        "python -m scquint.quantification.run read_mapping/Snakefile --cores {threads} -d output/mapping/ --config min_cells_per_intron=30 fastq_paths=../fastq_paths.txt fasta_path={genome_fasta_path} gtf_path={full_gtf_path} sjdb_overhang=99"


rule make_fastq_paths_subset:
    input:
        expand("output/fastq/{sample_id}_R1.fastq.gz", sample_id=sample_ids_subset),
    output:
        "output/fastq_paths_subset.txt"
    run:
        df = pd.DataFrame(sample_ids_subset, columns=["sample_id"])
        base_path = os.path.join(os.getcwd(), "output/fastq/")
        df["fastq_1"] = base_path + df.sample_id + "_R1.fastq.gz"
        df["fastq_2"] = base_path + df.sample_id + "_R2.fastq.gz"
        df.to_csv(output[0], "\t", index=False, header=False)


rule kallisto_quantification:
    input:
        "output/fastq_paths_subset.txt",
        full_gtf_path,
    output:
        "output/quantification/kallisto/adata.h5ad"
    threads: workflow.cores
    shell:
        "python -m scquint.quantification.run kallisto/Snakefile --cores {threads} -d output/quantification/kallisto/ --config fastq_paths=../../fastq_paths_subset.txt genome_fasta_path={genome_fasta_path} gtf_path={full_gtf_path} min_cells_per_isoform=30"


rule bins_quantification:
    input:
        "output/bam_paths_subset.txt",
        full_gtf_path,
    threads: workflow.cores
    output:
        "output/quantification/bins/adata.h5ad"
    shell:
        "python -m scquint.quantification.run bins/Snakefile --cores all -d output/quantification/bins/ --config min_cells_per_bin=100 gtf_path={full_gtf_path} bam_paths=../../bam_paths_subset.txt"


rule transform_adata_with_NMF:
    input:
        "output/quantification/bins/adata_annotated.h5ad"
    output:
        "output/quantification/bins-nmf/adata_annotated.h5ad"
    run:
        original_adata = anndata.read_h5ad(input[0])
        cluster_gene_id_map = original_adata.var.groupby("cluster").gene_id.first()
        clusters = []
        gene_ids = []
        Xs = []
        n_clusters = len(pd.unique(original_adata.var.cluster))
        print("n_clusters: ", n_clusters)
        new_cluster = 0
        for cluster in pd.unique(original_adata.var.cluster):
            print(cluster)
            gene_id = cluster_gene_id_map.loc[cluster]
            idx_features = np.where(original_adata.var.cluster==cluster)[0]
            X = original_adata.X[:, idx_features].toarray()
            for n_components in [2, 5, 10]:
                X_NMF = NMF(n_components=n_components, max_iter=10000, solver="mu", beta_loss="frobenius").fit_transform(X)
                n_cells, n_features = X_NMF.shape
                Xs.append(X_NMF)
                clusters.append(np.full(n_features, new_cluster))
                new_cluster += 1
                gene_ids.append(np.full(n_features, gene_id))
        X = np.hstack(Xs)
        clusters = np.concatenate(clusters)
        gene_ids = np.concatenate(gene_ids)
        var = pd.DataFrame(dict(cluster=clusters,gene_id=gene_ids))
        print(var)
        adata = anndata.AnnData(X=X, var=var, obs=original_adata.obs)
        print(adata.shape)
        print("new n_clusters: ", adata.var.cluster.unique().shape)
        adata.write(output[0])


rule process_encode_blacklist:
    input:
        encode_blacklist_path
    output:
        "output/encode_blacklist.bed"
    shell:
        "set +o pipefail; cut -f1-3 {input} | bedtools sort -i stdin | uniq > {output}"


rule filter_bam:
    input:
        "output/mapping/mapping_second_pass/{sample_id}/Aligned.rmdup.out.bam",
        "output/encode_blacklist.bed"
    output:
        protected("output/mapping/filtered_bams/{sample_id}.bam"),
    shell:
        "bedtools intersect -split -sorted -a {input[0]} -b {input[1]} -v > {output}"


rule make_bam_paths:
    input:
        expand("output/mapping/filtered_bams/{sample_id}.bam", sample_id=sample_ids),
    output:
        "output/bam_paths.txt",
    run:
        cwd = os.getcwd()
        pd.DataFrame(dict(
            sample_id=sample_ids,
            bam_path=[f"{cwd}/output/mapping/filtered_bams/{sample_id}.bam"
                      for sample_id in sample_ids])
        ).to_csv(output[0], "\t", index=False, header=False)


rule make_bam_paths_subset:
    input:
        expand("output/mapping/filtered_bams/{sample_id}.bam", sample_id=sample_ids_subset),
    output:
        "output/bam_paths_subset.txt",
    run:
        cwd = os.getcwd()
        pd.DataFrame(dict(
            sample_id=sample_ids_subset,
            bam_path=[f"{cwd}/output/mapping/filtered_bams/{sample_id}.bam"
                      for sample_id in sample_ids_subset])
        ).to_csv(output[0], "\t", index=False, header=False)


rule prepare_chromosomes_file:
    input:
        full_gtf_path
    output:
        "output/chromosomes.txt"
    shell:
        "cut -f1 {input} | grep -v \# | grep -v GL | grep -v JH | sort | uniq > {output}"


rule add_metadata:
    input:
        "output/quantification/{quantification}/adata.h5ad",
    output:
        "output/quantification/{quantification,gene-expression|exons|bins|kallisto|introns-gene|introns-shared-acceptor|introns-nontransitive|introns-transitive}/adata_annotated.h5ad",
    run:
        adata = anndata.read_h5ad(input[0])
        print(adata.obs)
        adata.obs = sample_info.loc[adata.obs.index.values]
        print(adata.obs)
        adata.write(output[0], compression="gzip")


rule make_bam_paths_plate:
    input:
        expand("output/mapping/filtered_bams/{sample_id}.bam", sample_id=sample_ids)
    output:
        "output/bam_paths_{plate}.txt",
    run:
        s_ids = sample_ids[np.where(sample_info.plate_id==wildcards["plate"])[0]]
        print(wildcards["plate"], len(s_ids))
        cwd = os.getcwd()
        pd.DataFrame(dict(sample_id=s_ids, bam_path=[f"{cwd}/output/mapping/filtered_bams/{sample_id}.bam" for sample_id in s_ids])).to_csv(output[0], "\t", index=False, header=False)


rule make_coverage_track_bigwig_plate:
    input:
        "output/bam_paths_{plate}.txt",
    output:
        "output/coverage_track/plate/{plate}/coverage.bw",
    threads: workflow.cores // 4
    shell:
        "python -m scquint.quantification.run coverage_track/Snakefile --cores {threads} -d output/coverage_track/plate/{wildcards.plate}/ --config bam_paths=../../../bam_paths_{wildcards.plate}.txt chrom_sizes_path={chrom_sizes_path}"


rule intron_quantification:
    input:
        "output/bam_paths.txt",
        "output/chromosomes.txt",
        full_gtf_path,
        sjdb_path,
        chrom_sizes_path
    threads: workflow.cores
    output:
        "output/quantification/introns/output/introns-shared-acceptor/adata.h5ad",
    shell:
        "python -m scquint.quantification.run introns/Snakefile -q --cores {threads} -d output/quantification/introns/ --config min_cells_per_intron=100 bam_paths=../../bam_paths.txt chromosomes_path=../../chromosomes.txt fasta_path={genome_fasta_path} gtf_path={full_gtf_path} chrom_sizes_path={chrom_sizes_path} sjdb_path={sjdb_path}"


rule extract_intron_quantification:
    input:
        "output/quantification/introns/output/introns-{grouping}/adata.h5ad"
    output:
        "output/quantification/introns-{grouping}/adata.h5ad"
    shell:
        "cp {input} {output}"


rule gene_expression_quantification:
    input:
        "output/bam_paths.txt",
        full_gtf_path,
    threads: workflow.cores
    output:
        "output/quantification/gene-expression/adata.h5ad"
    shell:
        "python -m scquint.quantification.run genes/Snakefile --cores all -q -d output/quantification/gene-expression/ --config min_cells_per_gene=100 gtf_path={full_gtf_path} bam_paths=../../bam_paths.txt"


rule differential_test_mg_basal_individual_plate:
    input:
        "output/quantification/{quantification}/adata_annotated.h5ad",
    output:
        'output/differential_splicing/mg_basal_individual_plate/{individual}/{quantification}/splicing.clusters.csv',
        'output/differential_splicing/mg_basal_individual_plate/{individual}/{quantification}/splicing.introns.csv',
    run:
        print("threads: ", threads)
        obs = sample_info[
            (sample_info.tissue=="Mammary_Gland") &
            (sample_info.cell_ontology_class=="basal cell") &
            (sample_info["mouse.id"]==wildcards["individual"])
        ].sort_index()
        adata = anndata.read_h5ad(input[0])
        adata = adata[obs.index.values]
        plates = obs.plate_id.unique()
        print(plates)
        #assert(len(plates)==2)
        #cell_idx_a = np.where(
        #    (obs.plate_id==plates[0])
        #)[0]
        #cell_idx_b = np.where(
        #    (obs.plate_id!=plates[0])
        #)[0]
        print("hardcoding B002438")
        cell_idx_a = np.where(
            (obs.plate_id=="B002438")
        )[0]
        cell_idx_b = np.where(
            (obs.plate_id!="B002438")
        )[0]

        permute = False
        if permute:
            cell_idx_all = np.concatenate([cell_idx_a, cell_idx_b])
            cell_idx_all_p = np.random.permutation(cell_idx_all)
            cell_idx_a_p = cell_idx_all_p[:len(cell_idx_a)]
            cell_idx_b_p = cell_idx_all_p[len(cell_idx_a):]
            cell_idx_a = cell_idx_a_p
            cell_idx_b = cell_idx_b_p

        if wildcards["quantification"] != "gene-expression":
            adata.var["original_cluster"] = adata.var.cluster
            diff_spl_clusters, diff_spl_introns = run_differential_splicing(
                adata,
                "permutation-Euclidean",
                cell_idx_a,
                cell_idx_b,
                min_cells_per_cluster=30 if wildcards["quantification"] != "bins-nmf" else None,
                min_total_cells_per_intron=30 if wildcards["quantification"] != "bins-nmf" else None,
                device="cuda:0",
                #device="cpu",
                n_permutations=100000,
               )
            diff_spl_clusters.to_csv(output[0], '\t')
            diff_spl_introns.to_csv(output[1], '\t')
        else:
            diff_exp = run_differential_expression(adata, cell_idx_a, cell_idx_b, 30)
            diff_exp.to_csv(output[0], '\t', index=False)
            diff_exp.to_csv(output[1], '\t', index=False)


rule make_bam_paths_mg_basal_individual_plate:
    input:
        "output/bam_paths.txt",
    output:
        "output/bam_paths/mg_basal_individual_{individual}_{plate}.txt",
    run:
        s_ids = sample_ids[
            np.where(
                (sample_info.tissue=="Mammary_Gland") &
                (sample_info.cell_ontology_class=="basal cell") &
                (sample_info["mouse.id"]==wildcards["individual"]) &
                (sample_info.plate_id==wildcards["plate"])
            )[0]
        ]
        print(wildcards["plate"], len(s_ids))
        cwd = os.getcwd()
        pd.DataFrame(dict(sample_id=s_ids, bam_path=[f"{cwd}/output/mapping/filtered_bams/{sample_id}.bam" for sample_id in s_ids])).to_csv(output[0], "\t", index=False, header=False)


rule make_coverage_track_bigwig_mg_basal_individual_plate:
    input:
        "output/bam_paths/mg_basal_individual_{individual}_{plate}.txt",
    output:
        "output/coverage_track/mg_basal_individual_plate/{individual}/{plate}/coverage.bw",
    threads: workflow.cores // 4
    shell:
        "python -m scquint.quantification.run coverage_track/Snakefile --cores {threads} -d output/coverage_track/mg_basal_individual_plate/{wildcards.individual}/{wildcards.plate}/ --config bam_paths=../../../../bam_paths/mg_basal_individual_{wildcards.individual}_{wildcards.plate}.txt chrom_sizes_path={chrom_sizes_path}"


rule dimensionality_reduction_mg_pca:
    input:
        "output/quantification/{quantification}/adata_annotated.h5ad",
    output:
        "output/dimensionality_reduction/mg/{quantification}/pca/latent.txt",
    wildcard_constraints: quantification='.+(?<!gene-expression)'
    run:
        adata = anndata.read_h5ad(input[0])
        adata = adata[(adata.obs.tissue=="Mammary_Gland")]
        sorted_index = sorted(adata.obs.index)
        adata = adata[sorted_index]
        if wildcards["quantification"] != "bins-nmf":
            adata = filter_min_cells_per_feature(adata, 100)
        latent = run_pca(adata, 20)
        np.savetxt(output[0], latent)


rule dimensionality_reduction_mg_expression:
    input:
        "output/quantification/gene-expression/adata_annotated.h5ad",
    output:
        "output/dimensionality_reduction/mg/gene-expression/pca/latent.txt",
    run:
        adata = anndata.read_h5ad(input[0])
        adata = adata[(adata.obs.tissue=="Mammary_Gland")]
        sorted_index = sorted(adata.obs.index)
        adata = adata[sorted_index]
        sc.pp.filter_genes(adata, min_cells=100)
        sc.pp.normalize_total(adata, target_sum=1e4)
        sc.pp.log1p(adata)
        X = adata.X.toarray()
        latent = PCA(n_components=20).fit_transform(X)
        np.savetxt(output[0], latent)


rule filter_bam_to_region:
    input:
        "output/mapping/filtered_bams/{sample_id}.bam"
    output:
        "output/bam_regions/{gene}/{sample_id}.bam"
    run:
        chromosome, start, end = genes_bam_merge[wildcards["gene"]]["region"]
        shell(f"bamtools filter -region {chromosome}:{start}..{end} -in {input} -out {output}")


rule make_bam_paths_gene:
    input:
        lambda wildcards: expand(f"output/bam_regions/{wildcards['gene']}/{{sample_id}}.bam", sample_id=sample_ids[(sample_info.tissue=="Marrow") & (sample_info.cell_type==wildcards["cell_type"])])
    output:
        "output/bam_paths-{gene}-{cell_type}.txt"
    run:
        pd.DataFrame(input).to_csv(output[0], "\t", index=False, header=False)


rule merge_bams:
    input:
        "output/bam_paths-{gene}-{cell_type}.txt"
    output:
        "output/bam_regions/{gene}/{cell_type}/merged.bam"
    threads:
        workflow.cores
    priority: 10
    shell:
        "samtools merge --threads {threads} -b {input} {output}"


rule differential_test_tissue_cell_type:
    input:
        "output/quantification/gene-expression/adata_annotated.h5ad",
        "output/quantification/introns-shared-acceptor/adata_annotated.h5ad",
    output:
        'output/differential_splicing/tissue_cell_type/{tissue}/{cell_type}/expression.csv',
        'output/differential_splicing/tissue_cell_type/{tissue}/{cell_type}/splicing.clusters.csv',
        'output/differential_splicing/tissue_cell_type/{tissue}/{cell_type}/splicing.introns.csv',
    threads: workflow.cores // 4
    run:
        adata_exp = anndata.read_h5ad(input[0])
        adata_exp.obs.index = adata_exp.obs.index.astype(str)
        adata_spl = anndata.read_h5ad(input[1])
        adata_spl.obs.index = adata_spl.obs.index.astype(str)
        adata_spl.var.index = adata_spl.var.index.astype(str)
        assert((adata_exp.obs.index == adata_spl.obs.index).all())
        obs = adata_exp.obs
        obs.loc[:, "cell_type"] = obs.cell_ontology_class.str.replace(" ", "_").str.replace("-", "_")
        cell_idx_a = np.where((obs.tissue==wildcards["tissue"]) &
                              (obs.cell_type==wildcards["cell_type"]))[0]
        cell_idx_b = np.where((obs.tissue==wildcards["tissue"]) &
                              (obs.cell_type!=wildcards["cell_type"]) &
                              (obs.cell_type.isin([ct for t, ct in tissue_cell_type_pairs if t==wildcards["tissue"]])))[0]
        MIN_FEATURES = 50
        diff_exp = run_differential_expression(adata_exp, cell_idx_a, cell_idx_b, MIN_FEATURES)
        diff_exp.to_csv(output[0], '\t', index=False)
        diff_spl_clusters, diff_spl_introns = run_differential_splicing(
            adata_spl,
            cell_idx_a,
            cell_idx_b,
            min_cells_per_cluster=MIN_FEATURES,
            min_total_cells_per_intron=MIN_FEATURES,
            n_jobs=threads,
        )
        diff_spl_clusters.to_csv(output[1], '\t')
        diff_spl_introns.to_csv(output[2], '\t')


rule extract_gene_cds:
    input:
        full_gtf_path
    output:
        "output/gene_cds.txt"
    run:
        df = pd.read_csv(
            input[0], '\t', header=None, comment="#",
            names=['chromosome', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attribute'],
           )
        print(df.shape)
        df = df[df.feature=="CDS"]
        print(df.shape)
        df['gene_id'] = df.attribute.str.extract(r'gene_id "([^;]*)";')
        res = df.groupby("gene_id").agg({"chromosome": "first", "start": "min", "end": "max", "strand": "first"})
        print(res)
        res.to_csv(output[0], "\t")


rule extract_gene_name:
    input:
        full_gtf_path
    output:
        "output/gene_name.txt"
    run:
        df = pd.read_csv(
            input[0], '\t', header=None, comment="#",
            names=['chromosome', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attribute'],
           )
        print(df.shape)
        df = df[df.feature=="gene"]
        print(df.shape)
        df['gene_id'] = df.attribute.str.extract(r'gene_id "([^;]*)";')
        df['gene_name'] = df.attribute.str.extract(r'gene_name "([^;]*)";')
        res = df.groupby("gene_id").gene_name.first()
        print(res)
        res.to_csv(output[0], "\t")


rule filter_diff_spl_significant:
    input:
        'output/{anything}/expression.csv',
        'output/{anything}/splicing.clusters.csv',
        'output/{anything}/splicing.introns.csv',
        "output/gene_cds.txt",
        "output/gene_name.txt",
    output:
        'output/{anything}/splicing.significant.tsv',
    run:
        diff_exp = pd.read_csv(input[0], "\t", index_col=0)
        diff_spl_cluster = pd.read_csv(input[1], "\t", index_col=0)
        diff_spl_intron = pd.read_csv(input[2], "\t", index_col=0)
        gene_cds = pd.read_csv(input[3], "\t", index_col=0)
        gene_name = pd.read_csv(input[4], "\t", index_col=0)

        assert(set(diff_spl_cluster.index.values) == set(diff_spl_intron.cluster.unique()))

        print(diff_spl_cluster.shape)
        diff_spl_cluster = diff_spl_cluster[
            ((diff_spl_cluster.p_value_adj <= config["fdr"]) &
             (diff_spl_cluster.max_abs_delta_psi >= config["min_abs_delta_psi"]))
        ]
        print(diff_spl_cluster.shape)
        diff_spl_cluster = diff_spl_cluster.merge(gene_name, how="left", left_on="gene_id", right_index=True)
        print(diff_spl_cluster.shape)
        def max_abs_lfc_psi_unannotated(row_cluster):
            introns = diff_spl_intron[diff_spl_intron.cluster==row_cluster.name]
            return (introns.abs_lfc_psi * (~introns.annotated).astype(int)).max()
        diff_spl_cluster["max_abs_lfc_psi_unannotated"] = diff_spl_cluster.apply(max_abs_lfc_psi_unannotated, axis=1)
        def max_abs_delta_psi_unannotated(row_cluster):
            introns = diff_spl_intron[diff_spl_intron.cluster==row_cluster.name]
            return (introns.abs_delta_psi * (~introns.annotated).astype(int)).max()
        diff_spl_cluster["max_abs_delta_psi_unannotated"] = diff_spl_cluster.apply(max_abs_delta_psi_unannotated, axis=1)
        diff_spl_cluster["Annotated"] = diff_spl_cluster.max_abs_delta_psi_unannotated < config["min_abs_delta_psi"]

        coordinates = diff_spl_intron.groupby("cluster").agg({"chromosome": "first", "start": "unique", "end": "unique"})
        diff_spl_cluster = diff_spl_cluster.merge(coordinates, how="left", left_index=True, right_index=True)

        print(diff_spl_cluster.Annotated.value_counts())
        def get_diff_exp_rank(row_cluster):
            try:
                return diff_exp.loc[row_cluster.gene_name].ranking
            except KeyError:
                return np.nan
        diff_spl_cluster["diff_exp_rank"] = diff_spl_cluster.apply(get_diff_exp_rank, axis=1)
        def check_region(row_cluster):
            try:
                cds = gene_cds.loc[row_cluster.gene_id]
            except KeyError:
                return "Non-coding"
            introns = diff_spl_intron[diff_spl_intron.cluster==row_cluster.name]
            cluster_start = introns.start.min()
            cluster_end = introns.end.max()
            if cds.strand == "+":
                if cluster_start < cds.start:
                    return "5' UTR"
                if cluster_start < cds.end:
                    return "CDS"
                return "3' UTR"
            elif cds.strand == "-":
                if cluster_start < cds.start:
                    return "3' UTR"
                if cluster_start < cds.end:
                    return "CDS"
                return "5' UTR"
            else:
                raise Exception("strand not implemented")
        diff_spl_cluster["Region"] = diff_spl_cluster.apply(check_region, axis=1)
        print(diff_spl_cluster.Region.value_counts())
        diff_spl_cluster.max_abs_delta_psi = diff_spl_cluster.max_abs_delta_psi.round(decimals=3)

        def signif(x, p):
            x = np.asarray(x)
            x_positive = np.where(np.isfinite(x) & (x != 0), np.abs(x), 10**(p-1))
            mags = 10 ** (p - 1 - np.floor(np.log10(x_positive)))
            return np.round(x * mags) / mags

        diff_spl_cluster.p_value = signif(diff_spl_cluster.p_value.values, 3)
        diff_spl_cluster.p_value_adj = signif(diff_spl_cluster.p_value_adj.values, 3)

        diff_spl_cluster.to_csv(
            output[0], "\t",
            columns=["gene_id", "gene_name", "p_value", "p_value_adj", "max_abs_delta_psi", "chromosome", "start", "end", "Annotated", "Region", "diff_exp_rank"],
        )


rule merge_significant:
    input:
        lambda wildcards: expand('output/differential_splicing/tissue_cell_type/{{tissue}}/{cell_type}/splicing.significant.tsv', cell_type=[ct for t, ct in tissue_cell_type_pairs if t==wildcards["tissue"]])
    output:
        "output/differential_splicing/tissue_cell_type/{tissue}/merged_significant.txt",
    run:
        dfs = []
        for cell_type, input_path in zip([ct for t, ct in tissue_cell_type_pairs if t==wildcards["tissue"]], input):
            df = pd.read_csv(input_path, "\t")
            df["Cell type"] = cell_type.replace("_", " ")
            dfs.append(df)
        df = pd.concat(dfs, ignore_index=True)
        df = df.sort_values("p_value_adj")
        df.to_csv(output[0], "\t", index=False)


rule plot_significant:
    input:
        "output/differential_splicing/tissue_cell_type/{tissue}/merged_significant.txt",
    output:
        "output/differential_splicing/tissue_cell_type/{tissue}/merged_significant_all.svg",
        "output/differential_splicing/tissue_cell_type/{tissue}/merged_significant_aggregate.svg",
        #"output/differential_splicing/tissue_cell_type/{tissue}/merged_significant_5p.pdf",
        #"output/differential_splicing/tissue_cell_type/{tissue}/merged_significant_cds.pdf",
        #"output/differential_splicing/tissue_cell_type/{tissue}/merged_significant_3p.pdf",
    run:
        df_all = pd.read_csv(input[0], "\t")
        df_all["Type"] = df_all.Annotated
        df_all.Type = df_all.Type.replace(True, "Annotated").replace(False, "Novel")
        df_all.Region = df_all.Region.replace("Non-coding", "Non-coding RNA")

        def plot_counts(df, output_path):
            df_plot = df.groupby(["Type", "Cell type"]).size().reset_index().pivot(columns='Type', index='Cell type', values=0)
            g = df_plot.plot(kind='bar', stacked=True)
            g.set_xticklabels(g.get_xticklabels(), rotation=45, horizontalalignment='right')
            g.set(xlabel="", ylabel='Diff. spl. events')
            #g.despine(left=True)
            sns.despine(left=True)
            plt.legend(loc='upper right')
            plt.savefig(output_path, bbox_inches='tight')
            plt.close()
        plot_counts(df_all, output[0])
        #plot_counts(df_all[df_all.Region=="5' UTR"], output[1])
        #plot_counts(df_all[df_all.Region=="Coding region"], output[2])
        #plot_counts(df_all[df_all.Region=="3' UTR"], output[3])
        df = df_all
        df_plot = df.groupby(["Type", "Region"]).size().reset_index().pivot(columns='Type', index='Region', values=0).loc[["5' UTR", "CDS", "3' UTR", "Non-coding RNA"]]
        g = df_plot.plot(kind='bar', stacked=True)
        g.set_xticklabels(g.get_xticklabels(), rotation=45, horizontalalignment='right')
        g.set(xlabel="", ylabel='Diff. spl. events')
        sns.despine(left=True)
        plt.legend(loc='upper right')
        plt.savefig(output[1], bbox_inches='tight')


rule compare_latent_custom_plot:
    input:
        expand("output/dimensionality_reduction/mg/{quantification}/pca/latent.txt", quantification=quantifications_mg_individual),
    output:
        "output/comparison/mg_3_38_F/cell_ontology_class.svg",
        "output/comparison/mg_3_38_F/plate.svg",
    run:
        obs = sample_info[(sample_info.tissue=="Mammary_Gland")]
        obs = obs.sort_index()
        idx = np.where((obs["mouse.id"]=="3_38_F") & (obs.cell_ontology_class!="endothelial cell"))[0]
        obs = obs.iloc[idx]
        obs["Cell type"] = obs.cell_ontology_class
        obs["Plate ID"] = obs.plate_id
        dfs = []
        for name, input_path in zip(quantifications_mg_individual, input):
            if name == "gene-expression":
                name = "Gene expression \n (featureCounts)"
            if name == "kallisto":
                name = "Isoform proportions \n (kallisto)"
            if name == "bins-nmf":
                name = "100-bp bin cov. proportions \n (ODEGR-NMF)"
            if name == "introns-shared-acceptor":
                name = "Alt. intron proportions \n (scQuint)"
            df = obs.copy()
            latent = np.loadtxt(input_path)
            latent = latent[idx]
            proj = UMAP(min_dist=0.5, n_neighbors=15, random_state=42).fit_transform(latent)
            df["UMAP 1"] = proj[:, 0]
            df["UMAP 2"] = proj[:, 1]
            df["Quantification"] = name
            dfs.append(df)
        df = pd.concat(dfs)
        df = df.replace("luminal epithelial cell of mammary gland", "luminal\nepithelial")
        df = df.replace("basal cell", "basal")
        df = df.replace("stromal cell", "stromal")
        g = sns.relplot(
            data=df, x="UMAP 1", y="UMAP 2",
            col="Quantification", hue="Cell type",
            kind="scatter", facet_kws={'sharey': False, 'sharex': False},
            height=2.5, palette="tab10", edgecolor="none", s=8,
        )
        g.set_titles(col_template="{col_name}")
        g.fig.subplots_adjust(wspace=0.1)
        for ax in g.axes.flat:
            ax.set_xticks([])
            ax.set_yticks([])
            ax.set_ylabel("UMAP 2")
        sns.despine()
        plt.savefig(output[0], bbox_inches='tight')
        plt.close()
        g = sns.relplot(
            data=df, x="UMAP 1", y="UMAP 2",
            col="Quantification", hue="Plate ID",
            kind="scatter", facet_kws={'sharey': False, 'sharex': False},
            height=2.5, palette=["C3", "C4", "C6"], edgecolor="none", s=8,
        )
        #g.set_titles(col_template="{col_name}")
        g.set_titles(col_template="")
        g.fig.subplots_adjust(wspace=0.1)
        for ax in g.axes.flat:
            ax.set_xticks([])
            ax.set_yticks([])
            ax.set_ylabel("UMAP 2")
        sns.despine()
        plt.savefig(output[1], bbox_inches='tight')
        plt.close()


rule dimensionality_reduction_marrow_b_expression:
    input:
        "output/quantification/gene-expression/adata_annotated.h5ad",
    output:
        "output/dimensionality_reduction/marrow_b/gene-expression/PCA/latent.txt",
    run:
        adata = anndata.read_h5ad(input[0])
        adata = adata[(adata.obs.tissue=="Marrow") & (adata.obs.cell_ontology_class.str.endswith("B cell"))]
        sc.pp.filter_genes(adata, min_cells=30)
        sc.pp.normalize_total(adata, target_sum=1e4)
        sc.pp.log1p(adata)
        X = adata.X.toarray()
        latent = PCA(n_components=20).fit_transform(X)
        np.savetxt(output[0], latent)


rule dimensionality_reduction_marrow_b_pca:
    input:
        "output/quantification/{quantification}/adata_annotated.h5ad",
    output:
        "output/dimensionality_reduction/marrow_b/{quantification}/PCA_{K}/latent.txt",
    run:
        adata = anndata.read_h5ad(input[0])
        adata = adata[(adata.obs.tissue=="Marrow") & (adata.obs.cell_ontology_class.str.endswith("B cell"))]
        adata = filter_min_cells_per_feature(adata, 30)
        latent = run_pca(adata, int(wildcards["K"]))
        np.savetxt(output[0], latent)


rule compare_latent_marrow_b:
    input:
        "output/dimensionality_reduction/marrow_b/gene-expression/PCA/latent.txt",
        "output/dimensionality_reduction/marrow_b/introns-shared-acceptor/PCA_20/latent.txt",
    output:
        expand("output/comparison/marrow_b/{label}.svg", label=labels)
    run:
        obs = sample_info.copy()
        idx = np.where((obs.tissue=="Marrow") & (obs.cell_ontology_class.str.endswith("B cell")))[0]
        obs = obs.iloc[idx]

        obs = obs.replace("late pro-B cell", "(1) pro-B")
        obs = obs.replace("precursor B cell", "(2) pre-B")
        obs = obs.replace("immature B cell", "(3) immature B")
        obs = obs.replace("naive B cell", "(4) naive B")

        dfs = []
        for name, input_path in zip(["Expression latent space", "Splicing latent space"], input):
            df = obs.copy()
            latent = np.loadtxt(input_path)
            proj = UMAP(min_dist=0.5, n_neighbors=15, random_state=42).fit_transform(latent)
            df["UMAP 1"] = proj[:, 0]
            df["UMAP 2"] = proj[:, 1]
            df["Quantification"] = name
            df = df[df.cell_ontology_class != "early pro-B cell"]
            df = df.sort_values("cell_ontology_class")
            dfs.append(df)
        df = pd.concat(dfs)
        for i, label in enumerate(labels):
            g = sns.relplot(
                data=df, x="UMAP 1", y="UMAP 2",
                col="Quantification", hue=label,
                kind="scatter", facet_kws={'sharey': False, 'sharex': False},
                height=3, palette="tab10", edgecolor="none", s=4,
               )
            g.set_titles(col_template="{col_name}")
            g.fig.subplots_adjust(wspace=0.1)
            for ax in g.axes.flat:
                ax.set_xticks([])
                ax.set_yticks([])
                ax.set_ylabel("UMAP 2")
            sns.despine()
            plt.savefig(output[i], bbox_inches='tight')


rule psi_plot:
    input:
        "output/quantification/introns-shared-acceptor/adata_annotated.h5ad",
    output:
        expand("output/plots/{intron}.svg", intron=introns_to_plot),
    run:
        adata = anndata.read_h5ad(input[0])
        adata.obs = adata.obs.replace("late pro-B cell", "(1) pro-B")
        adata.obs = adata.obs.replace("precursor B cell", "(2) pre-B")
        adata.obs = adata.obs.replace("immature B cell", "(3) immature B")
        adata.obs = adata.obs.replace("naive B cell", "(4) naive B")
        print(adata.shape)
        adata.obs["Cell type"] = adata.obs.cell_ontology_class
        adata = adata[adata.obs["Cell type"].isin(cell_type_order)]
        print(adata.shape)
        X = group_normalize(adata.X.toarray(), adata.var.cluster.values, smooth=False)
        var = adata.var.copy()
        var["position"] = np.arange(len(var))
        var["id"] = var.chromosome.astype(str) + ":" + var.start.astype(str) + "-" + var.end.astype(str)
        var = var.set_index("id")
        for i, intron in enumerate(introns_to_plot):
            obs = adata.obs.copy()
            print("position: ", var.loc[intron].position)
            obs["PSI"] = X[:, var.loc[intron].position].ravel()
            print(obs.groupby("Cell type").PSI.mean())
            print(obs.PSI.isna().sum())

            g = sns.FacetGrid(
                obs,
                col="Cell type",
                col_order=cell_type_order,
                hue="Cell type",
                hue_order=cell_type_order,
                palette="tab10",
                sharex=False,
                sharey=True,
                #height=1.5,
                height=2,
                aspect=1,
            )
            eps = 1e-4
            g.map_dataframe(
                sns.histplot,
                y="PSI",
                bins=np.linspace(0-eps, 1+eps, 11),
                stat="probability",
            )
            g.fig.subplots_adjust(wspace=0)
            g.set_titles(col_template="{col_name}")
            g.set_ylabels("PSI")
            g.set(xticks=[])
            g.set(xlim=(0, 1), ylim=(0, 1))
            sns.despine(bottom=True)
            plt.savefig(output[i], bbox_inches='tight')


rule exp_plot:
    input:
        "output/quantification/gene-expression/adata_annotated.h5ad",
    output:
        expand("output/plots/{gene}.svg", gene=genes_to_plot),
    run:
        adata = anndata.read_h5ad(input[0])
        adata.obs = adata.obs.replace("late pro-B cell", "(1) pro-B")
        adata.obs = adata.obs.replace("precursor B cell", "(2) pre-B")
        adata.obs = adata.obs.replace("immature B cell", "(3) immature B")
        adata.obs = adata.obs.replace("naive B cell", "(4) naive B")
        print(adata.shape)
        adata.obs["Cell type"] = adata.obs.cell_ontology_class
        adata = adata[adata.obs["Cell type"].isin(cell_type_order)]
        print(adata.shape)
        sc.pp.normalize_total(adata, target_sum=1e4)
        sc.pp.log1p(adata)
        for i, gene in enumerate(genes_to_plot):
            obs = adata.obs.copy()
            obs["log norm. expression"] = adata[:, gene].X.toarray().ravel()
            plt.figure(figsize=(3, 2))
            g = sns.violinplot(
                data=obs,
                x="Cell type",
                y="log norm. expression",
                order=cell_type_order,
                #hue="Cell type",
                #hue_order=cell_type_order,
                palette="tab10",
                cut=0.05,
                scale="width",
                width=0.75,
            )
            g.set(xlabel=None)
            sns.despine(bottom=True)
            plt.xticks(rotation=45)
            plt.savefig(output[i], bbox_inches='tight')
            plt.close()
            plt.clf()


rule diff_test_summary:
    input:
        'output/{anything}/expression.csv',
        'output/{anything}/splicing.clusters.csv',
    output:
        'output/{anything}/summary.tsv',
    run:
        df_exp = pd.read_csv(input[0], "\t")
        df_spl = pd.read_csv(input[1], "\t")
        n_genes_exp = ((df_exp.p_value_adj < config["fdr"]) & (df_exp.abs_lfc > config["min_abs_lfc"])).sum()
        n_genes_spl = len(df_spl[(df_spl.p_value_adj < config["fdr"]) & (df_spl.max_abs_delta_psi > config["min_abs_delta_psi"])].gene_id.unique())
        ratio = n_genes_spl / n_genes_exp
        intersection = len(list(set(df_exp.gene.unique()[:100]).intersection(set(df_spl.gene_id.unique()[:100]))))
        print(n_genes_exp, n_genes_spl, ratio, intersection)
        res = pd.DataFrame([[n_genes_exp, n_genes_spl, ratio, intersection]], columns=["n_genes_exp", "n_genes_spl", "ratio", "top100_intersection"])
        res.to_csv(output[0], "\t", index=False)


def calculate_classification_metrics(latent, classes, idx, seed=None):
    latent = latent[idx]
    classes = classes[idx]
    all_classes = np.unique(classes)

    try:
        X_train, X_test, y_train, y_test = train_test_split(
            latent, classes, test_size=0.33, random_state=seed, stratify=classes
        )
    except:
        X_train, X_test, y_train, y_test = train_test_split(
            latent, classes, test_size=0.33, random_state=seed, stratify=None
        )
        print("not stratifying")

    clf = LogisticRegression(random_state=seed, max_iter=10000)
    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)
    y_proba = clf.predict_proba(X_test)
    return accuracy_score(y_test, y_pred), f1_score(y_test, y_pred), roc_auc_score(y_test, y_proba[:, 1])


rule get_classification_score:
    input:
        "output/dimensionality_reduction/marrow/gene-expression/PCA/latent.txt",
        "output/dimensionality_reduction/marrow/introns-shared-acceptor/PCA_20/latent.txt",
    output:
        "output/dimensionality_reduction/marrow/classification_score.tsv",
    run:
        latent_exp = np.loadtxt(input[0])
        latent_spl = np.loadtxt(input[1])
        obs = sample_info[sample_info.tissue=="Marrow"]

        results = []
        for tissue, cell_type in tissue_cell_type_pairs:
            if tissue != "Marrow": continue
            print(cell_type)
            idx = np.where(np.isin(obs.cell_type, [ct for t, ct in tissue_cell_type_pairs if t==tissue]))[0]
            print(idx)
            labels = (obs.cell_type==cell_type)
            print(labels.sum(), len(labels), len(latent_exp), len(latent_spl))

            for seed in range(30):
                results.append((cell_type.replace("_", " "), "Expression", seed, *calculate_classification_metrics(latent_exp, labels, idx, seed)))
                results.append((cell_type.replace("_", " "), "Splicing", seed, *calculate_classification_metrics(latent_spl, labels, idx, seed)))
        results = pd.DataFrame(results, columns=['Cell type', 'Latent space', 'seed', 'accuracy', 'F1 score', "AUC"])
        results.to_csv(output[0], "\t", index=False)


rule plot_classification_score:
    input:
        "output/dimensionality_reduction/marrow/classification_score.tsv",
    output:
        "output/dimensionality_reduction/marrow/classification_score.svg",
    run:
        df = pd.read_csv(input[0], "\t")
        g = sns.barplot(x="Cell type", y="AUC", hue="Latent space", data=df, ci='sd', palette="Accent");
        g.set_xticklabels(g.get_xticklabels(), rotation=45,  horizontalalignment='right')
        g.set(xlabel="")
        sns.despine()
        #plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., title="latent space");
        plt.tight_layout()
        plt.savefig(output[0], bbox_inches="tight")


rule get_marker_introns:
    input:
        'output/{anything}/splicing.clusters.csv',
        'output/{anything}/splicing.introns.csv',
    output:
        'output/{anything}/marker_introns.tsv',
    run:
        groups = pd.read_csv(input[0], "\t")
        introns = pd.read_csv(input[1], "\t")
        introns["id"] = introns.chromosome.astype(str) + ":" + introns.start.astype(str) + "-" + introns.end.astype(str)
        introns = introns.set_index("id")
        groups = groups[(groups.p_value_adj < config["fdr"])].sort_values("max_abs_delta_psi", ascending=False).head(10)
        print(groups.max_abs_delta_psi)
        marker_introns = groups.cluster.apply(lambda x: introns[introns.cluster==x].delta_psi.idxmax())
        print(marker_introns)
        marker_introns.to_csv(output[0], index=False, header=False)


rule plot_marker_introns:
    input:
        "output/quantification/introns-shared-acceptor/adata_annotated.h5ad",
        expand('output/differential_splicing/tissue_cell_type/{tct[0]}/{tct[1]}/marker_introns.tsv', tct=tissue_cell_type_pairs),
    output:
        'output/differential_splicing/tissue_cell_type/marker_introns.svg',
    run:
        adata_spl = anndata.read_h5ad(input[0])
        adata_spl.var["id"] = adata_spl.var.chromosome.astype(str) + ":" + adata_spl.var.start.astype(str) + "-" + adata_spl.var.end.astype(str)
        adata_spl.var = adata_spl.var.set_index("id")

        all_marker_introns = []
        for input_path in input[1:]:
            marker_introns = pd.read_csv(input_path, "\t", header=None).values.astype(str).ravel().tolist()[:3]
            all_marker_introns += marker_introns
        print(all_marker_introns)
        print(len(all_marker_introns))
        all_marker_introns = pd.unique(all_marker_introns)
        print(len(all_marker_introns))
        adata_spl.X = group_normalize(adata_spl.X.toarray(), adata_spl.var.cluster.values, smooth=False)
        adata_spl.obs["tissue_cell_type"] = adata_spl.obs.tissue.astype(str) + "/" + adata_spl.obs.cell_type.astype(str)
        tissue_cell_types = [tissue + "/" + cell_type for tissue, cell_type in tissue_cell_type_pairs]
        adata_spl = adata_spl[adata_spl.obs["tissue_cell_type"].isin(tissue_cell_types)]
        adata_spl = adata_spl[:, all_marker_introns]
        for tissue_cell_type in tissue_cell_types:
            print(tissue_cell_type)
            for intron in all_marker_introns:
                idx_cells = np.where(adata_spl.obs["tissue_cell_type"]==tissue_cell_type)[0]
                n_defined = (~np.isnan(adata_spl[idx_cells, intron].X)).sum()
                if n_defined < 10:
                    adata_spl[idx_cells, intron].X = np.nan
        gene_name = pd.read_csv("output/gene_name.txt", "\t", index_col=0)
        adata_spl.var = adata_spl.var.merge(gene_name, how="left", left_on="gene_id", right_index=True)
        adata_spl.var.loc[:, "id"] = adata_spl.var.gene_name.astype(str) + "_" + adata_spl.var.index
        adata_spl.var = adata_spl.var.set_index("id")

        g = sc.pl.matrixplot(
            adata_spl,
            adata_spl.var.index.values,
            groupby='tissue_cell_type',
            categories_order=tissue_cell_types,
            return_fig=True, vmin=0.0, vmax=1.0, cmap='bwr', swap_axes=True, colorbar_title="Mean PSI")
        plt.tight_layout()
        g.savefig(output[0], bbox_inches="tight")


rule prepare_adata_for_cellxgene:
    input:
        "output/quantification/gene-expression/adata_annotated.h5ad",
        "output/quantification/introns-shared-acceptor/adata_annotated.h5ad",
        "output/gene_name.txt",
    output:
        "output/adata_cellxgene.h5ad",
    run:
        gene_name = pd.read_csv(input[2], "\t", index_col=0)
        adata_exp = anndata.read_h5ad(input[0])
        adata_exp.var = adata_exp.var.merge(gene_name, how="left", left_index=True, right_index=True)
        adata_exp.var["gene_id"] = adata_exp.var.index.values
        adata_exp.var = adata_exp.var.set_index("gene_name")
        adata_exp.var_names_make_unique()
        adata_exp.obs.index = adata_exp.obs.index.astype(str)
        adata_spl = anndata.read_h5ad(input[1])
        adata_spl.var = adata_spl.var.merge(gene_name, how="left", left_on="gene_id", right_index=True)
        adata_spl.var["id"] = adata_spl.var.gene_name + "_" + adata_spl.var.chromosome.astype(str) + ":" + adata_spl.var.start.astype(str) + "-" + adata_spl.var.end.astype(str)
        adata_spl.var = adata_spl.var.set_index("id", drop=False)
        adata_spl.obs.index = adata_spl.obs.index.astype(str)
        adata_spl.var.index = adata_spl.var.index.astype(str)
        assert((adata_exp.obs.index == adata_spl.obs.index).all())
        sc.pp.normalize_total(adata_exp, target_sum=1e4)
        sc.pp.log1p(adata_exp)
        adata_exp.X = adata_exp.X.toarray()
        adata_spl.X = group_normalize(adata_spl.X.toarray(), adata_spl.var.cluster.values, smooth=False)
        latent = PCA(n_components=40).fit_transform(adata_exp.X)
        proj = UMAP(min_dist=0.5, n_neighbors=15, random_state=42).fit_transform(latent)

        X = np.hstack((adata_exp.X, adata_spl.X))
        print(adata_exp.shape, adata_spl.shape, X.shape)
        obs = adata_exp.obs
        var = pd.concat([adata_exp.var, adata_spl.var])
        adata = anndata.AnnData(X=X, obs=obs, var=var)
        adata.obsm["X_umap"] = proj
        adata.write_h5ad(output[0], compression="gzip")


rule make_bam_paths_tct:
    input:
        expand("output/mapping/filtered_bams/{sample_id}.bam", sample_id=sample_ids)
    output:
        "output/bam_paths/tct/{tissue}/{cell_type}/paths.txt",
    run:
        s_ids = sample_ids[np.where((sample_info.tissue==wildcards["tissue"]) & (sample_info.cell_type==wildcards["cell_type"]))[0]]
        cwd = os.getcwd()
        pd.DataFrame(dict(sample_id=s_ids, bam_path=[f"{cwd}/output/mapping/filtered_bams/{sample_id}.bam" for sample_id in s_ids])).to_csv(output[0], "\t", index=False, header=False)


rule make_coverage_track_tct:
    input:
        "output/bam_paths/tct/{tissue}/{cell_type}/paths.txt",
    output:
        "output/coverage_track/tct/{tissue}/{cell_type}/coverage.bw",
    threads: workflow.cores // 4
    shell:
        "python -m scquint.quantification.run coverage_track/Snakefile --cores {threads} -d output/coverage_track/tct/{wildcards.tissue}/{wildcards.cell_type}/ --config bam_paths=../../../../bam_paths/tct/{wildcards.tissue}/{wildcards.cell_type}/paths.txt chrom_sizes_path={chrom_sizes_path}"
