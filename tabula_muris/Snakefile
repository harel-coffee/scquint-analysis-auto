import anndata
from Bio.Seq import Seq
from collections import Counter, defaultdict
import csv
import itertools
from more_itertools import flatten, pairwise
import numpy as np
import os
import pandas as pd
import re
import scanpy as sc
import scipy.sparse as sp_sparse
from scipy.stats import chi2_contingency, spearmanr
from shutil import copyfile
from sklearn.cluster import KMeans, SpectralClustering
from sklearn.decomposition import PCA, NMF
from sklearn.feature_selection import RFECV, SelectFromModel
from sklearn.linear_model import LogisticRegression, LogisticRegressionCV
from sklearn.metrics import accuracy_score, f1_score, roc_auc_score
from sklearn.model_selection import train_test_split
from statsmodels.stats.multitest import multipletests
import umap.umap_ as umap
UMAP = umap.UMAP
from textwrap import wrap
import matplotlib
import matplotlib.pyplot as plt
import seaborn as sns

from scquint.differential_splicing import run_differential_splicing
from scquint.dimensionality_reduction import run_pca
from scquint.utils import (filter_min_cells_per_cluster,
                            filter_min_cells_per_feature, filter_singletons,
                            group_normalize, relabel,
                            run_differential_expression, recluster)

from spliceVI.dimensionality_reduction import run_vae
from spliceVI.utils import plot_comparison

matplotlib.use('pdf')
#sns.set_palette("muted")
sns.set(style="white")

configfile: 'config.yaml'


# TODO: this should go into an independent prepare_metadata.py script
# obs_file = "GSM4505405_tabula-muris-senis-facs-official-raw-obj-metadata.csv"
# obs = pd.read_csv(obs_file, ",", index_col=0)
# if np.isin('3m', obs.age.values):
#     obs.loc[obs.age=='3m', 'my_id'] = obs[obs.age=='3m'].index.str.split('.').str[:2].str.join('_')
# if np.isin('18m', obs.age.values):
#     obs.loc[obs.age=='18m', 'my_id'] = (obs[obs.age=='18m'].index.str.split('_').str[:2].str.join('_'))
# if np.isin('21m', obs.age.values):
#     obs.loc[obs.age=='21m', 'my_id'] = (obs[obs.age=='21m'].index.str.split('_').str[:2].str.join('_'))
# if np.isin('24m', obs.age.values):
#     obs.loc[obs.age=='24m', 'my_id'] = (obs[obs.age=='24m'].index.str.split('_').str[:3]
#                                        .str.join('.').str.split('.').str[:2].str.join('_'))
#obs = obs.set_index("my_id")

genome_fasta_path = config["genome_fasta_path"]
full_gtf_path = config["gtf_path"]
chrom_sizes_path = config["chrom_sizes_path"]
encode_blacklist_path = config["encode_blacklist_path"]
sjdb_path = config["sjdb_path"]  # maybe should be created in this workflow
groupings = ["nontransitive", "transitive", "gene"]

sample_info = pd.read_csv("obs.txt.gz", "\t", index_col=0)
sample_ids = sample_info.index.values
print("len(sample_ids): ", len(sample_ids))
sample_info.loc[:, "cell_type"] = sample_info.cell_ontology_class.str.replace(" ", "_").str.replace("-", "_")
sample_info["plate_id"] = sample_info.index.str.split("_").str[1]


#cwd = os.getcwd()
#pd.DataFrame(dict(
#    sample_id=sample_ids,
#    bam_path=[f"{cwd}/output/mapping/filtered_bams/{sample_id}.bam"
#              for sample_id in sample_ids])
#).to_csv("output/bam_paths.txt", "\t", index=False, header=False)

#obs = sample_info
#
##x = (obs[(obs["mouse.id"]=="3_10_M") & (obs.tissue=="Brain_Non-Myeloid") & (obs.subtissue=="Cortex")])
##print(x.plate_id.value_counts())
## MAA000560    287
## MAA000561     97
#
## x = (obs[(obs["mouse.id"]=="3_10_M") & (obs.tissue=="Brain_Non-Myeloid") & (obs.subtissue=="Cerebellum")])
## print(x.plate_id.value_counts())
## MAA000581    201
## MAA000578     40
#
#x = (obs[(obs["mouse.id"]=="3_10_M") & (obs.tissue=="Brain_Non-Myeloid") & (obs.subtissue=="Hippocampus")])
#print(x.plate_id.value_counts())
#
#x = (obs[(obs["mouse.id"]=="3_10_M") & (obs.tissue=="Brain_Non-Myeloid") & (obs.subtissue=="Striatum")])
#print(x.plate_id.value_counts())
#
#
#for mouse in ["3_10_M", "3_38_F", "3_39_F", "3_8_M", "3_9_M"]:
#    for subtissue in ["Cortex", "Cerebellum", "Hippocampus", "Striatum"]:
#        print(mouse, subtissue)
#        x = (obs[(obs["mouse.id"]==mouse) & (obs.tissue=="Brain_Non-Myeloid") & (obs.subtissue==subtissue)])
#        print(x.plate_id.value_counts())
#        print(x.cell_ontology_class.value_counts().head(3))
#raise Exception("debug")


#sample_ids_subset = sorted(sample_info[(sample_info.tissue=="Mammary_Gland")&(sample_info["mouse.id"]=="3_56_F")].index.values)
#sample_ids_subset = sorted(sample_info[(sample_info.tissue=="Mammary_Gland")&(sample_info["mouse.id"]=="3_38_F")].index.values)
sample_ids_subset = sorted(sample_info[sample_info.tissue=="Mammary_Gland"].index.values)
print("len(sample_ids_subset): ", len(sample_ids_subset))

sample_ids_leafcutter = sample_ids_subset

# zcat GSE109774_list_of_SRR_accessions_and_raw_filenames.txt.gz | cut -f 2,3 | cut -d "-" -f 1-2 | sed 's/-/_/g' > srr_cell_pairs.txt
sample_srr = pd.read_csv("srr_cell_pairs.txt", '\t', header=None, names=['srr', 'cell'])
sample_srr = sample_srr[sample_srr.cell.isin(sample_ids)]

genes_bam_merge = {
#    "Foxp1": {
#        "region": ["chr6", 98888459, 99713014],
#        "cell_types": ["late_pro_B_cell", "precursor_B_cell", "immature_B_cell", "naive_B_cell"],
#    },
    "Smarca4": {
        "region": ["chr9", 21615842, 21633577],
        "cell_types": ["late_pro_B_cell", "precursor_B_cell", "immature_B_cell", "naive_B_cell"],
    },
#    "Echdc2": {
#        "region": ["chr4", 108164887, 108179634],
#        "cell_types": ["hepatocyte_cluster_0", "hepatocyte_cluster_1"],
#    },
}


quantifications_mg_individual = ["gene-expression", "kallisto", "bins-nmf", "introns-shared-acceptor"]
#quantifications_mg_individual_expanded = ["gene-expression", "kallisto", "bins", "exons", "introns-gene", "introns-transitive", "SE", "introns-shared-acceptor"]
#quantifications_mg_individual_expanded = ["gene-expression", "kallisto", "bins", "exons", "introns-gene", "leafcutter", "introns-transitive"]
quantifications_mg_individual_expanded = ["leafcutter", "introns-transitive", "introns-shared-acceptor"]
#quantifications_mg_individual_expanded = ["gene-expression", "exons", "introns-gene", "introns-transitive", "SE", "introns-shared-acceptor"]
#quantifications_mg_individual_expanded = ["gene-expression", "kallisto", "bins-nmf"]

motif1 = "AAGCAGTGGTATCAACGCAGAGT"
motif2 = "ACTTTTTTTTTTTTTTTTTTTTTTTTTTTTTT"
motif3 = "AAGCAGTGGTATCAACGCAGAGTACGGG"
motif1_rc = str(Seq(motif1).reverse_complement())
motif2_rc = str(Seq(motif2).reverse_complement())
motif3_rc = str(Seq(motif3).reverse_complement())

sample_info["cell_type"] = sample_info.cell_ontology_class.str.replace(" ", "_").str.replace("-", "_")
sample_info["Cell type"] = sample_info.cell_ontology_class

new_clusters = pd.read_csv("output/comparison/Liver-hepatocyte/clusters_spl.tsv", "\t", index_col=0)
sample_info = sample_info.merge(new_clusters, how="left", left_index=True, right_index=True)
sample_info_notna = sample_info[~(sample_info.cluster_spl.isna())]
sample_info_notna["Cluster"] = "cluster_" + sample_info_notna.cluster_spl.astype(int).astype(str)
sample_info_notna["cell_type"] = sample_info_notna["cell_type"] + "_" + sample_info_notna.Cluster
#sample_info.loc[~(sample_info.cluster_spl.isna()), "cell_type"] = sample_info_notna["cell_type"].values

tissues = sample_info.tissue.unique()
cell_types = sample_info.cell_type.unique()
tissue_cell_type_pairs = []
tissue_cell_type_pairs_including_singletons = []
for tissue in tissues:
    tissue_cell_type_counts = sample_info[sample_info.tissue==tissue].cell_type.value_counts()
    tissue_cell_types = [ct for ct in sample_info[sample_info.tissue==tissue].cell_type.unique()
                         if tissue_cell_type_counts[ct] >= 100]
    tissue_cell_type_pairs_including_singletons += [[tissue, cell_type]
                                                    for cell_type in tissue_cell_types]
    if len(tissue_cell_types) < 2:
        continue
    tissue_cell_type_pairs += [[tissue, cell_type]
                               for cell_type in tissue_cell_types]
print(len(tissue_cell_type_pairs), len(tissue_cell_type_pairs_including_singletons))


flatten = lambda l: [item for sublist in l for item in sublist]



labels = ["Cell type", "mouse.id", "sex", "plate_id", "tissue"]
#labels = ["cell_ontology_class", "mouse.id", "sex", "plate_id", "tissue"]


introns_to_plot = [
    "chr6:99260420-99266347",
]

genes_to_plot = [
    "ENSMUSG00000030067",
]


cell_type_order = ["(1) pro-B", "(2) pre-B", "(3) immature B", "(4) naive B"]

#features = ["all_exp", "tf_exp", "tf_exp_spl", "all_spl", "sf_exp", "sf_exp_spl",]
features = ["all_exp", "tf_exp", "tf_exp_spl", "tf_spl",]
#features = ["tf_exp", "tf_exp_spl", "sf_exp", "sf_exp_spl", "all_exp", "all_spl", "tf_spl", "sf_spl",]


rule all:
    input:
        "output/cell_type_classification/Mammary_Gland/basal_cell/variables.tsv",
        #expand("output/dendrogram/all_exp-FALSE-{features2}-{scale2}/entanglement.txt", features2=["tf_exp", "tf_spl", "tf_exp_spl"], scale2=["TRUE", "FALSE"])
        #expand("output/dendrogram/all_exp-TRUE-{features2}-{scale2}/entanglement.txt", features2=["all_exp", "tf_exp", "tf_spl", "tf_exp_spl", "sf_exp", "sf_spl", "sf_exp_spl"], scale2=["TRUE", "FALSE"])
        #expand("output/dendrogram/{features}/features.tsv", features=features),
        #"output/differential_splicing/new_clusters/Liver/hepatocyte/marker_genes.svg",
        #"output/differential_splicing/marrow_b/tf_Foxp1_trajectory.svg",
        #"output/differential_splicing/marrow_b/tf_Smarca4_trajectory.svg",
#        expand("output/bam_regions/Smarca4/{cell_type}/merged.bam", cell_type=genes_bam_merge["Smarca4"]["cell_types"]),
        #"output/differential_splicing/new_clusters/Liver/hepatocyte/marker_introns.tsv",
        #"output/differential_splicing/new_clusters/Liver/hepatocyte/marker_introns.tsv",
        #"output/differential_splicing/marrow_b/marker_introns_trajectory_spl.svg",
        #expand('output/differential_splicing/marrow_b/{cell_type}/marker_introns.tsv', cell_type=cell_type_order),
        #expand("output/bam_regions/Echdc2/{cell_type}/merged.bam", cell_type=genes_bam_merge["Echdc2"]["cell_types"]),
        #"output/plots/hepatocyte_new_clusters/",
        #"output/plots/hepatocyte_new_clusters_exp/",
        #expand("output/comparison/tissue/Liver/{label}.svg", label=labels),
        #"output/adata_cellxgene_exp_spl.h5ad",
        #'output/differential_splicing/new_clusters/Liver/hepatocyte/plots',
        #expand("output/comparison/pca_vae/{tissue}/cell_type.svg", tissue=["Diaphragm", "Mammary_Gland"]),
        #"output/coverage_track/new_clusters/Heart/monocyte/0.0/coverage.bw",
        #"output/coverage_track/new_clusters/Heart/monocyte/1.0/coverage.bw",
        #"output/coverage_track/new_clusters/Liver/hepatocyte/0.0/coverage.bw",
        #"output/coverage_track/new_clusters/Liver/hepatocyte/1.0/coverage.bw",
        #"output/dimensionality_reduction/all/introns-shared-acceptor/vae_hyperopt/latent.txt",
        #"output/adata_cellxgene_spl_pca.h5ad",
        #'output/differential_splicing/new_clusters/Heart/monocyte/splicing.clusters.tsv',
        #'output/differential_splicing/new_clusters/Marrow/hematopoietic_stem_cell/splicing.clusters.tsv',
        #'output/differential_splicing/new_clusters/Liver/hepatocyte/splicing.clusters.significant.tsv',
        #'output/differential_splicing/new_clusters/Liver/hepatocyte/splicing.clusters.significant.tsv',
        #'output/differential_splicing/new_clusters/Liver/hepatocyte/marker_introns_dist.svg',
        #'output/differential_splicing/new_clusters/Liver/hepatocyte/marker_genes.svg',
        #'output/differential_splicing/new_clusters/Liver/hepatocyte/libsize.svg',
        #'output/differential_splicing/new_clusters/Liver/hepatocyte/percent_mito.svg',
        #'output/differential_splicing/new_clusters/Liver/hepatocyte/marker_introns.svg',
        #"output/comparison/Liver-hepatocyte/",
        #"output/comparison/well/Liver-hepatocyte/",
        #"output/comparison/Heart-monocyte/",
        #"output/comparison/Marrow-hematopoietic_stem_cell/",
        #"output/comparison/all",
        #"output/dimensionality_reduction/all/introns-shared-acceptor/vae_frequency-smoothed_False_100/latent.txt",
        #expand("output/dimensionality_reduction/tissue/{tissue}/introns-shared-acceptor/vae_frequency-smoothed_False/latent.txt", tissue=["Marrow", "Heart", "Brain_Myeloid"]),
        #expand("output/dimensionality_reduction/mg/{quantification}/vae_log_True/latent.txt", quantification=["leafcutter", "introns-transitive", "introns-shared-acceptor", "SE", "SE-shared-acceptor", "SE-shared-donor"]),
        #"output/quantification/introns/output/introns-shared-acceptor/adata.h5ad",
        #expand("output/mapping/filtered_bams/{sample_id}.bam.bai", sample_id=sample_ids),
        #"output/quantification/leafcutter/adata_annotated.h5ad",
        #expand("output/comparison/tissue/{tissue}/cell_ontology_class.svg", tissue=["Marrow", "Liver"]),
        #"output/dimensionality_reduction/marrow/classification_score.svg",
        #"output/quantification/SE/adata_annotated.h5ad",
        #"output/comparison/mg_3_38_F/classification_results_plots/",
        #"output/comparison/cortex_3_9_M/classification_results_plots/",
        #expand("output/differential_splicing/tissue_cell_type/{tct[0]}/{tct[1]}/splicing.clusters.tsv", tct=tissue_cell_type_pairs),
        #expand("output/differential_splicing/tissue_cell_type/{tct[0]}/{tct[1]}/summary.tsv", tct=tissue_cell_type_pairs),
        #"output/adata_cellxgene.h5ad",
        #expand("output/coverage_track/tct/{tct[0]}/{tct[1]}/coverage.bw", tct=tissue_cell_type_pairs_including_singletons),
        #"output/differential_splicing/tissue_cell_type/Marrow/merged_significant_all.svg",
        #"output/dimensionality_reduction/marrow/classification_score.svg",
        #expand("output/plots/{gene}.svg", gene=genes_to_plot),
        #expand("output/plots/{intron}.svg", intron=introns_to_plot),
        #expand("output/comparison/marrow_b/{label}.svg", label=labels),
        #"output/comparison/cortex_3_9_M/cell_ontology_class.svg",
        #"output/comparison/mg_3_38_F/cell_ontology_class.svg",
        #"output/comparison/mg_3_39_F/cell_ontology_class.svg",
        #expand("output/differential_splicing/tissue_cell_type/{tissue}/merged_significant_all.svg", tissue=pd.unique([t for t, ct in tissue_cell_type_pairs])),
        #expand("output/coverage_track/mg_basal_individual_plate/3_38_F/{plate}/coverage.bw", plate=["B002433", "B002432", "B002438"]),
        #expand(
        #    'output/differential_splicing/mg_basal_individual_plate/{individual}/{quantification}/splicing.clusters.csv',
        #    individual=["3_38_F"],
        #    quantification=["gene-expression"],
        #)
        #"output/coverage_track/mg_basal_individual_plate/3_56_F/B000167/coverage.bw",
        #"output/coverage_track/mg_basal_individual_plate/3_56_F/B000166/coverage.bw",
        #expand("output/bam_regions/Foxp1/{cell_type}/merged.bam", cell_type=genes_bam_merge["Foxp1"]["cell_types"]),


#rule download:
#    output: temp('output/srr/{srr}.sra')
#    priority: 100
#    shell: """
#    prefetch -o {output} {wildcards.srr}
#    """
#
#
#rule fastq_dump:
#    input:
#        'output/srr/{srr}.sra'
#    output:
#        temp('output/srr/{srr}_1.fastq.gz'),
#        temp('output/srr/{srr}_2.fastq.gz')
#    shell: """
#    cd output/srr && (fastq-dump --gzip --split-files {wildcards.srr}.sra || rm {wildcards.srr}.sra)
#    """
#
#
#def get_input_merge_fastq(wildcards):
#    return expand('output/srr/{{sra}}_{number}.fastq.gz'.format(number=wildcards.number),
#                  sra=sample_srr.srr[sample_srr.cell==wildcards.sample_id].values)
#
#
#rule merge_fastq:
#   input: get_input_merge_fastq
#   output: temp('output/fastq_raw/{sample_id}_{number}.fastq.gz')
#   shell: 'cat {input} > {output}'
#
#
#rule trim_adapters:
#    input:
#        "output/fastq_raw/{sample_id}_1.fastq.gz",
#        "output/fastq_raw/{sample_id}_2.fastq.gz",
#    output:
#        "output/fastq/{sample_id}_R1.fastq.gz",
#        "output/fastq/{sample_id}_R2.fastq.gz",
#    shell:
#        "cutadapt -g {motif1} -g {motif2} -g {motif3} -a {motif1_rc} -a {motif2_rc} -a {motif3_rc} -G {motif1} -G {motif2} -G {motif3} -A {motif1_rc} -A {motif2_rc} -A {motif3_rc} -m30 -n 4 -o {output[0]} -p {output[1]} {input[0]} {input[1]}"
#
#
#rule make_fastq_paths:
#    input:
#        expand("output/fastq/{sample_id}_R{pair}.fastq.gz", sample_id=sample_ids, pair=[1, 2]),
#    output:
#        "output/fastq_paths.txt"
#    run:
#        df = pd.DataFrame(sample_ids, columns=["sample_id"])
#        base_path = os.path.join(os.getcwd(), "output/fastq/")
#        df["fastq_1"] = base_path + df.sample_id + "_R1.fastq.gz"
#        df["fastq_2"] = base_path + df.sample_id + "_R2.fastq.gz"
#        df.to_csv(output[0], "\t", index=False, header=False)
#
#
#rule read_mapping:
#    input:
#        "output/fastq_paths.txt",
#        full_gtf_path
#    threads: workflow.cores
#    priority: 100
#    output:
#        expand("output/mapping/mapping_second_pass/{sample_id}/Aligned.rmdup.out.bam", sample_id=sample_ids)
#    shell:
#        "python -m scquint.quantification.run read_mapping/Snakefile --cores {threads} -d output/mapping/ --config min_cells_per_intron=30 fastq_paths=../fastq_paths.txt fasta_path={genome_fasta_path} gtf_path={full_gtf_path} sjdb_overhang=99"
#
#
#rule make_fastq_paths_subset:
#    input:
#        expand("output/fastq/{sample_id}_R1.fastq.gz", sample_id=sample_ids_subset),
#    output:
#        "output/fastq_paths_subset.txt"
#    run:
#        df = pd.DataFrame(sample_ids_subset, columns=["sample_id"])
#        base_path = os.path.join(os.getcwd(), "output/fastq/")
#        df["fastq_1"] = base_path + df.sample_id + "_R1.fastq.gz"
#        df["fastq_2"] = base_path + df.sample_id + "_R2.fastq.gz"
#        df.to_csv(output[0], "\t", index=False, header=False)
#
#
#rule kallisto_quantification:
#    input:
#        "output/fastq_paths_subset.txt",
#        full_gtf_path,
#    output:
#        "output/quantification/kallisto/adata.h5ad"
#    threads: workflow.cores
#    shell:
#        "python -m scquint.quantification.run kallisto/Snakefile --cores {threads} -d output/quantification/kallisto/ --config fastq_paths=../../fastq_paths_subset.txt genome_fasta_path={genome_fasta_path} gtf_path={full_gtf_path} min_cells_per_isoform=30"
#
#
#rule bins_quantification:
#    input:
#        "output/bam_paths_subset.txt",
#        full_gtf_path,
#    threads: workflow.cores
#    output:
#        "output/quantification/bins/adata.h5ad"
#    shell:
#        "python -m scquint.quantification.run bins/Snakefile --cores all -d output/quantification/bins/ --config min_cells_per_bin=100 gtf_path={full_gtf_path} bam_paths=../../bam_paths_subset.txt"
#
#
#rule transform_adata_with_NMF:
#    input:
#        "output/quantification/bins/adata_annotated.h5ad"
#    output:
#        "output/quantification/bins-nmf/adata_annotated.h5ad"
#    run:
#        original_adata = anndata.read_h5ad(input[0])
#        cluster_gene_id_map = original_adata.var.groupby("cluster").gene_id.first()
#        clusters = []
#        gene_ids = []
#        Xs = []
#        n_clusters = len(pd.unique(original_adata.var.cluster))
#        print("n_clusters: ", n_clusters)
#        new_cluster = 0
#        for cluster in pd.unique(original_adata.var.cluster):
#            print(cluster)
#            gene_id = cluster_gene_id_map.loc[cluster]
#            idx_features = np.where(original_adata.var.cluster==cluster)[0]
#            X = original_adata.X[:, idx_features].toarray()
#            for n_components in [2, 5, 10]:
#                X_NMF = NMF(n_components=n_components, max_iter=10000, solver="mu", beta_loss="frobenius").fit_transform(X)
#                n_cells, n_features = X_NMF.shape
#                Xs.append(X_NMF)
#                clusters.append(np.full(n_features, new_cluster))
#                new_cluster += 1
#                gene_ids.append(np.full(n_features, gene_id))
#        X = np.hstack(Xs)
#        clusters = np.concatenate(clusters)
#        gene_ids = np.concatenate(gene_ids)
#        var = pd.DataFrame(dict(cluster=clusters,gene_id=gene_ids))
#        print(var)
#        adata = anndata.AnnData(X=X, var=var, obs=original_adata.obs)
#        print(adata.shape)
#        print("new n_clusters: ", adata.var.cluster.unique().shape)
#        adata.write(output[0])
#
#
#rule process_encode_blacklist:
#    input:
#        encode_blacklist_path
#    output:
#        "output/encode_blacklist.bed"
#    shell:
#        "set +o pipefail; cut -f1-3 {input} | bedtools sort -i stdin | uniq > {output}"
#
#
#rule filter_bam:
#    input:
#        "output/mapping/mapping_second_pass/{sample_id}/Aligned.rmdup.out.bam",
#        "output/encode_blacklist.bed"
#    output:
#        protected("output/mapping/filtered_bams/{sample_id}.bam"),
#    shell:
#        "bedtools intersect -split -sorted -a {input[0]} -b {input[1]} -v > {output}"
#
#
#rule index_bam:
#    input:
#        "output/mapping/filtered_bams/{sample_id}.bam",
#    output:
#        "output/mapping/filtered_bams/{sample_id}.bam.bai"
#    shell:
#        "samtools index {input}"
#
#
#rule make_bam_paths:
#    input:
#        expand("output/mapping/filtered_bams/{sample_id}.bam.bai", sample_id=sample_ids),
#    output:
#        "output/bam_paths.txt",
#    run:
#        cwd = os.getcwd()
#        pd.DataFrame(dict(
#            sample_id=sample_ids,
#            bam_path=[f"{cwd}/output/mapping/filtered_bams/{sample_id}.bam"
#                      for sample_id in sample_ids])
#        ).to_csv(output[0], "\t", index=False, header=False)
#

#rule make_bam_paths_subset:
#    input:
#        expand("output/mapping/filtered_bams/{sample_id}.bam", sample_id=sample_ids_subset),
#    output:
#        "output/bam_paths_subset.txt",
#    run:
#        cwd = os.getcwd()
#        pd.DataFrame(dict(
#            sample_id=sample_ids_subset,
#            bam_path=[f"{cwd}/output/mapping/filtered_bams/{sample_id}.bam"
#                      for sample_id in sample_ids_subset])
#        ).to_csv(output[0], "\t", index=False, header=False)
#
#
#rule prepare_chromosomes_file:
#    input:
#        full_gtf_path
#    output:
#        "output/chromosomes.txt"
#    shell:
#        "cut -f1 {input} | grep -v \# | grep -v GL | grep -v JH | sort | uniq > {output}"
#
#
#rule add_metadata:
#    input:
#        "output/quantification/{quantification}/adata.h5ad",
#    output:
#        "output/quantification/{quantification,gene-expression|leafcutter|kallisto-SE|exons|bins|kallisto|introns-gene|introns-shared-acceptor|introns-nontransitive|introns-transitive}/adata_annotated.h5ad",
#    run:
#        adata = anndata.read_h5ad(input[0])
#        print(adata.obs)
#        adata.obs = sample_info.loc[adata.obs.index.values]
#        print(adata.obs)
#        adata.write(output[0], compression="gzip")
#
#
#rule make_bam_paths_plate:
#    input:
#        expand("output/mapping/filtered_bams/{sample_id}.bam", sample_id=sample_ids)
#    output:
#        "output/bam_paths_{plate}.txt",
#    run:
#        s_ids = sample_ids[np.where(sample_info.plate_id==wildcards["plate"])[0]]
#        print(wildcards["plate"], len(s_ids))
#        cwd = os.getcwd()
#        pd.DataFrame(dict(sample_id=s_ids, bam_path=[f"{cwd}/output/mapping/filtered_bams/{sample_id}.bam" for sample_id in s_ids])).to_csv(output[0], "\t", index=False, header=False)
#
#
#rule make_coverage_track_bigwig_plate:
#    input:
#        "output/bam_paths_{plate}.txt",
#    output:
#        "output/coverage_track/plate/{plate}/coverage.bw",
#    threads: workflow.cores // 4
#    shell:
#        "python -m scquint.quantification.run coverage_track/Snakefile --cores {threads} -d output/coverage_track/plate/{wildcards.plate}/ --config bam_paths=../../../bam_paths_{wildcards.plate}.txt chrom_sizes_path={chrom_sizes_path}"
#
#
#rule intron_quantification:
#    input:
#        "output/bam_paths.txt",
#        "output/chromosomes.txt",
#        full_gtf_path,
#        sjdb_path,
#        chrom_sizes_path
#    threads: workflow.cores
#    output:
#        "output/quantification/introns/output/introns-shared-acceptor/adata.h5ad",
#    shell:
#        "python -m scquint.quantification.run introns/Snakefile -q --cores {threads} -d output/quantification/introns/ --config min_cells_per_intron=100 bam_paths=../../bam_paths.txt chromosomes_path=../../chromosomes.txt fasta_path={genome_fasta_path} gtf_path={full_gtf_path} chrom_sizes_path={chrom_sizes_path} sjdb_path={sjdb_path}"
#
#
#rule extract_intron_quantification:
#    input:
#        "output/quantification/introns/output/introns-{grouping}/adata.h5ad"
#    output:
#        "output/quantification/introns-{grouping}/adata.h5ad"
#    shell:
#        "cp {input} {output}"
#

#rule gene_expression_quantification:
#    input:
#        "output/bam_paths.txt",
#        full_gtf_path,
#    threads: workflow.cores
#    output:
#        "output/quantification/gene-expression/adata.h5ad"
#    shell:
#        "python -m scquint.quantification.run genes/Snakefile --cores all -q -d output/quantification/gene-expression/ --config min_cells_per_gene=100 gtf_path={full_gtf_path} bam_paths=../../bam_paths.txt"
#
#
#rule differential_test_mg_basal_individual_plate:
#    input:
#        "output/quantification/{quantification}/adata_annotated.h5ad",
#    output:
#        'output/differential_splicing/mg_basal_individual_plate/{individual}/{quantification}/splicing.clusters.csv',
#        'output/differential_splicing/mg_basal_individual_plate/{individual}/{quantification}/splicing.introns.csv',
#    run:
#        print("threads: ", threads)
#        obs = sample_info[
#            (sample_info.tissue=="Mammary_Gland") &
#            (sample_info.cell_ontology_class=="basal cell") &
#            (sample_info["mouse.id"]==wildcards["individual"])
#        ].sort_index()
#        adata = anndata.read_h5ad(input[0])
#        adata = adata[obs.index.values]
#        plates = obs.plate_id.unique()
#        print(plates)
#        #assert(len(plates)==2)
#        #cell_idx_a = np.where(
#        #    (obs.plate_id==plates[0])
#        #)[0]
#        #cell_idx_b = np.where(
#        #    (obs.plate_id!=plates[0])
#        #)[0]
#        print("hardcoding B002438")
#        cell_idx_a = np.where(
#            (obs.plate_id=="B002438")
#        )[0]
#        cell_idx_b = np.where(
#            (obs.plate_id!="B002438")
#        )[0]
#
#        permute = False
#        if permute:
#            cell_idx_all = np.concatenate([cell_idx_a, cell_idx_b])
#            cell_idx_all_p = np.random.permutation(cell_idx_all)
#            cell_idx_a_p = cell_idx_all_p[:len(cell_idx_a)]
#            cell_idx_b_p = cell_idx_all_p[len(cell_idx_a):]
#            cell_idx_a = cell_idx_a_p
#            cell_idx_b = cell_idx_b_p
#
#        if wildcards["quantification"] != "gene-expression":
#            adata.var["original_cluster"] = adata.var.cluster
#            diff_spl_clusters, diff_spl_introns = run_differential_splicing(
#                adata,
#                "permutation-Euclidean",
#                cell_idx_a,
#                cell_idx_b,
#                min_cells_per_cluster=30 if wildcards["quantification"] != "bins-nmf" else None,
#                min_total_cells_per_intron=30 if wildcards["quantification"] != "bins-nmf" else None,
#                device="cuda:0",
#                #device="cpu",
#                n_permutations=100000,
#               )
#            diff_spl_clusters.to_csv(output[0], '\t')
#            diff_spl_introns.to_csv(output[1], '\t')
#        else:
#            diff_exp = run_differential_expression(adata, cell_idx_a, cell_idx_b, 30)
#            diff_exp.to_csv(output[0], '\t', index=False)
#            diff_exp.to_csv(output[1], '\t', index=False)
#
#
#rule make_bam_paths_mg_basal_individual_plate:
#    input:
#        "output/bam_paths.txt",
#    output:
#        "output/bam_paths/mg_basal_individual_{individual}_{plate}.txt",
#    run:
#        s_ids = sample_ids[
#            np.where(
#                (sample_info.tissue=="Mammary_Gland") &
#                (sample_info.cell_ontology_class=="basal cell") &
#                (sample_info["mouse.id"]==wildcards["individual"]) &
#                (sample_info.plate_id==wildcards["plate"])
#            )[0]
#        ]
#        print(wildcards["plate"], len(s_ids))
#        cwd = os.getcwd()
#        pd.DataFrame(dict(sample_id=s_ids, bam_path=[f"{cwd}/output/mapping/filtered_bams/{sample_id}.bam" for sample_id in s_ids])).to_csv(output[0], "\t", index=False, header=False)
#
#
#rule make_coverage_track_bigwig_mg_basal_individual_plate:
#    input:
#        "output/bam_paths/mg_basal_individual_{individual}_{plate}.txt",
#    output:
#        "output/coverage_track/mg_basal_individual_plate/{individual}/{plate}/coverage.bw",
#    threads: workflow.cores // 4
#    shell:
#        "python -m scquint.quantification.run coverage_track/Snakefile --cores {threads} -d output/coverage_track/mg_basal_individual_plate/{wildcards.individual}/{wildcards.plate}/ --config bam_paths=../../../../bam_paths/mg_basal_individual_{wildcards.individual}_{wildcards.plate}.txt chrom_sizes_path={chrom_sizes_path}"
#
#
#rule dimensionality_reduction_mg_pca:
#    input:
#        "output/quantification/{quantification}/adata_annotated.h5ad",
#    output:
#        "output/dimensionality_reduction/mg/{quantification}/pca_{min_cells}_{k}/latent.txt",
#    wildcard_constraints: quantification='.+(?<!gene-expression)'
#    run:
#        adata = anndata.read_h5ad(input[0])
#        adata = adata[(adata.obs.tissue=="Mammary_Gland")]
#        sorted_index = sorted(adata.obs.index)
#        adata = adata[sorted_index]
#        if wildcards["quantification"] != "bins-nmf":
#            adata = filter_min_cells_per_feature(adata, int(wildcards["min_cells"]))
#        print(adata.shape)
#        if wildcards["quantification"] == "introns-transitive" or wildcards["quantification"] == "leafcutter":
#            adata = recluster(adata)
#        print(adata.shape)
#        latent = run_pca(adata, int(wildcards["k"]))
#        np.savetxt(output[0], latent)
#
#
#rule dimensionality_reduction_mg_vae:
#    input:
#        "output/quantification/{quantification}/adata_annotated.h5ad",
#    output:
#        "output/dimensionality_reduction/mg/{quantification}/vae_{n_cells}/latent.txt",
#    wildcard_constraints: quantification='.+(?<!gene-expression)'
#    resources:
#        gpu=1
#    run:
#        adata = anndata.read_h5ad(input[0])
#        adata = adata[(adata.obs.tissue=="Mammary_Gland")]
#        sorted_index = sorted(adata.obs.index)
#        adata = adata[sorted_index]
#        if wildcards["quantification"] != "bins-nmf":
#            adata = filter_min_cells_per_feature(adata, int(wildcards["n_cells"]))
#        if np.isin(wildcards["quantification"], ["introns-transitive", "introns-transitive-shuffled", "leafcutter", "introns-subset-lc", "introns-subset-lc-nonfiltered"]):
#            adata = recluster(adata)
#        print(wildcards["quantification"], adata.shape)
#        feature_addition = group_normalize(adata.X.sum(axis=0), adata.var.cluster, smooth=False).A1.ravel()
#
#        latent, model = run_vae(
#            adata, n_epochs_kl_warmup=30, regularization_gaussian_std=10.0,
#            use_cuda=True, input_transform="frequency-smoothed",
#            feature_addition=feature_addition, sample=False,
#        )
#        np.savetxt(output[0], latent)
#
#rule dimensionality_reduction_mg_expression:
#    input:
#        "output/quantification/gene-expression/adata_annotated.h5ad",
#    output:
#        "output/dimensionality_reduction/mg/gene-expression/pca_{min_cells}_{k}/latent.txt",
#    run:
#        adata = anndata.read_h5ad(input[0])
#        adata = adata[(adata.obs.tissue=="Mammary_Gland")]
#        sorted_index = sorted(adata.obs.index)
#        adata = adata[sorted_index]
#        sc.pp.filter_genes(adata, min_cells=int(wildcards["min_cells"]))
#        sc.pp.normalize_total(adata, target_sum=1e4)
#        sc.pp.log1p(adata)
#        X = adata.X.toarray()
#        latent = PCA(n_components=int(wildcards["k"])).fit_transform(X)
#        np.savetxt(output[0], latent)
#
#
#rule dimensionality_reduction_mg_3_38_F_pca:
#    input:
#        "output/quantification/{quantification}/adata_annotated.h5ad",
#    output:
#        "output/dimensionality_reduction/mg_3_38_F/{quantification}/pca_{k}/latent.txt",
#    wildcard_constraints: quantification='.+(?<!gene-expression)'
#    run:
#        adata = anndata.read_h5ad(input[0])
#        adata = adata[(adata.obs.tissue=="Mammary_Gland") & (adata.obs["mouse.id"]=="3_38_F")]
#        sorted_index = sorted(adata.obs.index)
#        adata = adata[sorted_index]
#        if wildcards["quantification"] != "bins-nmf":
#            adata = filter_min_cells_per_feature(adata, 50)
#        print(adata.shape)
#        latent = run_pca(adata, int(wildcards["k"]))
#        np.savetxt(output[0], latent)
#
#
#rule dimensionality_reduction_mg_3_38_F_expression:
#    input:
#        "output/quantification/gene-expression/adata_annotated.h5ad",
#    output:
#        "output/dimensionality_reduction/mg_3_38_F/gene-expression/pca_{k}/latent.txt",
#    run:
#        adata = anndata.read_h5ad(input[0])
#        adata = adata[(adata.obs.tissue=="Mammary_Gland") & (adata.obs["mouse.id"]=="3_38_F")]
#        sorted_index = sorted(adata.obs.index)
#        adata = adata[sorted_index]
#        sc.pp.filter_genes(adata, min_cells=50)
#        sc.pp.normalize_total(adata, target_sum=1e4)
#        sc.pp.log1p(adata)
#        X = adata.X.toarray()
#        latent = PCA(n_components=int(wildcards["k"])).fit_transform(X)
#        np.savetxt(output[0], latent)
#
#
#rule dimensionality_reduction_all_pca:
#    input:
#        "output/quantification/{quantification}/adata_annotated.h5ad",
#    output:
#        "output/dimensionality_reduction/all/{quantification}/pca_{n_cells}_{k}/latent.txt",
#    wildcard_constraints: quantification='.+(?<!gene-expression)'
#    run:
#        adata = anndata.read_h5ad(input[0])
#        if wildcards["quantification"] != "bins-nmf":
#            adata = filter_min_cells_per_feature(adata, int(wildcards["n_cells"]))
#        print(adata.shape)
#        if wildcards["quantification"] == "introns-transitive" or wildcards["quantification"] == "leafcutter":
#            adata = recluster(adata)
#        print(adata.shape)
#        latent = run_pca(adata, int(wildcards["k"]))
#        print("latent.shape: ", latent.shape)
#        np.savetxt(output[0], latent)
#
#
#rule dimensionality_reduction_all_vae:
#    input:
#        "output/quantification/{quantification}/adata_annotated.h5ad",
#    output:
#        "output/dimensionality_reduction/all/{quantification}/vae_{transform}_{sample}_{min_cells}/latent.txt",
#    wildcard_constraints: quantification='.+(?<!gene-expression)'
#    resources:
#        gpu=1
#    run:
#        adata = anndata.read_h5ad(input[0])
#        if wildcards["quantification"] != "bins-nmf":
#            adata = filter_min_cells_per_feature(adata, int(wildcards["min_cells"]))
#        if np.isin(wildcards["quantification"], ["introns-transitive", "introns-transitive-shuffled", "leafcutter", "introns-subset-lc", "introns-subset-lc-nonfiltered"]):
#            adata = recluster(adata)
#        print(wildcards["quantification"], adata.shape)
#        input_transform = wildcards["transform"]
#        if input_transform == "frequency-smoothed":
#            feature_addition = group_normalize(adata.X.sum(axis=0), adata.var.cluster, smooth=False).A1.ravel()
#            print(feature_addition.shape)
#        else:
#            feature_addition = None
#        latent, model = run_vae(
#            adata, n_epochs_kl_warmup=30, regularization_gaussian_std=None,
#            use_cuda=True, input_transform=input_transform,
#            feature_addition=feature_addition, sample=wildcards["sample"]=="True" or wildcards["sample"]=="true",
#        )
#        np.savetxt(output[0], latent)
#
#
#rule dimensionality_reduction_all_vae_hyperopt:
#    input:
#        "output/quantification/{quantification}/adata_annotated.h5ad",
#    output:
#        "output/dimensionality_reduction/all/{quantification}/vae_hyperopt/latent.txt",
#    wildcard_constraints: quantification='.+(?<!gene-expression)'
#    resources:
#        gpu=1
#    run:
#        adata = anndata.read_h5ad(input[0])
#        if wildcards["quantification"] != "bins-nmf":
#            adata = filter_min_cells_per_feature(adata, 100)
#        if np.isin(wildcards["quantification"], ["introns-transitive", "introns-transitive-shuffled", "leafcutter", "introns-subset-lc", "introns-subset-lc-nonfiltered"]):
#            adata = recluster(adata)
#        print(wildcards["quantification"], adata.shape)
#        feature_addition = group_normalize(adata.X.sum(axis=0), adata.var.cluster, smooth=False).A1.ravel()
#
#        latent, model = run_vae(
#            adata, n_epochs_kl_warmup=20, regularization_gaussian_std=None,
#            use_cuda=True, input_transform="frequency-smoothed",
#            feature_addition=feature_addition, sample=False, linearity="non-linear",
#            n_layers=2, n_latent=34, dropout_rate=0.224,
#        )
#        np.savetxt(output[0], latent)
#
#
#rule dimensionality_reduction_all_expression:
#    input:
#        "output/quantification/gene-expression/adata_annotated.h5ad",
#    output:
#        "output/dimensionality_reduction/all/gene-expression/pca_{k}/latent.txt",
#    run:
#        adata = anndata.read_h5ad(input[0])
#        print(adata.shape)
#        sc.pp.filter_genes(adata, min_cells=100)
#        print(adata.shape)
#        sc.pp.normalize_total(adata, target_sum=1e4)
#        sc.pp.log1p(adata)
#        sc.pp.highly_variable_genes(adata)
#        adata = adata[:, adata.var.highly_variable]
#        print(adata.shape)
#
#        X = adata.X.toarray()
#        latent = PCA(n_components=int(wildcards["k"])).fit_transform(X)
#        np.savetxt(output[0], latent)
#
#
#rule dimensionality_reduction_all_joint_pca:
#    input:
#        "output/quantification/gene-expression/adata_annotated.h5ad",
#        "output/quantification/introns-shared-acceptor/adata_annotated.h5ad",
#    output:
#        "output/dimensionality_reduction/all/joint/pca_{k}/latent.txt",
#    run:
#        adata_exp = anndata.read_h5ad(input[0])
#        sc.pp.filter_genes(adata_exp, min_cells=100)
#        sc.pp.normalize_total(adata_exp, target_sum=1e4)
#        sc.pp.log1p(adata_exp)
#        X_exp = adata_exp.X.toarray()
#
#        adata_spl = anndata.read_h5ad(input[1])
#        adata_spl = filter_min_cells_per_feature(adata_spl, 100)
#        X_spl = group_normalize(adata_spl.X.toarray(), adata_spl.var.cluster.values, smooth=True)
#        intron_clusters = adata_spl.var.cluster.values
#        all_intron_clusters = np.unique(intron_clusters)
#        first_indices_dict = {}
#        for i, c in enumerate(intron_clusters):
#            if c not in first_indices_dict:
#                first_indices_dict[c] = i
#        first_indices = np.array([first_indices_dict[c] for c in all_intron_clusters])
#        X_spl = np.delete(X_spl, first_indices, axis=1)
#
#        #X = np.hstack([X_exp, X_spl])
#        X = X_spl
#        print(X_exp.shape, X_spl.shape, X.shape)
#
#        adata = anndata.AnnData(X=X, obs=adata_exp.obs)
#        print(adata.shape)
#        print(adata.var)
#        sc.pp.highly_variable_genes(adata)
#        adata = adata[:, adata.var.highly_variable]
#        print(adata.shape)
#        print(adata.var)
#        X = adata.X
#
#        latent = PCA(n_components=int(wildcards["k"])).fit_transform(X)
#        np.savetxt(output[0], latent)
#
#
#rule dimensionality_reduction_brain_pca:
#    input:
#        "output/quantification/{quantification}/adata_annotated.h5ad",
#    output:
#        "output/dimensionality_reduction/brain/{quantification}/pca_{k}/latent.txt",
#    wildcard_constraints: quantification='.+(?<!gene-expression)'
#    run:
#        adata = anndata.read_h5ad(input[0])
#        adata = adata[(adata.obs.tissue=="Brain_Non-Myeloid")]
#        sorted_index = sorted(adata.obs.index)
#        adata = adata[sorted_index]
#        if wildcards["quantification"] != "bins-nmf":
#            adata = filter_min_cells_per_feature(adata, 100)
#        print(adata.shape)
#        latent = run_pca(adata, int(wildcards["k"]))
#        np.savetxt(output[0], latent)
#
#
#rule dimensionality_reduction_brain_expression:
#    input:
#        "output/quantification/gene-expression/adata_annotated.h5ad",
#    output:
#        "output/dimensionality_reduction/brain/gene-expression/pca_{k}/latent.txt",
#    run:
#        adata = anndata.read_h5ad(input[0])
#        adata = adata[(adata.obs.tissue=="Brain_Non-Myeloid")]
#        sorted_index = sorted(adata.obs.index)
#        adata = adata[sorted_index]
#        sc.pp.filter_genes(adata, min_cells=100)
#        sc.pp.normalize_total(adata, target_sum=1e4)
#        sc.pp.log1p(adata)
#        X = adata.X.toarray()
#        latent = PCA(n_components=int(wildcards["k"])).fit_transform(X)
#        np.savetxt(output[0], latent)
#
#
#rule filter_bam_to_region:
#    input:
#        "output/mapping/filtered_bams/{sample_id}.bam"
#    output:
#        "output/bam_regions/{gene}/{sample_id}.bam"
#    run:
#        chromosome, start, end = genes_bam_merge[wildcards["gene"]]["region"]
#        #shell(f"bamtools filter -region {chromosome}:{start}..{end} -in {input} -out {output}")
#        shell(f"samtools view -b -o {output} {input} {chromosome}:{start}-{end}")
#
#
#rule make_bam_paths_gene:
#    input:
#        lambda wildcards: expand(f"output/bam_regions/{wildcards['gene']}/{{sample_id}}.bam", sample_id=sample_ids[(sample_info.cell_type==wildcards["cell_type"])])
#    output:
#        "output/bam_paths-{gene}-{cell_type}.txt"
#    run:
#        pd.DataFrame(input).to_csv(output[0], "\t", index=False, header=False)
#
#
#rule merge_bams:
#    input:
#        "output/bam_paths-{gene}-{cell_type}.txt"
#    output:
#        "output/bam_regions/{gene}/{cell_type}/merged.bam"
#    threads:
#        workflow.cores
#    priority: 10
#    shell:
#        "samtools merge --threads {threads} -b {input} {output}"
#
#
#rule differential_test_tissue_cell_type:
#    input:
#        "output/quantification/gene-expression/adata_annotated.h5ad",
#        #"output/quantification/introns-transitive/adata_annotated.h5ad",
#        "output/quantification/introns-shared-acceptor/adata_annotated.h5ad",
#    output:
#        'output/differential_splicing/tissue_cell_type/{tissue}/{cell_type}/expression.tsv',
#        'output/differential_splicing/tissue_cell_type/{tissue}/{cell_type}/splicing.clusters.tsv',
#        'output/differential_splicing/tissue_cell_type/{tissue}/{cell_type}/splicing.introns.tsv',
#    threads: workflow.cores // 4
#    #threads: workflow.cores
#    run:
#        adata_exp = anndata.read_h5ad(input[0])
#        adata_exp.obs.index = adata_exp.obs.index.astype(str)
#        adata_spl = anndata.read_h5ad(input[1])
#        adata_spl.obs.index = adata_spl.obs.index.astype(str)
#        adata_spl.var.index = adata_spl.var.index.astype(str)
#        assert((adata_exp.obs.index == adata_spl.obs.index).all())
#        obs = adata_exp.obs
#        obs.loc[:, "cell_type"] = obs.cell_ontology_class.str.replace(" ", "_").str.replace("-", "_")
#        cell_idx_a = np.where((obs.tissue==wildcards["tissue"]) &
#                              (obs.cell_type==wildcards["cell_type"]))[0]
#        cell_idx_b = np.where((obs.tissue==wildcards["tissue"]) &
#                              (obs.cell_type!=wildcards["cell_type"]) &
#                              (obs.cell_type.isin([ct for t, ct in tissue_cell_type_pairs if t==wildcards["tissue"]])))[0]
#        MIN_FEATURES = 50
#        diff_exp = run_differential_expression(adata_exp, cell_idx_a, cell_idx_b, MIN_FEATURES)
#        diff_exp.to_csv(output[0], '\t', index=False)
#        diff_spl_clusters, diff_spl_introns = run_differential_splicing(
#            adata_spl,
#            cell_idx_a,
#            cell_idx_b,
#            min_cells_per_cluster=MIN_FEATURES,
#            min_total_cells_per_intron=MIN_FEATURES,
#            n_jobs=threads,
#            do_recluster=False,
#        )
#        diff_spl_clusters.to_csv(output[1], '\t')
#        diff_spl_introns.to_csv(output[2], '\t')
#
#
#rule extract_gene_cds:
#    input:
#        full_gtf_path
#    output:
#        "output/gene_cds.txt"
#    run:
#        df = pd.read_csv(
#            input[0], '\t', header=None, comment="#",
#            names=['chromosome', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attribute'],
#           )
#        print(df.shape)
#        df = df[df.feature=="CDS"]
#        print(df.shape)
#        df['gene_id'] = df.attribute.str.extract(r'gene_id "([^;]*)";')
#        res = df.groupby("gene_id").agg({"chromosome": "first", "start": "min", "end": "max", "strand": "first"})
#        print(res)
#        res.to_csv(output[0], "\t")
#
#
#rule extract_gene_name:
#    input:
#        full_gtf_path
#    output:
#        "output/gene_name.txt"
#    run:
#        df = pd.read_csv(
#            input[0], '\t', header=None, comment="#",
#            names=['chromosome', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attribute'],
#           )
#        print(df.shape)
#        df = df[df.feature=="gene"]
#        print(df.shape)
#        df['gene_id'] = df.attribute.str.extract(r'gene_id "([^;]*)";')
#        df['gene_name'] = df.attribute.str.extract(r'gene_name "([^;]*)";')
#        res = df.groupby("gene_id").gene_name.first()
#        print(res)
#        res.to_csv(output[0], "\t")
#
#
#rule filter_diff_spl_significant:
#    input:
#        'output/{anything}/expression.tsv',
#        'output/{anything}/splicing.clusters.tsv',
#        'output/{anything}/splicing.introns.tsv',
#        "output/gene_cds.txt",
#        "output/gene_name.txt",
#    output:
#        'output/{anything}/splicing.clusters.significant.tsv',
#    run:
#        diff_exp = pd.read_csv(input[0], "\t", index_col=0)
#        diff_spl_cluster = pd.read_csv(input[1], "\t", index_col=0)
#        diff_spl_intron = pd.read_csv(input[2], "\t", index_col=0)
#        gene_cds = pd.read_csv(input[3], "\t", index_col=0)
#        gene_name = pd.read_csv(input[4], "\t", index_col=0)
#
#        assert(set(diff_spl_cluster.index.values) == set(diff_spl_intron.cluster.unique()))
#
#        print(diff_spl_cluster.shape)
#        diff_spl_cluster = diff_spl_cluster[
#            ((diff_spl_cluster.p_value_adj <= config["fdr"]) &
#             (diff_spl_cluster.max_abs_delta_psi >= config["min_abs_delta_psi"]))
#        ]
#        print(diff_spl_cluster.shape)
#        diff_spl_cluster = diff_spl_cluster.merge(gene_name, how="left", left_on="gene_id", right_index=True)
#        print(diff_spl_cluster.shape)
#        def max_abs_lfc_psi_unannotated(row_cluster):
#            introns = diff_spl_intron[diff_spl_intron.cluster==row_cluster.name]
#            return (introns.abs_lfc_psi * (~introns.annotated).astype(int)).max()
#        diff_spl_cluster["max_abs_lfc_psi_unannotated"] = diff_spl_cluster.apply(max_abs_lfc_psi_unannotated, axis=1)
#        def max_abs_delta_psi_unannotated(row_cluster):
#            introns = diff_spl_intron[diff_spl_intron.cluster==row_cluster.name]
#            return (introns.abs_delta_psi * (~introns.annotated).astype(int)).max()
#        diff_spl_cluster["max_abs_delta_psi_unannotated"] = diff_spl_cluster.apply(max_abs_delta_psi_unannotated, axis=1)
#        diff_spl_cluster["Annotated"] = diff_spl_cluster.max_abs_delta_psi_unannotated < config["min_abs_delta_psi"]
#
#        #coordinates = diff_spl_intron.groupby("cluster").agg({"chromosome": "first", "start": "unique", "end": "unique"})
#        #diff_spl_cluster = diff_spl_cluster.merge(coordinates, how="left", left_index=True, right_index=True)
#
#        print(diff_spl_cluster.Annotated.value_counts())
#        def get_diff_exp_rank(row_cluster):
#            try:
#                return diff_exp.loc[row_cluster.gene_id].ranking
#            except KeyError:
#                return np.nan
#        diff_spl_cluster["diff_exp_rank"] = diff_spl_cluster.apply(get_diff_exp_rank, axis=1)
#        def check_region(row_cluster):
#            try:
#                cds = gene_cds.loc[row_cluster.gene_id]
#            except KeyError:
#                return "Non-coding"
#            introns = diff_spl_intron[diff_spl_intron.cluster==row_cluster.name]
#            cluster_start = introns.start.min()
#            cluster_end = introns.end.max()
#            if cds.strand == "+":
#                if cluster_start < cds.start:
#                    return "5' UTR"
#                if cluster_start < cds.end:
#                    return "CDS"
#                return "3' UTR"
#            elif cds.strand == "-":
#                if cluster_start < cds.start:
#                    return "3' UTR"
#                if cluster_start < cds.end:
#                    return "CDS"
#                return "5' UTR"
#            else:
#                raise Exception("strand not implemented")
#        diff_spl_cluster["Region"] = diff_spl_cluster.apply(check_region, axis=1)
#        diff_spl_cluster.max_abs_delta_psi = diff_spl_cluster.max_abs_delta_psi.round(decimals=3)
#
#        diff_spl_cluster.to_csv(
#            output[0], "\t",
#            #columns=["gene_id", "gene_name", "p_value_adj", "max_abs_delta_psi", "Annotated", "Region", "diff_exp_rank", "p_value", "chromosome", "start", "end"],
#            columns=["gene_id", "gene_name", "p_value", "p_value_adj", "max_abs_delta_psi", "Annotated", "Region", "diff_exp_rank"],
#        )
#
#
#rule merge_significant:
#    input:
#        lambda wildcards: expand('output/differential_splicing/tissue_cell_type/{{tissue}}/{cell_type}/splicing.clusters.significant.tsv', cell_type=[ct for t, ct in tissue_cell_type_pairs if t==wildcards["tissue"]])
#    output:
#        "output/differential_splicing/tissue_cell_type/{tissue}/merged_significant.tsv",
#    run:
#        dfs = []
#        for cell_type, input_path in zip([ct for t, ct in tissue_cell_type_pairs if t==wildcards["tissue"]], input):
#            df = pd.read_csv(input_path, "\t")
#            df["Cell type"] = cell_type.replace("_", " ")
#            dfs.append(df)
#        df = pd.concat(dfs, ignore_index=True)
#        df = df.sort_values("p_value_adj")
#        df.to_csv(output[0], "\t", index=False)
#
#
#rule plot_significant:
#    input:
#        "output/differential_splicing/tissue_cell_type/{tissue}/merged_significant.tsv",
#    output:
#        "output/differential_splicing/tissue_cell_type/{tissue}/merged_significant_all.svg",
#        "output/differential_splicing/tissue_cell_type/{tissue}/merged_significant_aggregate.svg",
#        #"output/differential_splicing/tissue_cell_type/{tissue}/merged_significant_5p.pdf",
#        #"output/differential_splicing/tissue_cell_type/{tissue}/merged_significant_cds.pdf",
#        #"output/differential_splicing/tissue_cell_type/{tissue}/merged_significant_3p.pdf",
#    run:
#        df_all = pd.read_csv(input[0], "\t")
#        df_all["Type"] = df_all.Annotated
#        df_all.Type = df_all.Type.replace(True, "Annotated").replace(False, "Novel")
#        df_all.Region = df_all.Region.replace("Non-coding", "Non-coding RNA")
#
#        def plot_counts(df, output_path):
#            df_plot = df.groupby(["Type", "Cell type"]).size().reset_index().pivot(columns='Type', index='Cell type', values=0)
#            g = df_plot.plot(kind='bar', stacked=True)
#            g.set_xticklabels(g.get_xticklabels(), rotation=45, horizontalalignment='right')
#            g.set(xlabel="", ylabel='Diff. spl. events')
#            #g.despine(left=True)
#            sns.despine()
#            plt.legend(loc='upper right')
#            plt.savefig(output_path, bbox_inches='tight')
#            plt.close()
#        plot_counts(df_all, output[0])
#        #plot_counts(df_all[df_all.Region=="5' UTR"], output[1])
#        #plot_counts(df_all[df_all.Region=="Coding region"], output[2])
#        #plot_counts(df_all[df_all.Region=="3' UTR"], output[3])
#        df = df_all
#        df_plot = df.groupby(["Type", "Region"]).size().reset_index().pivot(columns='Type', index='Region', values=0).loc[["5' UTR", "CDS", "3' UTR", "Non-coding RNA"]]
#        g = df_plot.plot(kind='bar', stacked=True)
#        g.set_xticklabels(g.get_xticklabels(), rotation=45, horizontalalignment='right')
#        g.set(xlabel="", ylabel='Diff. spl. events')
#        sns.despine()
#        plt.legend(loc='upper right')
#        plt.savefig(output[1], bbox_inches='tight')
#
#
#rule compare_latent_custom_plot:
#    input:
#        #expand("output/dimensionality_reduction/mg/{quantification}/pca_50_10/latent.txt", quantification=quantifications_mg_individual_expanded),
#        "output/dimensionality_reduction/mg/gene-expression/pca_50_10/latent.txt",
#        "output/dimensionality_reduction/mg/kallisto/vae_30/latent.txt",
#        "output/dimensionality_reduction/mg/bins/vae_30/latent.txt",
#        "output/dimensionality_reduction/mg/exons/vae_30/latent.txt",
#        "output/dimensionality_reduction/mg/introns-gene/vae_30/latent.txt",
#        "output/dimensionality_reduction/mg/leafcutter/vae_30/latent.txt",
#        "output/dimensionality_reduction/mg/introns-shared-acceptor/vae_30/latent.txt",
#        #"output/dimensionality_reduction/mg/leafcutter/pca_30_10/latent.txt",
#        #"output/dimensionality_reduction/mg/leafcutter/vae_30/latent.txt",
#        #"output/dimensionality_reduction/mg/leafcutter/vae_50/latent.txt",
#        #"output/dimensionality_reduction/mg/introns-shared-acceptor/pca_30_10/latent.txt",
#        #"output/dimensionality_reduction/mg/introns-shared-acceptor/vae_30/latent.txt",
#        #"output/dimensionality_reduction/mg/introns-shared-acceptor/vae_50/latent.txt",
#        #"output/dimensionality_reduction/mg/leafcutter/vae_100/latent.txt",
#    output:
#        #"output/comparison/mg_3_38_F/cell_ontology_class.svg",
#        "output/comparison/mg_{individual}/cell_ontology_class.svg",
#        "output/comparison/mg_{individual}/plate.svg",
#    run:
#        obs = sample_info[(sample_info.tissue=="Mammary_Gland")]
#        obs = obs.sort_index()
#        idx = np.where((obs["mouse.id"]==wildcards["individual"]) & (obs.cell_ontology_class!="endothelial cell"))[0]
#        obs = obs.iloc[idx]
#        obs["Cell type"] = obs.cell_ontology_class
#        obs["Plate ID"] = obs.plate_id
#        dfs = []
#        #names = ["Leafcutter-PCA", "LeafCutter-VAE", "LeafCutter-Ours-PCA", "LeafCutter-Ours-VAE", "SharedAcceptor-PCA", "SharedAcceptor-VAE"]
#        #names = ["Leafcutter", "SharedAcceptor", "AnnotatedSE", "AnnotatedSE-SharedAcceptor", "AnnotatedSE-SharedDonor"]
#        names = ["Gene expression", "kallisto", "ODEGR-NMF", "DEXSeq", "DESJ", "LeafCutter", "scQuint"]
#        #names = ["LeafCutter-VAE-30", "LeafCutter-VAE-50", "LeafCutter-VAE-100"]
#        #names = ["LeafCutter-VAE-30", "LeafCutter-VAE-50", "scQuint-VAE-30", "scQuint-VAE-50"]
#        #names = ["LeafCutter-PCA", "LeafCutter-VAE", "scQuint-PCA", "scQuint-VAE"]
#        for name, input_path in zip(names, input):
#            print(name)
#            #if name == "gene-expression":
#            #    #name = "Gene expression \n (featureCounts)"
#            #    name = "Gene expression"
#            #if name == "kallisto":
#            #    pass
#            #    #name = "Isoform proportions \n (kallisto)"
#            #if name == "bins":
#            #    #name = "100-bp bin cov. proportions \n (ODEGR-NMF)"
#            #    name = "ODEGR-NMF"
#            #if name == "introns-shared-acceptor":
#            #    #name = "Alt. intron proportions \n (scQuint)"
#            #    name = "scQuint"
#            #if name == "introns-transitive":
#            #    name = "LeafCutter (ours)"
#            #if name == "introns-gene":
#            #    name = "DESJ"
#            #if name == "SE":
#            #    name = "Skipped exons"
#            #if name == "exons":
#            #    name = "DEXSeq"
#            df = obs.copy()
#            latent = np.loadtxt(input_path)
#            latent = latent[idx]
#            proj = UMAP(min_dist=0.5, n_neighbors=15, random_state=42).fit_transform(latent)
#            df["UMAP 1"] = proj[:, 0]
#            df["UMAP 2"] = proj[:, 1]
#            df["Quantification"] = name
#            dfs.append(df)
#        df = pd.concat(dfs)
#        df = df.replace("luminal epithelial cell of mammary gland", "luminal epithelial")
#        df = df.replace("basal cell", "basal")
#        df = df.replace("stromal cell", "stromal")
#        g = sns.relplot(
#            data=df, x="UMAP 1", y="UMAP 2",
#            row="Quantification",
#            #row_order=["Gene expression", "kallisto", "DEXSeq", "ODEGR-NMF", "DESJ", "LeafCutter", "Skipped exons", "scQuint"],
#            #row_order=["Gene expression", "kallisto", "DEXSeq", "ODEGR-NMF", "DESJ", "LeafCutter"],
#            row_order=names,
#            hue="Cell type",
#            kind="scatter",
#            facet_kws={'sharey': False, 'sharex': False},
#            height=2.0, palette="tab10", edgecolor="none", s=8,
#            aspect=0.8,
#        )
#        g.set_titles(row_template="{row_name}")
#        #g.fig.subplots_adjust(hspace=0.1)
#        for ax in g.axes.flat:
#            ax.set_xticks([])
#            ax.set_yticks([])
#            ax.set_xlabel("UMAP 1")
#            ax.set_ylabel("UMAP 2")
#        sns.despine()
#        leg = g._legend
#        leg.set_bbox_to_anchor([0.5, 1.0])
#        leg._loc = 8
#        plt.tight_layout()
#        plt.savefig(output[0], bbox_inches='tight')
#        plt.close()
#        g = sns.relplot(
#            data=df, x="UMAP 1", y="UMAP 2",
#            row="Quantification",
#            #row_order=["Gene expression", "kallisto", "DEXSeq", "ODEGR-NMF", "DESJ", "LeafCutter", "Skipped exons", "scQuint"],
#            #row_order=["Gene expression", "kallisto", "DEXSeq", "ODEGR-NMF", "DESJ", "LeafCutter"],
#            row_order=names,
#            hue="Plate ID",
#            kind="scatter",
#            facet_kws={'sharey': False, 'sharex': False, "margin_titles": False},
#            height=2.0, palette=["C3", "C8", "C9"], edgecolor="none", s=8,
#            aspect=0.95,
#            #legend=False,
#        )
#        g.set_titles(row_template="{row_name}")
#        #g.fig.subplots_adjust(hspace=0.1)
#        for ax in g.axes.flat:
#            ax.set_xticks([])
#            ax.set_yticks([])
#            ax.set_xlabel("UMAP 1")
#            ax.set_ylabel("UMAP 2")
#        sns.despine()
#        leg = g._legend
#        leg.set_bbox_to_anchor([0.5, 1.0])
#        leg._loc = 8
#        #plt.savefig(output[1])
#        #plt.savefig(output[1], bbox_extra_artists=(leg,), bbox_inches='tight')
#        #plt.savefig(output[1], bbox_extra_artists=(leg,))
#        #g.get_figure().savefig(output[1], bbox_inches='tight')
#        #plt.subplots_adjust(top=0.95, right=0.95)
#        #g.savefig(output[1], bbox_inches='tight', bbox_extra_artists=(leg,))
#        plt.tight_layout()
#        plt.savefig(output[1], bbox_inches='tight')
#        plt.close()
#
#
#rule dimensionality_reduction_marrow_b_expression:
#    input:
#        "output/quantification/gene-expression/adata_annotated.h5ad",
#    output:
#        "output/dimensionality_reduction/marrow_b/gene-expression/PCA/latent.txt",
#    run:
#        adata = anndata.read_h5ad(input[0])
#        adata = adata[(adata.obs.tissue=="Marrow") & (adata.obs.cell_ontology_class.str.endswith("B cell"))]
#        sc.pp.filter_genes(adata, min_cells=30)
#        sc.pp.normalize_total(adata, target_sum=1e4)
#        sc.pp.log1p(adata)
#        X = adata.X.toarray()
#        latent = PCA(n_components=20).fit_transform(X)
#        np.savetxt(output[0], latent)
#
#
#rule dimensionality_reduction_marrow_b_pca:
#    input:
#        "output/quantification/{quantification}/adata_annotated.h5ad",
#    output:
#        "output/dimensionality_reduction/marrow_b/{quantification}/PCA_{K}/latent.txt",
#    run:
#        adata = anndata.read_h5ad(input[0])
#        adata = adata[(adata.obs.tissue=="Marrow") & (adata.obs.cell_ontology_class.str.endswith("B cell"))]
#        adata = filter_min_cells_per_feature(adata, 30)
#        if wildcards["quantification"] == "introns-transitive":
#            adata = recluster(adata)
#        latent = run_pca(adata, int(wildcards["K"]))
#        np.savetxt(output[0], latent)
#
#
#rule compare_latent_marrow_b:
#    input:
#        #"output/dimensionality_reduction/marrow_b/gene-expression/PCA/latent.txt",
#        #"output/dimensionality_reduction/marrow_b/introns-transitive/PCA_10/latent.txt",
#        #"output/dimensionality_reduction/marrow_b/introns-shared-acceptor/PCA_20/latent.txt",
#        "output/dimensionality_reduction/all/gene-expression/pca_40/latent.txt",
#        "output/dimensionality_reduction/all/introns-shared-acceptor/vae_hyperopt/latent.txt",
#    output:
#        expand("output/comparison/marrow_b/{label}.svg", label=labels)
#    run:
#        obs = sample_info.copy()
#        idx = np.where((obs.tissue=="Marrow") & (obs.cell_ontology_class.str.endswith("B cell")))[0]
#        obs = obs.iloc[idx]
#
#        obs = obs.replace("late pro-B cell", "(1) pro-B")
#        obs = obs.replace("precursor B cell", "(2) pre-B")
#        obs = obs.replace("immature B cell", "(3) immature B")
#        obs = obs.replace("naive B cell", "(4) naive B")
#
#        dfs = []
#        for name, input_path in zip(["Expression latent space", "Splicing latent space"], input):
#            df = obs.copy()
#            latent = np.loadtxt(input_path)
#            latent = latent[idx]
#
#            proj = UMAP(min_dist=0.5, n_neighbors=15, random_state=42).fit_transform(latent)
#            df["UMAP 1"] = proj[:, 0]
#            df["UMAP 2"] = proj[:, 1]
#            df["Quantification"] = name
#            df = df[df.cell_ontology_class != "early pro-B cell"]
#            df = df.sort_values("cell_ontology_class")
#            dfs.append(df)
#        df = pd.concat(dfs)
#        for i, label in enumerate(labels):
#            g = sns.relplot(
#                data=df, x="UMAP 1", y="UMAP 2",
#                col="Quantification", hue=label,
#                kind="scatter", facet_kws={'sharey': False, 'sharex': False},
#                height=3, palette="tab10", edgecolor="none", s=4,
#               )
#            g.set_titles(col_template="{col_name}")
#            g.fig.subplots_adjust(wspace=0.1)
#            for ax in g.axes.flat:
#                ax.set_xticks([])
#                ax.set_yticks([])
#                ax.set_ylabel("UMAP 2")
#            sns.despine()
#            plt.savefig(output[i], bbox_inches='tight')
#
#
#rule psi_plot_marrow_b:
#    input:
#        "output/quantification/introns-shared-acceptor/adata_annotated.h5ad",
#    output:
#        expand("output/plots/{intron}.svg", intron=introns_to_plot),
#    run:
#        adata = anndata.read_h5ad(input[0])
#        adata.obs = adata.obs.replace("late pro-B cell", "(1) pro-B")
#        adata.obs = adata.obs.replace("precursor B cell", "(2) pre-B")
#        adata.obs = adata.obs.replace("immature B cell", "(3) immature B")
#        adata.obs = adata.obs.replace("naive B cell", "(4) naive B")
#        print(adata.shape)
#        adata.obs["Cell type"] = adata.obs.cell_ontology_class
#        adata = adata[adata.obs["Cell type"].isin(cell_type_order)]
#        print(adata.shape)
#        X = group_normalize(adata.X.toarray(), adata.var.cluster.values, smooth=False)
#        var = adata.var.copy()
#        var["position"] = np.arange(len(var))
#        var["id"] = var.chromosome.astype(str) + ":" + var.start.astype(str) + "-" + var.end.astype(str)
#        var = var.set_index("id")
#        for i, intron in enumerate(introns_to_plot):
#            obs = adata.obs.copy()
#            print("position: ", var.loc[intron].position)
#            obs["PSI"] = X[:, var.loc[intron].position].ravel()
#            print(obs.groupby("Cell type").PSI.mean())
#            print(obs.PSI.isna().sum())
#
#            g = sns.FacetGrid(
#                obs,
#                col="Cell type",
#                col_order=cell_type_order,
#                hue="Cell type",
#                hue_order=cell_type_order,
#                palette="tab10",
#                sharex=False,
#                sharey=True,
#                #height=1.5,
#                height=2,
#                aspect=1,
#            )
#            eps = 1e-4
#            g.map_dataframe(
#                sns.histplot,
#                y="PSI",
#                bins=np.linspace(0-eps, 1+eps, 11),
#                stat="probability",
#            )
#            g.fig.subplots_adjust(wspace=0)
#            g.set_titles(col_template="{col_name}")
#            g.set_ylabels("PSI")
#            g.set(xticks=[])
#            g.set(xlim=(0, 1), ylim=(0, 1))
#            sns.despine(bottom=True)
#            plt.savefig(output[i], bbox_inches='tight')
#
#
#rule exp_plot_marrow_b:
#    input:
#        "output/quantification/gene-expression/adata_annotated.h5ad",
#    output:
#        expand("output/plots/{gene}.svg", gene=genes_to_plot),
#    run:
#        adata = anndata.read_h5ad(input[0])
#        adata.obs = adata.obs.replace("late pro-B cell", "(1) pro-B")
#        adata.obs = adata.obs.replace("precursor B cell", "(2) pre-B")
#        adata.obs = adata.obs.replace("immature B cell", "(3) immature B")
#        adata.obs = adata.obs.replace("naive B cell", "(4) naive B")
#        print(adata.shape)
#        adata.obs["Cell type"] = adata.obs.cell_ontology_class
#        adata = adata[adata.obs["Cell type"].isin(cell_type_order)]
#        print(adata.shape)
#        sc.pp.normalize_total(adata, target_sum=1e4)
#        sc.pp.log1p(adata)
#        for i, gene in enumerate(genes_to_plot):
#            obs = adata.obs.copy()
#            obs["log norm. expression"] = adata[:, gene].X.toarray().ravel()
#            plt.figure(figsize=(3, 2))
#            g = sns.violinplot(
#                data=obs,
#                x="Cell type",
#                y="log norm. expression",
#                order=cell_type_order,
#                #hue="Cell type",
#                #hue_order=cell_type_order,
#                palette="tab10",
#                cut=0.05,
#                scale="width",
#                width=0.75,
#            )
#            g.set(xlabel=None)
#            sns.despine(bottom=True)
#            plt.xticks(rotation=45)
#            plt.savefig(output[i], bbox_inches='tight')
#            plt.close()
#            plt.clf()
#
#
#rule diff_test_summary:
#    input:
#        'output/{anything}/expression.tsv',
#        'output/{anything}/splicing.clusters.tsv',
#    output:
#        'output/{anything}/summary.tsv',
#    run:
#        df_exp = pd.read_csv(input[0], "\t")
#        df_spl = pd.read_csv(input[1], "\t")
#        n_genes_exp = ((df_exp.p_value_adj < config["fdr"]) & (df_exp.abs_lfc > config["min_abs_lfc"])).sum()
#        n_genes_spl = len(df_spl[(df_spl.p_value_adj < config["fdr"]) & (df_spl.max_abs_delta_psi > config["min_abs_delta_psi"])].gene_id.unique())
#        ratio = n_genes_spl / n_genes_exp
#        intersection = len(list(set(df_exp.gene.unique()[:100]).intersection(set(df_spl.gene_id.unique()[:100]))))
#        print(n_genes_exp, n_genes_spl, ratio, intersection)
#        res = pd.DataFrame([[n_genes_exp, n_genes_spl, ratio, intersection]], columns=["n_genes_exp", "n_genes_spl", "ratio", "top100_intersection"])
#        res.to_csv(output[0], "\t", index=False)
#
#
#def calculate_classification_metrics(latent, classes, idx, seed=None):
#    latent = latent[idx]
#    classes = classes[idx]
#    all_classes = np.unique(classes)
#
#    try:
#        X_train, X_test, y_train, y_test = train_test_split(
#            latent, classes, test_size=0.33, random_state=seed, stratify=classes
#        )
#    except:
#        X_train, X_test, y_train, y_test = train_test_split(
#            latent, classes, test_size=0.33, random_state=seed, stratify=None
#        )
#        print("not stratifying")
#
#    clf = LogisticRegression(random_state=seed, max_iter=10000)
#    clf.fit(X_train, y_train)
#    y_pred = clf.predict(X_test)
#    y_proba = clf.predict_proba(X_test)
#    return accuracy_score(y_test, y_pred), f1_score(y_test, y_pred), roc_auc_score(y_test, y_proba[:, 1])
#
#
#rule get_classification_score:
#    input:
#        #"output/dimensionality_reduction/marrow/gene-expression/pca_20/latent.txt",
#        #"output/dimensionality_reduction/marrow/introns-transitive/pca_20/latent.txt",
#        "output/dimensionality_reduction/all/gene-expression/pca_40/latent.txt",
#        "output/dimensionality_reduction/all/introns-shared-acceptor/vae_hyperopt/latent.txt",
#    output:
#        "output/dimensionality_reduction/marrow/classification_score.tsv",
#    run:
#        cell_idx = np.where(sample_info.tissue=="Marrow")[0]
#        latent_exp = np.loadtxt(input[0])[cell_idx]
#        latent_spl = np.loadtxt(input[1])[cell_idx]
#        obs = sample_info.iloc[cell_idx]
#
#        results = []
#        for tissue, cell_type in tissue_cell_type_pairs:
#            if tissue != "Marrow": continue
#            print(cell_type)
#            idx = np.where(np.isin(obs.cell_type, [ct for t, ct in tissue_cell_type_pairs if t==tissue]))[0]
#            print(idx)
#            labels = (obs.cell_type==cell_type)
#            print(labels.sum(), len(labels), len(latent_exp), len(latent_spl))
#
#            for seed in range(30):
#                results.append((cell_type.replace("_", " "), "Expression", seed, *calculate_classification_metrics(latent_exp, labels, idx, seed)))
#                results.append((cell_type.replace("_", " "), "Splicing", seed, *calculate_classification_metrics(latent_spl, labels, idx, seed)))
#        results = pd.DataFrame(results, columns=['Cell type', 'Latent space', 'seed', 'accuracy', 'F1 score', "AUC"])
#        results.to_csv(output[0], "\t", index=False)
#
#
#rule plot_classification_score:
#    input:
#        "output/dimensionality_reduction/marrow/classification_score.tsv",
#    output:
#        "output/dimensionality_reduction/marrow/classification_score.svg",
#    run:
#        df = pd.read_csv(input[0], "\t")
#        g = sns.barplot(x="Cell type", y="AUC", hue="Latent space", data=df, ci='sd', palette="Accent");
#        g.set_xticklabels(g.get_xticklabels(), rotation=45,  horizontalalignment='right')
#        g.set(xlabel="")
#        sns.despine()
#        #plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., title="latent space");
#        plt.tight_layout()
#        plt.savefig(output[0], bbox_inches="tight")
#
#
#rule get_marker_introns:
#    input:
#        'output/{anything}/splicing.clusters.significant.tsv',
#        'output/{anything}/splicing.introns.tsv',
#    output:
#        'output/{anything}/marker_introns.tsv',
#    run:
#        groups = pd.read_csv(input[0], "\t")
#        introns = pd.read_csv(input[1], "\t")
#        introns["id"] = introns.chromosome.astype(str) + ":" + introns.start.astype(str) + "-" + introns.end.astype(str)
#        introns = introns.set_index("id")
#        groups = groups.sort_values("max_abs_delta_psi", ascending=False).head(30)
#        #groups = groups[(groups.p_value_adj < config["fdr"]) & (groups.max_abs_delta_psi >= config["min_abs_delta_psi"])].sort_values("p_value", ascending=True).head(30)
#        print(groups.p_value_adj)
#        print(groups.max_abs_delta_psi)
#        groups["marker_intron"] = groups.cluster.apply(lambda x: introns[introns.cluster==x].delta_psi.idxmax())
#        groups.to_csv(output[0], "\t")
#
#
#rule plot_marker_introns:
#    input:
#        "output/quantification/introns-shared-acceptor/adata_annotated.h5ad",
#        expand('output/differential_splicing/tissue_cell_type/{tct[0]}/{tct[1]}/marker_introns.tsv', tct=tissue_cell_type_pairs),
#    output:
#        'output/differential_splicing/tissue_cell_type/marker_introns.svg',
#    run:
#        adata_spl = anndata.read_h5ad(input[0])
#        adata_spl.var["id"] = adata_spl.var.chromosome.astype(str) + ":" + adata_spl.var.start.astype(str) + "-" + adata_spl.var.end.astype(str)
#        adata_spl.var = adata_spl.var.set_index("id")
#
#        all_marker_introns = []
#        for input_path in input[1:]:
#            marker_introns = pd.read_csv(input_path, "\t", header=None).values.astype(str).ravel().tolist()[:3]
#            all_marker_introns += marker_introns
#        print(all_marker_introns)
#        print(len(all_marker_introns))
#        all_marker_introns = pd.unique(all_marker_introns)
#        print(len(all_marker_introns))
#        adata_spl.X = group_normalize(adata_spl.X.toarray(), adata_spl.var.cluster.values, smooth=False)
#        adata_spl.obs["tissue_cell_type"] = adata_spl.obs.tissue.astype(str) + "/" + adata_spl.obs.cell_type.astype(str)
#        tissue_cell_types = [tissue + "/" + cell_type for tissue, cell_type in tissue_cell_type_pairs]
#        adata_spl = adata_spl[adata_spl.obs["tissue_cell_type"].isin(tissue_cell_types)]
#        adata_spl = adata_spl[:, all_marker_introns]
#        for tissue_cell_type in tissue_cell_types:
#            print(tissue_cell_type)
#            for intron in all_marker_introns:
#                idx_cells = np.where(adata_spl.obs["tissue_cell_type"]==tissue_cell_type)[0]
#                n_defined = (~np.isnan(adata_spl[idx_cells, intron].X)).sum()
#                if n_defined < 10:
#                    adata_spl[idx_cells, intron].X = np.nan
#        gene_name = pd.read_csv("output/gene_name.txt", "\t", index_col=0)
#        adata_spl.var = adata_spl.var.merge(gene_name, how="left", left_on="gene_id", right_index=True)
#        adata_spl.var.loc[:, "id"] = adata_spl.var.gene_name.astype(str) + "_" + adata_spl.var.index
#        adata_spl.var = adata_spl.var.set_index("id")
#
#        g = sc.pl.matrixplot(
#            adata_spl,
#            adata_spl.var.index.values,
#            groupby='tissue_cell_type',
#            categories_order=tissue_cell_types,
#            return_fig=True, vmin=0.0, vmax=1.0, cmap='bwr', swap_axes=True, colorbar_title="Mean PSI")
#        plt.tight_layout()
#        g.savefig(output[0], bbox_inches="tight")
#
#
rule prepare_adata_for_cellxgene:
    input:
        "output/quantification/gene-expression/adata_annotated.h5ad",
        "output/quantification/introns-shared-acceptor/adata_annotated.h5ad",
        "output/gene_name.txt",
    output:
        "output/adata_cellxgene_for_dendrogram_{smooth}.h5ad",
    run:
        gene_name = pd.read_csv(input[2], "\t", index_col=0)
        adata_exp = anndata.read_h5ad(input[0])
        adata_exp.var = adata_exp.var.merge(gene_name, how="left", left_index=True, right_index=True)
        adata_exp.var["gene_id"] = adata_exp.var.index.values
        adata_exp.var = adata_exp.var.set_index("gene_name")
        adata_exp.var_names_make_unique()
        adata_exp.obs.index = adata_exp.obs.index.astype(str)
        adata_spl = anndata.read_h5ad(input[1])
        adata_spl = filter_min_cells_per_feature(adata_spl, 100)
        adata_spl.var = adata_spl.var.merge(gene_name, how="left", left_on="gene_id", right_index=True)
        adata_spl.var["id"] = adata_spl.var.gene_name + "_" + adata_spl.var.chromosome.astype(str) + ":" + adata_spl.var.start.astype(str) + "-" + adata_spl.var.end.astype(str)
        adata_spl.var = adata_spl.var.set_index("id", drop=False)
        adata_spl.obs.index = adata_spl.obs.index.astype(str)
        adata_spl.var.index = adata_spl.var.index.astype(str)
        assert((adata_exp.obs.index == adata_spl.obs.index).all())
        sc.pp.normalize_total(adata_exp, target_sum=1e4)
        sc.pp.log1p(adata_exp)
        sc.pp.filter_genes(adata_exp, min_cells=100)
        adata_exp.X = adata_exp.X.toarray()
        #adata_spl.X = group_normalize(adata_spl.X.toarray(), adata_spl.var.cluster.values, smooth=False)
        adata_spl.X = group_normalize(adata_spl.X.toarray(), adata_spl.var.cluster.values, smooth=wildcards["smooth"]=="True")

        intron_clusters = adata_spl.var.cluster.values
        all_intron_clusters = np.unique(intron_clusters)
        first_indices_dict = {}
        not_first_indices = []
        for i, c in enumerate(intron_clusters):
            if c not in first_indices_dict:
                first_indices_dict[c] = i
            else:
                not_first_indices.append(i)
        first_indices = np.array([first_indices_dict[c] for c in all_intron_clusters])
        not_first_indices = np.array(not_first_indices)
        new_idx = adata_spl.var.index.values[not_first_indices]
        print(adata_spl.var.index)
        adata_spl = adata_spl[:, new_idx]
        print(adata_spl.var.index)

        latent = PCA(n_components=40).fit_transform(adata_exp.X)
        proj = UMAP(min_dist=0.5, n_neighbors=15, random_state=42).fit_transform(latent)

        X = np.hstack((adata_exp.X, adata_spl.X))
        print(adata_exp.shape, adata_spl.shape, X.shape)
        obs = adata_exp.obs
        var = pd.concat([adata_exp.var, adata_spl.var])
        adata = anndata.AnnData(X=X, obs=obs, var=var)
        adata.obsm["X_umap"] = proj
        adata.write_h5ad(output[0], compression="gzip")
#
#
#rule make_bam_paths_tct:
#    input:
#        expand("output/mapping/filtered_bams/{sample_id}.bam", sample_id=sample_ids)
#    output:
#        "output/bam_paths/tct/{tissue}/{cell_type}/paths.txt",
#    run:
#        s_ids = sample_ids[np.where((sample_info.tissue==wildcards["tissue"]) & (sample_info.cell_type==wildcards["cell_type"]))[0]]
#        cwd = os.getcwd()
#        pd.DataFrame(dict(sample_id=s_ids, bam_path=[f"{cwd}/output/mapping/filtered_bams/{sample_id}.bam" for sample_id in s_ids])).to_csv(output[0], "\t", index=False, header=False)
#
#
#rule make_coverage_track_tct:
#    input:
#        "output/bam_paths/tct/{tissue}/{cell_type}/paths.txt",
#    output:
#        "output/coverage_track/tct/{tissue}/{cell_type}/coverage.bw",
#    threads: workflow.cores // 4
#    shell:
#        "python -m scquint.quantification.run coverage_track/Snakefile --cores {threads} -d output/coverage_track/tct/{wildcards.tissue}/{wildcards.cell_type}/ --config bam_paths=../../../../bam_paths/tct/{wildcards.tissue}/{wildcards.cell_type}/paths.txt chrom_sizes_path={chrom_sizes_path}"
#
#
#quantifications_all = ["gene-expression", "introns-transitive", "SE", "introns-shared-acceptor"]
#
#rule clustering_patterns_comparison_quantitative:
#    input:
#        expand("output/dimensionality_reduction/mg/{quantification}/pca_20/latent.txt", quantification=quantifications_mg_individual_expanded),
#        #expand("output/dimensionality_reduction/mg_3_38_F/{quantification}/pca_10/latent.txt", quantification=quantifications_mg_individual_expanded),
#        #expand("output/dimensionality_reduction/all/{quantification}/pca_20/latent.txt", quantification=quantifications_all),
#    output:
#        "output/comparison/mg_3_38_F/classification_results.tsv",
#    run:
#        obs = sample_info[(sample_info.tissue=="Mammary_Gland")]
#        #obs = sample_info[(sample_info.tissue=="Mammary_Gland") & (sample_info["mouse.id"]=="3_38_F")]
#        obs = obs.sort_index()
#        #obs = sample_info.copy()
#        idx = np.where((obs.tissue=="Mammary_Gland") & (obs["mouse.id"]=="3_38_F") & (obs.cell_ontology_class!="endothelial cell"))[0]
#        obs = obs.iloc[idx]
#        obs["Cell type"] = obs.cell_ontology_class
#        obs["Plate ID"] = obs.plate_id
#        results = []
#        #for name, input_path in zip(quantifications_mg_individual_expanded, input):
#        for name, input_path in zip(quantifications_mg_individual_expanded + ["random"], input + ["random"]):
#            print(name)
#            #if name == "gene-expression":
#            #    name = "Gene expression \n (featureCounts)"
#            #if name == "kallisto":
#            #    name = "Isoform proportions \n (kallisto)"
#            #if name == "bins-nmf":
#            #    name = "100-bp bin cov. proportions \n (ODEGR-NMF)"
#            #if name == "introns-shared-acceptor":
#            #    name = "Alt. intron proportions \n (scQuint)"
#            if name != "random":
#                latent = np.loadtxt(input_path)
#                latent = latent[idx]
#
#            for cell_type in obs.cell_ontology_class.unique():
#
#                for seed in range(100):
#                    if name == "random":
#                        latent = np.random.normal(size=latent.shape)
#                    latent_a = latent[obs.cell_ontology_class==cell_type]
#                    latent_b = latent[obs.cell_ontology_class!=cell_type]
#                    dist_cell_type = np.linalg.norm(latent_a.mean(axis=0) - latent_b.mean(axis=0))
#                    latent_a = latent[(obs.cell_ontology_class==cell_type) & (obs.plate_id=="B002438")]
#                    latent_b = latent[(obs.cell_ontology_class==cell_type) & (obs.plate_id!="B002438")]
#                    dist_plate = np.linalg.norm(latent_a.mean(axis=0) - latent_b.mean(axis=0))
#                    dist_logratio = np.log(dist_cell_type) - np.log(dist_plate)
#                    #print(dist_cell_type, dist_plate, dist_logratio)
#
#                    results.append((name, cell_type, "cell_type", seed, *calculate_classification_metrics(latent, obs.cell_ontology_class==cell_type, slice(None), seed), dist_logratio))
#                    results.append((name, cell_type, "plate", seed, *calculate_classification_metrics(latent, obs.plate_id=="B002438", np.where(obs.cell_ontology_class==cell_type)[0], seed), dist_logratio))
#
#
#        results = pd.DataFrame(results, columns=["Method", 'Cell type', 'Prediction', 'seed', 'accuracy', 'F1 score', "AUROC", "dist_logratio"])
#        results.to_csv(output[0], "\t", index=False)
#
#
#rule clustering_patterns_comparison_quantitative_plot:
#    input:
#        "output/comparison/mg_3_38_F/classification_results.tsv",
#    output:
#        directory("output/comparison/mg_3_38_F/classification_results_plots/"),
#    run:
#        df = pd.read_csv(input[0], "\t")
#        df = df.replace("luminal epithelial cell of mammary gland", "luminal\nepithelial")
#        df = df.replace("basal cell", "basal")
#        df = df.replace("stromal cell", "stromal")
#        df.Method.replace({
#            "bins-nmf": "ODEGR-NMF",
#            "exons": "DEXSeq",
#            "introns-gene": "DESJ",
#            "introns-transitive": "LeafCutter",
#            "introns-shared-acceptor": "scQuint",
#        }, inplace=True)
#
#        os.makedirs(output[0])
#
#        for metric in ["AUROC", "accuracy", "dist_logratio"]:
#            g = sns.catplot(
#                x="Method",
#                y=metric,
#                data=df,
#                order=["random", "gene-expression", "kallisto", "LeafCutter", "SE", "SE-shared-donor", "SE-shared-acceptor", "scQuint"],
#                #order=["random", "gene-expression", "LeafCutter", "SE", "scQuint"],
#                ci='sd',
#                palette="Accent",
#                row="Cell type",
#                col="Prediction" if metric != "dist_logratio" else None,
#                #kind="bar",
#                kind="point", join=False,
#                margin_titles=True,
#                height=3.5,
#                aspect=1.0,
#               )
#            g.set_xticklabels(rotation=45, horizontalalignment="right")
#            #g.set(ylim=(0.45, 1), yticks=[0.5, 0.6, 0.7, 0.8, 0.9, 1.0])
#            g.set(xlabel="")
#            #sns.despine()
#            #plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., title="latent space");
#            plt.tight_layout()
#            plt.savefig(os.path.join(output[0], f"{metric}.svg"), bbox_inches="tight")
#            plt.close()
#
#

#wget https://sourceforge.net/projects/brie-rna/files/annotation/mouse/gencode.vM17/SE.filtered.gtf.gz/download -O SE.gtf.gz &&
#rule download_SE:
#    output:
#        "output/SE.gtf",
#    shell:
#        """
#        cd output &&
#        wget https://sourceforge.net/projects/brie-rna/files/annotation/mouse/gencode.vM17/SE.lenient.gtf.gz/download -O SE.gtf.gz &&
#        zcat SE.gtf.gz > SE.gtf
#        """


#rule kallisto_quantification_SE:
#    input:
#        "output/fastq_paths_subset.txt",
#        "output/SE.gtf"
#    output:
#        "output/quantification/kallisto-SE/adata.h5ad"
#    threads: workflow.cores
#    shell:
#        "python -m scquint.quantification.run kallisto/Snakefile --cores {threads} -d output/quantification/kallisto-SE/ --config fastq_paths=../../fastq_paths_subset.txt genome_fasta_path={genome_fasta_path} gtf_path=../../SE.gtf min_cells_per_isoform=30"


# export LD_LIBRARY_PATH=/global/home/users/gbenegas/miniconda2/lib:$LD_LIBRARY_PATH
# export PATH="/global/home/users/gbenegas/miniconda2/bin:$PATH"
# briekit-event -o AS_events -a /global/scratch/gbenegas/genomes/mus_musculus/mm10/mm10_filt.gtf
# zcat SE.gff3.gz > SE.gff3
# gffread SE.gff3 -T -o SE_new.gtf
#
#rule quantify_SE:
#    input:
#        "output/quantification/introns-transitive/adata_annotated.h5ad",
#        "output/SE_new.gtf",
#        #"output/SE.gtf",
#    output:
#        "output/quantification/SE/adata_annotated.h5ad",
#    run:
#        adata_spl = anndata.read_h5ad(input[0])
#        print(adata_spl.shape)
#        var = adata_spl.var.copy()
#        var["position"] = np.arange(len(var))
#        var["id"] = var.chromosome.astype(str) + ":" + var.start.astype(str) + "-" + var.end.astype(str)
#        var = var.set_index("id")
#
#        df = pd.read_csv(
#            input[1], '\t', header=None, comment="#",
#            names=['chromosome', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attribute'],
#        )
#        print(df.shape)
#        df = df[df.feature=="exon"]
#        print(df.shape)
#        df['gene_id'] = df.attribute.str.extract(r'gene_id "([^;]*)";')
#        #df['transcript_id'] = df.attribute.str.extract(r'transcript_id "([^;]*)"')  # the filtered versions need this
#        df['transcript_id'] = df.attribute.str.extract(r'transcript_id "([^;]*)";')
#        print(df)
#        #print("hardcoding chromosome")
#        #df = df[df.chromosome=="chr10"]
#
#        index = []
#        intron_summation_data = []
#        intron_summation_row_ind = []
#        intron_summation_col_ind = []
#
#        row = 0
#
#        for gene_id, exons_g in df.groupby("gene_id"):
#            introns_g = []
#            transcripts_g = []
#            for transcript_id, exons_t in exons_g.groupby("transcript_id"):
#                transcripts_g.append(transcript_id)
#                introns_t = [f"{e1[0]}:{e1[2]+1}-{e2[1]}" for e1, e2 in pairwise(exons_t.sort_values(["start", "end"])[["chromosome", "start", "end"]].values)]
#                introns_g.append(introns_t)
#            introns_g_flat = np.concatenate(introns_g)
#            n_matches = var.index.isin(introns_g_flat).sum()
#            if n_matches != len(introns_g_flat): continue
#            for transcript_id, introns_t in zip(transcripts_g, introns_g):
#                n = len(introns_t)
#                positions = var.loc[introns_t].position.values
#                index.append([gene_id, transcript_id])
#                intron_summation_data.append(np.ones(n, dtype=float))
#                intron_summation_row_ind.append(np.full(n, row))
#                intron_summation_col_ind.append(positions)
#                row += 1
#
#        intron_summation_data = np.concatenate(intron_summation_data)
#        intron_summation_row_ind = np.concatenate(intron_summation_row_ind)
#        intron_summation_col_ind = np.concatenate(intron_summation_col_ind)
#        intron_summation = sp_sparse.csr_matrix((intron_summation_data, (intron_summation_row_ind, intron_summation_col_ind)), shape=(row, len(var)))
#        print("intron_summation.shape: ", intron_summation.shape)
#        X = (adata_spl.X @ intron_summation.T).tocsr()
#        print(X.shape)
#        var = pd.DataFrame(index, columns=["gene_id", "transcript_id"])
#        var["cluster"] = relabel(var.gene_id)
#        adata = anndata.AnnData(X=X, obs=adata_spl.obs, var=var)
#        print(adata.shape)
#        adata = filter_min_cells_per_feature(adata, 30)
#        print(adata.shape)
#        adata.var["original_cluster"] = adata.var.cluster
#        adata.write(output[0], compression="gzip")
#
#
#rule quantify_SE_shared_acceptor:
#    input:
#        "output/quantification/introns-transitive/adata_annotated.h5ad",
#        "output/SE_new.gtf",
#    output:
#        "output/quantification/SE-shared-acceptor/adata_annotated.h5ad",
#    run:
#        adata_spl = anndata.read_h5ad(input[0])
#        print(adata_spl.shape)
#        var = adata_spl.var.copy()
#        var["position"] = np.arange(len(var))
#        var["id"] = var.chromosome.astype(str) + ":" + var.start.astype(str) + "-" + var.end.astype(str)
#        var = var.set_index("id")
#
#        df = pd.read_csv(
#            input[1], '\t', header=None, comment="#",
#            names=['chromosome', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attribute'],
#        )
#        print(df.shape)
#        df = df[df.feature=="exon"]
#        print(df.shape)
#        df['gene_id'] = df.attribute.str.extract(r'gene_id "([^;]*)";')
#        df['transcript_id'] = df.attribute.str.extract(r'transcript_id "([^;]*)";')
#        print(df)
#
#        index = []
#        intron_summation_data = []
#        intron_summation_row_ind = []
#        intron_summation_col_ind = []
#
#        row = 0
#
#        for gene_id, exons_g in df.groupby("gene_id"):
#            strand = exons_g.strand.values[0]
#            introns_g = []
#            transcripts_g = []
#            for transcript_id, exons_t in exons_g.groupby("transcript_id"):
#                transcripts_g.append(transcript_id)
#                introns_t = [f"{e1[0]}:{e1[2]+1}-{e2[1]}" for e1, e2 in pairwise(exons_t.sort_values(["start", "end"])[["chromosome", "start", "end"]].values)]
#                introns_g.append(introns_t)
#            introns_g_flat = np.concatenate(introns_g)
#            n_matches = var.index.isin(introns_g_flat).sum()
#            if n_matches != 3: continue
#            for transcript_id, introns_t in zip(transcripts_g, introns_g):
#                n = 1
#                if len(introns_t) > 1:
#                    if strand == "+":
#                        introns_t_filt = introns_t[1:]
#                    elif strand == "-":
#                        introns_t_filt = introns_t[:-1]
#                    else:
#                        raise Exception(f"strand {strand} not implemented")
#                else:
#                    introns_t_filt = introns_t
#                positions = var.loc[introns_t_filt].position.values
#                assert len(positions) == 1
#                index.append([gene_id, transcript_id])
#                intron_summation_data.append(np.ones(n, dtype=float))
#                intron_summation_row_ind.append(np.full(n, row))
#                intron_summation_col_ind.append(positions)
#                row += 1
#
#        intron_summation_data = np.concatenate(intron_summation_data)
#        intron_summation_row_ind = np.concatenate(intron_summation_row_ind)
#        intron_summation_col_ind = np.concatenate(intron_summation_col_ind)
#        intron_summation = sp_sparse.csr_matrix((intron_summation_data, (intron_summation_row_ind, intron_summation_col_ind)), shape=(row, len(var)))
#        print("intron_summation.shape: ", intron_summation.shape)
#        X = (adata_spl.X @ intron_summation.T).tocsr()
#        print(X.shape)
#        var = pd.DataFrame(index, columns=["gene_id", "transcript_id"])
#        var["cluster"] = relabel(var.gene_id)
#        adata = anndata.AnnData(X=X, obs=adata_spl.obs, var=var)
#        print(adata.shape)
#        adata = filter_min_cells_per_feature(adata, 30)
#        print(adata.shape)
#        adata.var["original_cluster"] = adata.var.cluster
#        adata.write(output[0], compression="gzip")
#
#
#rule quantify_SE_shared_donor:
#    input:
#        "output/quantification/introns-transitive/adata_annotated.h5ad",
#        "output/SE_new.gtf",
#    output:
#        "output/quantification/SE-shared-donor/adata_annotated.h5ad",
#    run:
#        adata_spl = anndata.read_h5ad(input[0])
#        print(adata_spl.shape)
#        var = adata_spl.var.copy()
#        var["position"] = np.arange(len(var))
#        var["id"] = var.chromosome.astype(str) + ":" + var.start.astype(str) + "-" + var.end.astype(str)
#        var = var.set_index("id")
#
#        df = pd.read_csv(
#            input[1], '\t', header=None, comment="#",
#            names=['chromosome', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attribute'],
#        )
#        print(df.shape)
#        df = df[df.feature=="exon"]
#        print(df.shape)
#        df['gene_id'] = df.attribute.str.extract(r'gene_id "([^;]*)";')
#        df['transcript_id'] = df.attribute.str.extract(r'transcript_id "([^;]*)";')
#        print(df)
#
#        index = []
#        intron_summation_data = []
#        intron_summation_row_ind = []
#        intron_summation_col_ind = []
#
#        row = 0
#
#        for gene_id, exons_g in df.groupby("gene_id"):
#            strand = exons_g.strand.values[0]
#            introns_g = []
#            transcripts_g = []
#            for transcript_id, exons_t in exons_g.groupby("transcript_id"):
#                transcripts_g.append(transcript_id)
#                introns_t = [f"{e1[0]}:{e1[2]+1}-{e2[1]}" for e1, e2 in pairwise(exons_t.sort_values(["start", "end"])[["chromosome", "start", "end"]].values)]
#                introns_g.append(introns_t)
#            introns_g_flat = np.concatenate(introns_g)
#            n_matches = var.index.isin(introns_g_flat).sum()
#            if n_matches != 3: continue
#            for transcript_id, introns_t in zip(transcripts_g, introns_g):
#                n = 1
#                if len(introns_t) > 1:
#                    if strand == "-":
#                        introns_t_filt = introns_t[1:]
#                    elif strand == "+":
#                        introns_t_filt = introns_t[:-1]
#                    else:
#                        raise Exception(f"strand {strand} not implemented")
#                else:
#                    introns_t_filt = introns_t
#                positions = var.loc[introns_t_filt].position.values
#                assert len(positions) == 1
#                index.append([gene_id, transcript_id])
#                intron_summation_data.append(np.ones(n, dtype=float))
#                intron_summation_row_ind.append(np.full(n, row))
#                intron_summation_col_ind.append(positions)
#                row += 1
#
#        intron_summation_data = np.concatenate(intron_summation_data)
#        intron_summation_row_ind = np.concatenate(intron_summation_row_ind)
#        intron_summation_col_ind = np.concatenate(intron_summation_col_ind)
#        intron_summation = sp_sparse.csr_matrix((intron_summation_data, (intron_summation_row_ind, intron_summation_col_ind)), shape=(row, len(var)))
#        print("intron_summation.shape: ", intron_summation.shape)
#        X = (adata_spl.X @ intron_summation.T).tocsr()
#        print(X.shape)
#        var = pd.DataFrame(index, columns=["gene_id", "transcript_id"])
#        var["cluster"] = relabel(var.gene_id)
#        adata = anndata.AnnData(X=X, obs=adata_spl.obs, var=var)
#        print(adata.shape)
#        adata = filter_min_cells_per_feature(adata, 30)
#        print(adata.shape)
#        adata.var["original_cluster"] = adata.var.cluster
#        adata.write(output[0], compression="gzip")
#
#
#rule clustering_patterns_cortex_comparison_quantitative:
#    input:
#        expand("output/dimensionality_reduction/brain/{quantification}/pca_20/latent.txt", quantification=quantifications_all),
#    output:
#        "output/comparison/cortex_3_9_M/classification_results.tsv",
#    run:
#        obs = sample_info[(sample_info.tissue=="Brain_Non-Myeloid")]
#        obs = obs.sort_index()
#        idx = np.where((obs.tissue=="Brain_Non-Myeloid") & (obs.subtissue=="Cortex") & (obs["mouse.id"]=="3_9_M") & (obs.cell_ontology_class.isin(["oligodendrocyte", "astrocyte"])))[0]
#        obs = obs.iloc[idx]
#        obs["Cell type"] = obs.cell_ontology_class
#        obs["Plate ID"] = obs.plate_id
#        target_plate = "MAA000926"
#        results = []
#        #for name, input_path in zip(quantifications_mg_individual_expanded + ["random"], input + ["random"]):
#        for name, input_path in zip(quantifications_all + ["random"], input + ["random"]):
#            print(name)
#            if name != "random":
#                latent = np.loadtxt(input_path)
#                latent = latent[idx]
#
#            for cell_type in obs.cell_ontology_class.unique():
#                for seed in range(100):
#                    if name == "random":
#                        latent = np.random.normal(size=latent.shape)
#                    latent_a = latent[obs.cell_ontology_class==cell_type]
#                    latent_b = latent[obs.cell_ontology_class!=cell_type]
#                    dist_cell_type = np.linalg.norm(latent_a.mean(axis=0) - latent_b.mean(axis=0))
#                    latent_a = latent[(obs.cell_ontology_class==cell_type) & (obs.plate_id==target_plate)]
#                    latent_b = latent[(obs.cell_ontology_class==cell_type) & (obs.plate_id!=target_plate)]
#                    dist_plate = np.linalg.norm(latent_a.mean(axis=0) - latent_b.mean(axis=0))
#                    dist_logratio = np.log(dist_cell_type) - np.log(dist_plate)
#                    #print(dist_cell_type, dist_plate, dist_logratio)
#
#                    results.append((name, cell_type, "cell_type", seed, *calculate_classification_metrics(latent, obs.cell_ontology_class==cell_type, slice(None), seed), dist_logratio))
#                    results.append((name, cell_type, "plate", seed, *calculate_classification_metrics(latent, obs.plate_id==target_plate, np.where(obs.cell_ontology_class==cell_type)[0], seed), dist_logratio))
#
#
#        results = pd.DataFrame(results, columns=["Method", 'Cell type', 'Prediction', 'seed', 'accuracy', 'F1 score', "AUROC", "dist_logratio"])
#        results.to_csv(output[0], "\t", index=False)
#
#
#rule clustering_patterns_cortex_comparison_quantitative_plot:
#    input:
#        "output/comparison/cortex_3_9_M/classification_results.tsv",
#    output:
#        directory("output/comparison/cortex_3_9_M/classification_results_plots/"),
#    run:
#        df = pd.read_csv(input[0], "\t")
#        df.Method.replace({
#            "bins-nmf": "ODEGR-NMF",
#            "exons": "DEXSeq",
#            "introns-gene": "DESJ",
#            "introns-transitive": "LeafCutter",
#            "introns-shared-acceptor": "scQuint",
#        }, inplace=True)
#
#        os.makedirs(output[0])
#
#        for metric in ["AUROC", "accuracy", "dist_logratio"]:
#            g = sns.catplot(
#                x="Method",
#                y=metric,
#                data=df,
#                #order=["random", "gene-expression", "kallisto", "LeafCutter", "SE", "SE-shared-donor", "SE-shared-acceptor", "scQuint"],
#                order=["random", "gene-expression", "LeafCutter", "SE", "scQuint"],
#                ci='sd',
#                palette="Accent",
#                row="Cell type",
#                col="Prediction" if metric != "dist_logratio" else None,
#                #kind="bar",
#                kind="point", join=False,
#                margin_titles=True,
#                height=3.5,
#                aspect=1.0,
#               )
#            g.set_xticklabels(rotation=45, horizontalalignment="right")
#            #g.set(ylim=(0.45, 1), yticks=[0.5, 0.6, 0.7, 0.8, 0.9, 1.0])
#            g.set(xlabel="")
#            #sns.despine()
#            #plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., title="latent space");
#            plt.tight_layout()
#            plt.savefig(os.path.join(output[0], f"{metric}.svg"), bbox_inches="tight")
#            plt.close()
#
#
#rule compare_latent_cortex_3_9_M_custom_plot:
#    input:
#        expand("output/dimensionality_reduction/brain/{quantification}/pca_20/latent.txt", quantification=quantifications_mg_individual_expanded),
#    output:
#        "output/comparison/cortex_3_9_M/cell_ontology_class.svg",
#        "output/comparison/cortex_3_9_M/plate.svg",
#    run:
#        obs = sample_info[(sample_info.tissue=="Brain_Non-Myeloid")]
#        obs = obs.sort_index()
#        idx = np.where((obs.tissue=="Brain_Non-Myeloid") & (obs.subtissue=="Cortex") & (obs["mouse.id"]=="3_9_M") & (obs.cell_ontology_class.isin(["oligodendrocyte", "astrocyte", "endothelial cell"])))[0]
#        obs = obs.iloc[idx]
#        obs["Cell type"] = obs.cell_ontology_class
#        obs["Plate ID"] = obs.plate_id
#        dfs = []
#        for name, input_path in zip(quantifications_mg_individual_expanded, input):
#            print(name)
#            if name == "gene-expression":
#                #name = "Gene expression \n (featureCounts)"
#                name = "Gene expression"
#            if name == "kallisto":
#                pass
#                #name = "Isoform proportions \n (kallisto)"
#            if name == "bins":
#                #name = "100-bp bin cov. proportions \n (ODEGR-NMF)"
#                name = "ODEGR-NMF"
#            if name == "introns-shared-acceptor":
#                #name = "Alt. intron proportions \n (scQuint)"
#                name = "scQuint"
#            if name == "introns-transitive":
#                name = "LeafCutter"
#            if name == "introns-gene":
#                name = "DESJ"
#            if name == "SE":
#                name = "Skipped exons"
#            if name == "exons":
#                name = "DEXSeq"
#            df = obs.copy()
#            latent = np.loadtxt(input_path)
#            latent = latent[idx]
#            proj = UMAP(min_dist=0.5, n_neighbors=15, random_state=42).fit_transform(latent)
#            df["UMAP 1"] = proj[:, 0]
#            df["UMAP 2"] = proj[:, 1]
#            df["Quantification"] = name
#            dfs.append(df)
#        df = pd.concat(dfs)
#        g = sns.relplot(
#            data=df, x="UMAP 1", y="UMAP 2",
#            row="Quantification",
#            #row_order=["Gene expression", "kallisto", "DEXSeq", "ODEGR-NMF", "DESJ", "LeafCutter", "Skipped exons", "scQuint"],
#            row_order=["Gene expression", "DEXSeq", "DESJ", "LeafCutter", "Skipped exons", "scQuint"],
#            hue="Cell type",
#            kind="scatter",
#            facet_kws={'sharey': False, 'sharex': False},
#            height=2.0, palette="tab10", edgecolor="none", s=8,
#            aspect=1.0,
#        )
#        g.set_titles(row_template="{row_name}")
#        #g.fig.subplots_adjust(hspace=0.1)
#        for ax in g.axes.flat:
#            ax.set_xticks([])
#            ax.set_yticks([])
#            ax.set_xlabel("UMAP 1")
#            ax.set_ylabel("UMAP 2")
#        sns.despine()
#        leg = g._legend
#        leg.set_bbox_to_anchor([0.5, 1.0])
#        leg._loc = 8
#        plt.tight_layout()
#        plt.savefig(output[0], bbox_inches='tight')
#        plt.close()
#        g = sns.relplot(
#            data=df, x="UMAP 1", y="UMAP 2",
#            row="Quantification",
#            #row_order=["Gene expression", "kallisto", "DEXSeq", "ODEGR-NMF", "DESJ", "LeafCutter", "Skipped exons", "scQuint"],
#            row_order=["Gene expression", "DEXSeq", "DESJ", "LeafCutter", "Skipped exons", "scQuint"],
#            hue="Plate ID",
#            kind="scatter",
#            facet_kws={'sharey': False, 'sharex': False, "margin_titles": False},
#            height=2.0, palette=["C3", "C4"], edgecolor="none", s=8,
#            aspect=1.0,
#            #legend=False,
#        )
#        g.set_titles(row_template="{row_name}")
#        #g.fig.subplots_adjust(hspace=0.1)
#        for ax in g.axes.flat:
#            ax.set_xticks([])
#            ax.set_yticks([])
#            ax.set_xlabel("UMAP 1")
#            ax.set_ylabel("UMAP 2")
#        sns.despine()
#        leg = g._legend
#        leg.set_bbox_to_anchor([0.5, 1.0])
#        leg._loc = 8
#        #plt.savefig(output[1])
#        #plt.savefig(output[1], bbox_extra_artists=(leg,), bbox_inches='tight')
#        #plt.savefig(output[1], bbox_extra_artists=(leg,))
#        #g.get_figure().savefig(output[1], bbox_inches='tight')
#        #plt.subplots_adjust(top=0.95, right=0.95)
#        #g.savefig(output[1], bbox_inches='tight', bbox_extra_artists=(leg,))
#        plt.tight_layout()
#        plt.savefig(output[1], bbox_inches='tight')
#        plt.close()
#
#
#rule dimensionality_reduction_marrow_expression:
#    input:
#        "output/quantification/gene-expression/adata_annotated.h5ad",
#    output:
#        "output/dimensionality_reduction/marrow/gene-expression/pca_20/latent.txt",
#    run:
#        adata = anndata.read_h5ad(input[0])
#        adata = adata[(adata.obs.tissue=="Marrow")]
#        sc.pp.filter_genes(adata, min_cells=30)
#        sc.pp.normalize_total(adata, target_sum=1e4)
#        sc.pp.log1p(adata)
#        X = adata.X.toarray()
#        latent = PCA(n_components=20).fit_transform(X)
#        np.savetxt(output[0], latent)
#
#
#rule dimensionality_reduction_marrow_pca:
#    input:
#        "output/quantification/{quantification}/adata_annotated.h5ad",
#    output:
#        "output/dimensionality_reduction/marrow/{quantification}/pca_{K}/latent.txt",
#    wildcard_constraints: quantification='.+(?<!gene-expression)'
#    run:
#        adata = anndata.read_h5ad(input[0])
#        adata = adata[(adata.obs.tissue=="Marrow")]
#        adata = filter_min_cells_per_feature(adata, 30)
#        if wildcards["quantification"] == "introns-transitive":
#            adata = recluster(adata)
#        latent = run_pca(adata, int(wildcards["K"]))
#        np.savetxt(output[0], latent)
#
#
#rule dimensionality_reduction_tissue_pca:
#    input:
#        "output/quantification/{quantification}/adata_annotated.h5ad",
#    output:
#        "output/dimensionality_reduction/tissue/{tissue}/{quantification}/pca_{k}/latent.txt",
#    wildcard_constraints: quantification='.+(?<!gene-expression)'
#    run:
#        adata = anndata.read_h5ad(input[0])
#        adata = adata[(adata.obs.tissue==wildcards["tissue"])]
#        if wildcards["quantification"] != "bins-nmf":
#            adata = filter_min_cells_per_feature(adata, 100)
#        print(adata.shape)
#        if wildcards["quantification"] == "introns-transitive":
#            adata = recluster(adata)
#        print(adata.shape)
#        latent = run_pca(adata, int(wildcards["k"]))
#        np.savetxt(output[0], latent)
#
#
#rule dimensionality_reduction_tissue_vae:
#    input:
#        "output/quantification/{quantification}/adata_annotated.h5ad",
#    output:
#        "output/dimensionality_reduction/tissue/{tissue}/{quantification}/vae_{transform}_{sample}/latent.txt",
#    wildcard_constraints: quantification='.+(?<!gene-expression)'
#    resources:
#        gpu=1
#    run:
#        adata = anndata.read_h5ad(input[0])
#        adata = adata[(adata.obs.tissue==wildcards["tissue"])]
#        if wildcards["quantification"] != "bins-nmf":
#            adata = filter_min_cells_per_feature(adata, 100)
#        if np.isin(wildcards["quantification"], ["introns-transitive", "introns-transitive-shuffled", "leafcutter", "introns-subset-lc", "introns-subset-lc-nonfiltered"]):
#            adata = recluster(adata)
#        print(wildcards["quantification"], adata.shape)
#        input_transform = wildcards["transform"]
#        if input_transform == "frequency-smoothed":
#            feature_addition = group_normalize(adata.X.sum(axis=0), adata.var.cluster, smooth=False).A1.ravel()
#            print(feature_addition.shape)
#        else:
#            feature_addition = None
#        latent, model = run_vae(
#            adata, n_epochs_kl_warmup=30, regularization_gaussian_std=10.0,
#            use_cuda=True, input_transform=input_transform,
#            feature_addition=feature_addition, sample=wildcards["sample"]=="True" or wildcards["sample"]=="true",
#        )
#        np.savetxt(output[0], latent)
#
#
#rule dimensionality_reduction_tissue_expression:
#    input:
#        "output/quantification/gene-expression/adata_annotated.h5ad",
#    output:
#        "output/dimensionality_reduction/tissue/{tissue}/gene-expression/pca_{k}/latent.txt",
#    run:
#        adata = anndata.read_h5ad(input[0])
#        adata = adata[(adata.obs.tissue==wildcards["tissue"])]
#        sc.pp.filter_genes(adata, min_cells=100)
#        sc.pp.normalize_total(adata, target_sum=1e4)
#        sc.pp.log1p(adata)
#        X = adata.X.toarray()
#        latent = PCA(n_components=int(wildcards["k"])).fit_transform(X)
#        np.savetxt(output[0], latent)
#
#
#rule dimensionality_reduction_tissue_joint_pca:
#    input:
#        "output/quantification/gene-expression/adata_annotated.h5ad",
#        "output/quantification/introns-shared-acceptor/adata_annotated.h5ad",
#    output:
#        "output/dimensionality_reduction/tissue/{tissue}/joint/pca_{k}/latent.txt",
#    run:
#        adata_exp = anndata.read_h5ad(input[0])
#        adata_exp = adata_exp[(adata_exp.obs.tissue==wildcards["tissue"])]
#        sc.pp.filter_genes(adata_exp, min_cells=30)
#        sc.pp.normalize_total(adata_exp, target_sum=1e4)
#        sc.pp.log1p(adata_exp)
#        X_exp = adata_exp.X.toarray()
#
#        adata_spl = anndata.read_h5ad(input[1])
#        adata_spl = adata_spl[(adata_spl.obs.tissue==wildcards["tissue"])]
#        adata_spl = filter_min_cells_per_feature(adata_spl, 30)
#        X_spl = group_normalize(adata_spl.X.toarray(), adata_spl.var.cluster.values, smooth=True)
#        intron_clusters = adata_spl.var.cluster.values
#        all_intron_clusters = np.unique(intron_clusters)
#        first_indices_dict = {}
#        for i, c in enumerate(intron_clusters):
#            if c not in first_indices_dict:
#                first_indices_dict[c] = i
#        first_indices = np.array([first_indices_dict[c] for c in all_intron_clusters])
#        X_spl = np.delete(X_spl, first_indices, axis=1)
#
#        X = np.hstack([X_exp, X_spl])
#        print(X_exp.shape, X_spl.shape, X.shape)
#
#        latent = PCA(n_components=int(wildcards["k"])).fit_transform(X)
#        np.savetxt(output[0], latent)
#
#
##
##
#rule compare_latent_tissue:
#    input:
#        "output/dimensionality_reduction/tissue/{tissue}/gene-expression/pca_20/latent.txt",
#        "output/dimensionality_reduction/tissue/{tissue}/introns-shared-acceptor/pca_20/latent.txt",
#        "output/dimensionality_reduction/tissue/{tissue}/joint/pca_20/latent.txt",
#        #"output/dimensionality_reduction/tissue/{tissue}/introns-shared-acceptor/vae_frequency-smoothed_False/latent.txt",
#    output:
#        expand("output/comparison/tissue/{{tissue}}/{label}.svg", label=labels)
#    run:
#        obs = sample_info.copy()
#        idx = np.where((obs.tissue==wildcards["tissue"]))[0]
#        obs = obs.iloc[idx]
#
#        dfs = []
#        names = ["Expression", "Splicing", "Joint"]
#        for name, input_path in zip(names, input):
#            df = obs.copy()
#            latent = np.loadtxt(input_path)
#
#            proj = UMAP(min_dist=0.5, n_neighbors=15, random_state=42).fit_transform(latent)
#            df["UMAP 1"] = proj[:, 0]
#            df["UMAP 2"] = proj[:, 1]
#            df["Quantification"] = name
#            dfs.append(df)
#        df = pd.concat(dfs)
#        for i, label in enumerate(labels):
#            g = sns.relplot(
#                data=df, x="UMAP 1", y="UMAP 2",
#                col="Quantification", hue=label,
#                kind="scatter", facet_kws={'sharey': False, 'sharex': False},
#                height=3, palette="tab20", edgecolor="none", s=4,
#               )
#            g.set_titles(col_template="{col_name}")
#            g.fig.subplots_adjust(wspace=0.1)
#            for ax in g.axes.flat:
#                ax.set_xticks([])
#                ax.set_yticks([])
#                ax.set_ylabel("UMAP 2")
#            sns.despine()
#            plt.savefig(output[i], bbox_inches='tight')
#
#
#rule leafcutter_extract:
#    input:
#        "output/mapping/filtered_bams/{sample_id}.bam",
#    output:
#        "output/quantification/leafcutter/juncs/{sample_id}.junc"
#    shell:
#        """
#        samtools index {input} &&
#        regtools junctions extract -s0 -a 8 -m 50 -M 500000 {input} -o {output}
#        """
#
#
#rule leafcutter_prepare_junc_files:
#    input:
#        expand("output/quantification/leafcutter/juncs/{sample_id}.junc", sample_id=sample_ids_leafcutter),
#    output:
#        "output/quantification/leafcutter/juncfiles.txt",
#    run:
#        for path in input:
#            shell(f"echo {path} >> {output}")
#
#
#rule leafcutter_cluster:
#    input:
#        "output/quantification/leafcutter/juncfiles.txt",
#    output:
#        "output/quantification/leafcutter/_perind_numers.counts.gz",
#    shell:
#        """
#        ~/miniconda2/bin/python leafcutter/clustering/leafcutter_cluster_regtools.py --checkchrom -j {input} -m 50 -o output/quantification/leafcutter/ -l 500000
#        """
#
#
#rule leafcutter_make_adata:
#    input:
#        "output/quantification/leafcutter/_perind_numers.counts.gz",
#    output:
#        "output/quantification/leafcutter/adata.h5ad",
#    run:
#        df = pd.read_csv(input[0], " ", index_col=0).T
#        print(df)
#        df = df.loc[sample_ids_leafcutter]
#        print(df)
#        X = sp_sparse.csr_matrix(df.values)
#        print(X.shape)
#        obs = pd.DataFrame(index=df.index)
#        print(obs)
#        var = pd.DataFrame(index=df.columns)
#        var["chromosome"] = var.index.str.split(":").str[0]
#        var["start"] = var.index.str.split(":").str[1]
#        var["end"] = var.index.str.split(":").str[2]
#        var["cluster"] = var.index.str.split(":").str[3]
#        print(var)
#        adata = anndata.AnnData(X=X, obs=obs, var=var)
#        print(adata.shape)
#        adata = filter_min_cells_per_feature(adata, 30)
#        print(adata.shape)
#        adata = recluster(adata)
#        print(adata.shape)
#        adata.var["original_cluster"] = adata.var.cluster
#        adata.write(output[0], compression="gzip")
#
#
###methods_compare_latent_all = ["gene-expression/pca_20", "introns-shared-acceptor/pca_100_20", "introns-shared-acceptor/vae_hyperopt"]
methods_compare_latent_all = ["gene-expression/pca_40", "introns-shared-acceptor/vae_hyperopt"]
###methods_compare_latent_all = ["gene-expression/pca_20", "introns-shared-acceptor/vae_frequency-smoothed_False_100", "introns-shared-acceptor/vae_hyperopt"]
###methods_compare_latent_all_names = ["Expression", "Splicing-PCA", "Splicing-VAE"]
methods_compare_latent_all_names = ["Expression", "Splicing"]
##methods_compare_latent_all_names = ["Expression", "Splicing-VAE", "Splicing-PCA", "Splicing-PCA-HV"]
##
#rule compare_latent_all:
#    input:
#        expand(
#            "output/dimensionality_reduction/all/{method}/latent.txt",
#            method=methods_compare_latent_all,
#        )
#    output:
#        directory("output/comparison/all"),
#    run:
#        obs = sample_info
#        latents = [np.loadtxt(input_path) for input_path in input]
#        latent_names = methods_compare_latent_all_names
#
#        new_clusters_exp = pd.read_csv("output/comparison/Liver-hepatocyte/clusters_exp.tsv", "\t", index_col=0)
#        obs = obs.merge(new_clusters_exp, how="left", left_index=True, right_index=True)
#        new_clusters_spl = pd.read_csv("output/comparison/Liver-hepatocyte/clusters_spl.tsv", "\t", index_col=0)
#        obs = obs.merge(new_clusters_spl, how="left", left_index=True, right_index=True)
#
#        print(obs.head())
#        #obs["Cell_type_cluster"] = obs.cell_ontology_class + "_" + obs.Cluster.astype(str)
#        #obs["Cell_type_cluster"] = obs.cell_ontology_class + "_" + obs.Cluster.astype(str)
#        print(obs.head())
#        #print(obs.Cluster.value_counts())
#
#        labels_list = [obs.cell_ontology_class, obs.sex, obs["mouse.id"], obs.plate_id, obs.tissue, obs.subtissue, obs.cluster_exp, obs.cluster_spl]
#        label_names = ["Cell type", "Sex", "Individual", "Plate", "Tissue", "Subtissue", "Cluster exp", "Cluster spl"]
#        projector = lambda: UMAP(min_dist=0.5, n_neighbors=15, random_state=42)
#        projector_name = "UMAP_15"
#        main_path = output[0]
#
#        path = os.path.join(main_path, "all")
#        plot_comparison(latents, latent_names, slice(None), labels_list, label_names, path, projector=projector, save=True)
#
#        for tissue in obs.tissue.unique():
#            path = os.path.join(main_path, "tissue", tissue, projector_name)
#            plot_comparison(latents, latent_names, np.where(obs.tissue==tissue)[0], labels_list, label_names, path, projector=projector, save=True)
#
#        path = os.path.join(main_path, "mg_individual_3_56_F", projector_name)
#        plot_comparison(latents, latent_names, np.where((obs.tissue=="Mammary_Gland") & (obs["mouse.id"]=="3_56_F"))[0], labels_list, label_names, path, projector=projector, save=True)
#        path = os.path.join(main_path, "mg_individual_3_57_F", projector_name)
#        plot_comparison(latents, latent_names, np.where((obs.tissue=="Mammary_Gland") & (obs["mouse.id"]=="3_57_F"))[0], labels_list, label_names, path, projector=projector, save=True)
#        path = os.path.join(main_path, "mg_individual_3_38_F", projector_name)
#        plot_comparison(latents, latent_names, np.where((obs.tissue=="Mammary_Gland") & (obs["mouse.id"]=="3_38_F"))[0], labels_list, label_names, path, projector=projector, save=True)
#        path = os.path.join(main_path, "mg_individual_3_39_F", projector_name)
#        plot_comparison(latents, latent_names, np.where((obs.tissue=="Mammary_Gland") & (obs["mouse.id"]=="3_39_F"))[0], labels_list, label_names, path, projector=projector, save=True)
#
#        path = os.path.join(main_path, "Marrow_B", projector_name)
#        plot_comparison(latents, latent_names, np.where((obs.tissue=="Marrow") & (obs.cell_ontology_class.str.endswith("B cell")))[0], labels_list, label_names, path, projector=projector, save=True)
#
#        #for tissue in obs.tissue.unique():
#        #    for cell_type in obs[obs.tissue==tissue].cell_ontology_class.unique():
#        #        idx = np.where((obs.tissue==tissue) & (obs.cell_ontology_class==cell_type))[0]
#        #        if len(idx) < 100: continue
#        #        path = os.path.join(main_path, "tissue_cell_type", tissue + "_" + cell_type, projector_name)
#        #        plot_comparison(latents, latent_names, idx, labels_list, label_names, path, projector=projector, save=True)
#
#
#rule compare_new_clusters:
#    input:
#        expand(
#            "output/dimensionality_reduction/all/{method}/latent.txt",
#            method=methods_compare_latent_all,
#        )
#    output:
#        directory("output/comparison/{tissue}-{cell_type}/"),
#    run:
#        obs = sample_info
#        cell_idx = np.where((obs.tissue==wildcards["tissue"])&(obs.cell_type==wildcards["cell_type"]))[0]
#        obs = obs.iloc[cell_idx].copy()
#        print(obs.shape)
#        latents = [np.loadtxt(input_path)[cell_idx] for input_path in input]
#
#        latent_exp = latents[0]
#        latent_spl = latents[1]
#
#        obs["cluster_exp"] = SpectralClustering(n_clusters=4, random_state=42, affinity="nearest_neighbors", n_neighbors=15).fit_predict(latent_exp)
#        obs["cluster_spl"] = SpectralClustering(n_clusters=2, random_state=42, affinity="nearest_neighbors", n_neighbors=15).fit_predict(latent_spl)
#        print(obs.cluster_exp.value_counts())
#        print(obs.cluster_spl.value_counts())
#
#        latent_names = methods_compare_latent_all
#        labels_list = [obs.cell_ontology_class, obs.sex, obs["mouse.id"], obs.plate_id, obs.tissue, obs.cluster_exp, obs.cluster_spl]
#        label_names = ["Cell type", "Sex", "Individual", "Plate", "Tissue", "Cluster exp", "Cluster spl"]
#        projector = lambda: UMAP(min_dist=0.5, n_neighbors=15, random_state=42)
#        projector_name = "UMAP_15"
#        main_path = output[0]
#
#        os.makedirs(main_path)
#        obs.cluster_exp.to_csv(os.path.join(main_path, "clusters_exp.tsv"), "\t")
#        obs.cluster_spl.to_csv(os.path.join(main_path, "clusters_spl.tsv"), "\t")
#
#        path = main_path
#        plot_comparison(latents, latent_names, slice(None), labels_list, label_names, path, projector=projector, save=True)
#
#
#rule differential_test_new_clusters:
#    input:
#        "output/quantification/gene-expression/adata_annotated.h5ad",
#        "output/quantification/introns-shared-acceptor/adata_annotated.h5ad",
#        "output/comparison/{tissue}-{cell_type}/clusters_spl.tsv",
#    output:
#        'output/differential_splicing/new_clusters/{tissue}/{cell_type}/expression.tsv',
#        'output/differential_splicing/new_clusters/{tissue}/{cell_type}/splicing.clusters.tsv',
#        'output/differential_splicing/new_clusters/{tissue}/{cell_type}/splicing.introns.tsv',
#    run:
#        adata_exp = anndata.read_h5ad(input[0])
#        adata_exp.obs.index = adata_exp.obs.index.astype(str)
#        adata_spl = anndata.read_h5ad(input[1])
#        adata_spl.obs.index = adata_spl.obs.index.astype(str)
#        adata_spl.var.index = adata_spl.var.index.astype(str)
#        assert((adata_exp.obs.index == adata_spl.obs.index).all())
#        clusters = pd.read_csv(input[2], "\t", index_col=0)
#        print(clusters)
#        adata_exp = adata_exp[clusters.index.values]
#        adata_spl = adata_spl[clusters.index.values]
#        print(adata_exp.shape, adata_spl.shape)
#
#        obs = adata_exp.obs
#        obs.loc[:, "cell_type"] = obs.cell_ontology_class.str.replace(" ", "_").str.replace("-", "_")
#        cell_idx_a = np.where((clusters.cluster_spl==1))[0]
#        cell_idx_b = np.where((clusters.cluster_spl==0))[0]
#        print(len(cell_idx_a), len(cell_idx_b))
#        MIN_FEATURES = 30
#        diff_exp = run_differential_expression(adata_exp, cell_idx_a, cell_idx_b, MIN_FEATURES)
#        diff_exp.to_csv(output[0], '\t', index=False)
#        diff_spl_clusters, diff_spl_introns = run_differential_splicing(
#            adata_spl,
#            cell_idx_a,
#            cell_idx_b,
#            min_cells_per_cluster=MIN_FEATURES,
#            min_total_cells_per_intron=MIN_FEATURES,
#            n_jobs=2,
#            do_recluster=False,
#        )
#        diff_spl_clusters.to_csv(output[1], '\t')
#        diff_spl_introns.to_csv(output[2], '\t')
#
#
#rule prepare_adata_for_cellxgene_exp_spl:
#    input:
#        "output/quantification/gene-expression/adata_annotated.h5ad",
#        "output/quantification/introns-shared-acceptor/adata_annotated.h5ad",
#        "output/gene_name.txt",
#        #"output/dimensionality_reduction/all/introns-shared-acceptor/pca_300_20/latent.txt",
#        "output/dimensionality_reduction/all/gene-expression/pca_40/latent.txt",
#        "output/dimensionality_reduction/all/introns-shared-acceptor/vae_hyperopt/latent.txt",
#    output:
#        #"output/adata_cellxgene_spl_pca.h5ad",
#        "output/adata_cellxgene_exp_spl.h5ad",
#    run:
#        gene_name = pd.read_csv(input[2], "\t", index_col=0)
#        latent_exp = np.loadtxt(input[3])
#        latent_spl = np.loadtxt(input[4])
#        adata_exp = anndata.read_h5ad(input[0])
#        adata_exp.var = adata_exp.var.merge(gene_name, how="left", left_index=True, right_index=True)
#        adata_exp.var["gene_id"] = adata_exp.var.index.values
#        adata_exp.var = adata_exp.var.set_index("gene_name")
#        adata_exp.var_names_make_unique()
#        adata_exp.obs.index = adata_exp.obs.index.astype(str)
#        adata_spl = anndata.read_h5ad(input[1])
#        adata_spl.var = adata_spl.var.merge(gene_name, how="left", left_on="gene_id", right_index=True)
#        adata_spl.var["id"] = adata_spl.var.gene_name + "_" + adata_spl.var.chromosome.astype(str) + ":" + adata_spl.var.start.astype(str) + "-" + adata_spl.var.end.astype(str)
#        adata_spl.var = adata_spl.var.set_index("id", drop=False)
#        adata_spl.obs.index = adata_spl.obs.index.astype(str)
#        adata_spl.var.index = adata_spl.var.index.astype(str)
#        assert((adata_exp.obs.index == adata_spl.obs.index).all())
#        sc.pp.normalize_total(adata_exp, target_sum=1e4)
#        sc.pp.log1p(adata_exp)
#        adata_exp.X = adata_exp.X.toarray()
#        adata_spl.X = group_normalize(adata_spl.X.toarray(), adata_spl.var.cluster.values, smooth=False)
#
#        X = np.hstack((adata_exp.X, adata_spl.X))
#        print(adata_exp.shape, adata_spl.shape, X.shape)
#        obs = adata_exp.obs
#        var = pd.concat([adata_exp.var, adata_spl.var])
#        adata = anndata.AnnData(X=X, obs=obs, var=var)
#        adata.obsm["X_umap"] = UMAP(min_dist=0.5, n_neighbors=15, random_state=42).fit_transform(latent_exp)
#        adata.obsm["X_umap_spl"] = UMAP(min_dist=0.5, n_neighbors=15, random_state=42).fit_transform(latent_spl)
#        adata.write_h5ad(output[0], compression="gzip")
#
#
#rule make_bam_paths_new_clusters:
##    input:
##        expand("output/mapping/filtered_bams/{sample_id}.bam", sample_id=sample_ids)
#    output:
#        "output/bam_paths/new_clusters/{tissue}/{cell_type}/{cluster}.txt",
#    run:
#        obs = sample_info.copy()
#        new_clusters = pd.read_csv(f"output/comparison/{wildcards.tissue}-{wildcards.cell_type}/clusters.tsv", "\t", index_col=0)
#        obs = obs.merge(new_clusters, how="left", left_index=True, right_index=True)
#        obs.Cluster = obs.Cluster.astype(str)
#        s_ids = sample_ids[np.where(
#            (obs.tissue==wildcards["tissue"]) &
#            (obs.cell_ontology_class==wildcards["cell_type"]) &
#            (obs.Cluster==wildcards["cluster"])
#        )[0]]
#        print(wildcards["cluster"], len(s_ids))
#        cwd = os.getcwd()
#        pd.DataFrame(dict(sample_id=s_ids, bam_path=[f"{cwd}/output/mapping/filtered_bams/{sample_id}.bam" for sample_id in s_ids])).to_csv(output[0], "\t", index=False, header=False)
#
#
#rule make_coverage_track_bigwig_new_clusters:
#    input:
#        "output/bam_paths/new_clusters/{tissue}/{cell_type}/{cluster}.txt",
#    output:
#        "output/coverage_track/new_clusters/{tissue}/{cell_type}/{cluster}/coverage.bw",
#    threads: workflow.cores // 2
#    shell:
#        "python -m scquint.quantification.run coverage_track/Snakefile --cores {threads} -d output/coverage_track/new_clusters/{wildcards.tissue}/{wildcards.cell_type}/{wildcards.cluster}/ --config bam_paths=../../../../../bam_paths/new_clusters/{wildcards.tissue}/{wildcards.cell_type}/{wildcards.cluster}.txt chrom_sizes_path={chrom_sizes_path}"
#
#
#rule compare_latent_pca_vae:
#    input:
#        "output/dimensionality_reduction/all/gene-expression/pca_20/latent.txt",
#        "output/dimensionality_reduction/all/introns-shared-acceptor/pca_100_20/latent.txt",
#        "output/dimensionality_reduction/all/introns-shared-acceptor/vae_hyperopt/latent.txt",
#    output:
#        "output/comparison/pca_vae/{tissue}/cell_type.svg",
#    run:
#        cell_idx = np.where(sample_info.tissue==wildcards["tissue"])[0]
#        dfs = []
#        names = ["Expression", "Splicing (PCA)", "Splicing (VAE)"]
#        for name, input_path in zip(names, input):
#            df = sample_info.iloc[cell_idx].copy()
#            latent = np.loadtxt(input_path)[cell_idx]
#            proj = UMAP(min_dist=0.5, n_neighbors=15, random_state=42).fit_transform(latent)
#            df["UMAP 1"] = proj[:, 0]
#            df["UMAP 2"] = proj[:, 1]
#            df["Quantification"] = name
#            dfs.append(df)
#        df = pd.concat(dfs)
#        g = sns.relplot(
#            data=df,
#            x="UMAP 1",
#            y="UMAP 2",
#            hue="Cell type",
#            col="Quantification",
#            col_order=names,
#            kind="scatter",
#            facet_kws={'sharey': False, 'sharex': False},
#            height=3,
#            palette="tab10",
#            edgecolor="none",
#            s=4,
#        )
#        g.set_titles(col_template="{col_name}")
#        g.fig.subplots_adjust(wspace=0.1)
#        for ax in g.axes.flat:
#            ax.set_xticks([])
#            ax.set_yticks([])
#            ax.set_ylabel("UMAP 2")
#        sns.despine()
#        plt.savefig(output[0], bbox_inches='tight')
#
#
#rule plot_hepatocytes_diff_spl:
#    input:
#        "output/quantification/introns-shared-acceptor/adata_annotated.h5ad",
#        'output/differential_splicing/new_clusters/Liver/hepatocyte/splicing.clusters.significant.tsv',
#        'output/differential_splicing/new_clusters/Liver/hepatocyte/splicing.introns.tsv',
#    output:
#        directory('output/differential_splicing/new_clusters/Liver/hepatocyte/plots'),
#    run:
#        adata = anndata.read_h5ad(input[0])
#        print(adata.shape)
#        adata.obs["Cell type"] = adata.obs.cell_ontology_class
#        adata = adata[(adata.obs.cell_ontology_class=="hepatocyte") & (adata.obs.subtissue=="Hepatocytes")]
#        new_clusters = pd.read_csv("output/comparison/Liver-hepatocyte/clusters.tsv", "\t", index_col=0)
#        adata.obs = adata.obs.merge(new_clusters, how="left", left_index=True, right_index=True)
#        adata.obs.Cluster = adata.obs.Cluster.astype(str)
#        print(adata.shape)
#        print(adata.obs.Cluster.value_counts())
#        print(adata.obs["mouse.id"].value_counts())
#        print(adata.obs.plate_id.value_counts())
#
#        intron_clusters = pd.read_csv(input[1], "\t")
#        gene_names = ["Echdc2", "Arid5b", "Lsr", "Ypel5", "BC024386", "Mgmt", "Gm30262", "Ndrg2", "Ssbp1", "St3gal5", "Adipor1", "Rpl34", "Polr2k"]
#        intron_clusters = intron_clusters[intron_clusters.gene_name.isin(gene_names)]
#        introns = pd.read_csv(input[2], "\t")
#        introns = introns[introns.cluster.isin(intron_clusters.cluster.unique())]
#        introns["id"] = introns.chromosome.astype(str) + ":" + introns.start.astype(str) + "-" + introns.end.astype(str)
#        introns = introns.set_index("id")
#        print(introns)
#
#        var = adata.var.copy()
#        var["id"] = var.chromosome.astype(str) + ":" + var.start.astype(str) + "-" + var.end.astype(str)
#        adata.var = var.set_index("id")
#        adata = adata[:, introns.index]
#        adata = filter_singletons(adata)
#        print(adata.shape)
#        adata.X = group_normalize(adata.X.toarray(), adata.var.cluster.values, smooth=False)
#
#        i = -1
#        for intron_id, intron in introns.iterrows():
#            i += 1
#            if i % 10 == 0: print(i)
#            print(intron_id)
#            obs = adata.obs.copy()
#            obs["PSI"] = adata[:, intron_id].X.ravel()
#
#            def robust_mean(series):
#                if (~series.isna()).sum() >= 3:
#                    return series.mean()
#                else:
#                    return np.nan
#
#            groupby = obs.groupby(["mouse.id", "Cluster"]).agg({"PSI": robust_mean}).reset_index()
#            groupby = groupby.rename(columns={'PSI' : 'mean_PSI'})
#
#            #g = sns.catplot(
#            #    data=groupby, kind="point",
#            #    x="mouse.id", y="mean_PSI", hue="Cluster",
#            #    ci="sd",
#            #    join=False,
#            #    dodge=True,
#            #)
#            #
#            g = sns.catplot(
#                x="Cluster", y="mean_PSI",
#                col="mouse.id",
#                data=groupby, kind="point",
#                height=2,
#            )
#
#
#            dir = os.path.join(output[0], intron.gene_id, str(intron.cluster))
#            if not os.path.exists(dir):
#                os.makedirs(dir)
#            plt.savefig(os.path.join(dir, intron_id + ".pdf"), bbox_inches='tight')
#            plt.close()
#
#
#rule psi_plot_hepatocyte_new_clusters:
#    input:
#        "output/quantification/introns-shared-acceptor/adata_annotated.h5ad",
#    output:
#        directory("output/plots/hepatocyte_new_clusters/"),
#    run:
#        adata = anndata.read_h5ad(input[0])
#        adata = adata[adata.obs.cell_ontology_class=="hepatocyte"]
#        new_clusters = pd.read_csv("output/comparison/Liver-hepatocyte/clusters_spl.tsv", "\t", index_col=0)
#        adata.obs = adata.obs.merge(new_clusters, how="left", left_index=True, right_index=True)
#        adata.obs["Cluster"] = adata.obs.cluster_spl.astype(int).astype(str)
#        print(adata.obs.Cluster.value_counts())
#
#        adata.X = group_normalize(adata.X.toarray(), adata.var.cluster.values, smooth=False)
#        var = adata.var.copy()
#        var["id"] = var.chromosome.astype(str) + ":" + var.start.astype(str) + "-" + var.end.astype(str)
#        adata.var = var.set_index("id")
#
#        introns = [
#            "chr4:108170227-108172089",  # Echdc2
#            "chr3:130729303-130730121",  # Rpl34
#            "chr7:30962245-30962811", # Lsr
#        ]
#
#        for i, intron in enumerate(introns):
#            obs = adata.obs.copy()
#            obs["PSI"] = adata[:, intron].X.ravel()
#
#            g = sns.FacetGrid(
#                obs,
#                col="Cluster",
#                hue="Cluster",
#                palette="tab10",
#                sharex=False,
#                sharey=True,
#                #height=1.5,
#                height=2,
#                aspect=1,
#            )
#            eps = 1e-4
#            g.map_dataframe(
#                sns.histplot,
#                y="PSI",
#                bins=np.linspace(0-eps, 1+eps, 11),
#                stat="probability",
#            )
#            g.fig.subplots_adjust(wspace=0)
#            g.set_titles(col_template="Cluster {col_name}")
#            g.set_ylabels("PSI")
#            g.set(xticks=[])
#            g.set(xlim=(0, 1), ylim=(0, 1))
#            sns.despine(bottom=True)
#            dir = output[0]
#            if not os.path.exists(dir):
#                os.makedirs(dir)
#            plt.savefig(os.path.join(dir, intron + ".svg"), bbox_inches='tight')
#
#
#rule exp_plot_hepatocyte_new_clusters:
#    input:
#        "output/quantification/gene-expression/adata_annotated.h5ad",
#    output:
#        directory("output/plots/hepatocyte_new_clusters_exp/"),
#    run:
#        adata = anndata.read_h5ad(input[0])
#        adata = adata[adata.obs.cell_ontology_class=="hepatocyte"]
#        new_clusters = pd.read_csv("output/comparison/Liver-hepatocyte/clusters_spl.tsv", "\t", index_col=0)
#        adata.obs = adata.obs.merge(new_clusters, how="left", left_index=True, right_index=True)
#        adata.obs["Cluster"] = "Cluster " + adata.obs.cluster_spl.astype(int).astype(str)
#
#        sc.pp.normalize_total(adata, target_sum=1e4)
#        sc.pp.log1p(adata)
#        genes = [
#            "ENSMUSG00000028601", # Echdc2
#            "ENSMUSG00000062006",  # Rpl34
#            "ENSMUSG00000001247",  # Lsr
#        ]
#        for i, gene in enumerate(genes):
#            obs = adata.obs.copy()
#            obs["log norm. expression"] = adata[:, gene].X.toarray().ravel()
#            print(obs.groupby("Cluster")["log norm. expression"].mean())
#            plt.figure(figsize=(3, 2))
#            g = sns.violinplot(
#                data=obs,
#                x="Cluster",
#                y="log norm. expression",
#                #hue="Cell type",
#                #hue_order=cell_type_order,
#                palette="tab10",
#                cut=0.05,
#                scale="width",
#                width=0.75,
#            )
#            g.set(xlabel=None)
#            sns.despine(bottom=True)
#            dir = output[0]
#            if not os.path.exists(dir):
#                os.makedirs(dir)
#            plt.savefig(os.path.join(dir, gene + ".svg"), bbox_inches='tight')
#            plt.close()
#            plt.clf()
#
#
#rule compare_latent_tissue:
#    input:
#        #"output/dimensionality_reduction/tissue/{tissue}/gene-expression/pca_20/latent.txt",
#        #"output/dimensionality_reduction/tissue/{tissue}/introns-shared-acceptor/pca_20/latent.txt",
#        #"output/dimensionality_reduction/tissue/{tissue}/joint/pca_20/latent.txt",
#        #"output/dimensionality_reduction/tissue/{tissue}/introns-shared-acceptor/vae_frequency-smoothed_False/latent.txt",
#        expand(
#            "output/dimensionality_reduction/all/{method}/latent.txt",
#            method=methods_compare_latent_all,
#        )
#    output:
#        expand("output/comparison/tissue/{{tissue}}/{label}.svg", label=labels)
#    run:
#        obs = sample_info.copy()
#        idx = np.where((obs.tissue==wildcards["tissue"]))[0]
#        obs = obs.iloc[idx]
#
#        new_clusters = pd.read_csv("output/comparison/Liver-hepatocyte/clusters_spl.tsv", "\t", index_col=0)
#        obs = obs.merge(new_clusters, how="left", left_index=True, right_index=True)
#        obs_notna = obs[~(obs.cluster_spl.isna())]
#        obs_notna["Cluster"] = "cluster " + obs_notna.cluster_spl.astype(int).astype(str)
#        obs_notna["Cell type"] = obs_notna["Cell type"] + " " + obs_notna.Cluster
#        obs.loc[~(obs.cluster_spl.isna()), "Cell type"] = obs_notna["Cell type"].values
#        print(obs["Cell type"].value_counts())
#
#        dfs = []
#        names = ["Expression latent space", "Splicing latent space"]
#        for name, input_path in zip(names, input):
#            df = obs.copy()
#            latent = np.loadtxt(input_path)[idx]
#
#            proj = UMAP(min_dist=0.5, n_neighbors=15, random_state=42).fit_transform(latent)
#            df["UMAP 1"] = proj[:, 0]
#            df["UMAP 2"] = proj[:, 1]
#            df["Quantification"] = name
#            dfs.append(df)
#        df = pd.concat(dfs)
#        for i, label in enumerate(labels):
#            g = sns.relplot(
#                data=df, x="UMAP 1", y="UMAP 2",
#                col="Quantification", hue=label,
#                kind="scatter", facet_kws={'sharey': False, 'sharex': False},
#                height=3, palette="tab20", edgecolor="none", s=4,
#                hue_order=obs["Cell type"].value_counts().index.values if label=="Cell type" else None
#               )
#            g.set_titles(col_template="{col_name}")
#            g.fig.subplots_adjust(wspace=0.1)
#            for ax in g.axes.flat:
#                ax.set_xticks([])
#                ax.set_yticks([])
#                ax.set_ylabel("UMAP 2")
#            sns.despine()
#            plt.savefig(output[i], bbox_inches='tight')
#
#
#rule plot_marker_introns_hepatocyte_clusters:
#    input:
#        "output/quantification/introns-shared-acceptor/adata_annotated.h5ad",
#        "output/differential_splicing/new_clusters/Liver/hepatocyte/marker_introns.tsv",
#    output:
#        "output/differential_splicing/new_clusters/Liver/hepatocyte/marker_introns.svg",
#    run:
#        adata_spl = anndata.read_h5ad(input[0])
#        adata_spl.var["id"] = adata_spl.var.chromosome.astype(str) + ":" + adata_spl.var.start.astype(str) + "-" + adata_spl.var.end.astype(str)
#        adata_spl.var = adata_spl.var.set_index("id")
#
#        new_clusters = pd.read_csv("output/comparison/Liver-hepatocyte/clusters_spl.tsv", "\t", index_col=0)
#        adata_spl.obs = adata_spl.obs.merge(new_clusters, how="left", left_index=True, right_index=True)
#        print(adata_spl.shape)
#        adata_spl = adata_spl[~adata_spl.obs.cluster_spl.isna()]
#        adata_spl.obs.cluster_spl = adata_spl.obs.cluster_spl.astype(int).astype(str)
#        print(adata_spl.shape)
#
#        all_marker_introns = pd.read_csv(input[1], "\t", header=None).values.astype(str).ravel().tolist()[:20]
#
#        adata_spl.X = group_normalize(adata_spl.X.toarray(), adata_spl.var.cluster.values, smooth=False)
#        adata_spl = adata_spl[:, all_marker_introns]
#
#        gene_name = pd.read_csv("output/gene_name.txt", "\t", index_col=0)
#        adata_spl.var = adata_spl.var.merge(gene_name, how="left", left_on="gene_id", right_index=True)
#        adata_spl.var.loc[:, "id"] = adata_spl.var.gene_name.astype(str) + "_" + adata_spl.var.index
#        adata_spl.var = adata_spl.var.set_index("id")
#
#        g = sc.pl.matrixplot(
#            adata_spl,
#            adata_spl.var.index.values,
#            groupby='cluster_spl',
#            #categories_order=tissue_cell_types,
#            return_fig=True, vmin=0.0, vmax=1.0, cmap='coolwarm', swap_axes=True, colorbar_title="Mean PSI")
#        plt.tight_layout()
#        g.savefig(output[0], bbox_inches="tight")
#
#
#rule plot_marker_introns_dist_hepatocyte_clusters:
#    input:
#        "output/quantification/introns-shared-acceptor/adata_annotated.h5ad",
#        "output/differential_splicing/new_clusters/Liver/hepatocyte/marker_introns.tsv",
#    output:
#        "output/differential_splicing/new_clusters/Liver/hepatocyte/marker_introns_dist.svg",
#    run:
#        adata_spl = anndata.read_h5ad(input[0])
#        adata_spl.var["prev_id"] = adata_spl.var.index.values
#        adata_spl.var["id"] = adata_spl.var.chromosome.astype(str) + ":" + adata_spl.var.start.astype(str) + "-" + adata_spl.var.end.astype(str)
#        adata_spl.var = adata_spl.var.set_index("id")
#
#        new_clusters = pd.read_csv("output/comparison/Liver-hepatocyte/clusters_spl.tsv", "\t", index_col=0)
#        adata_spl.obs = adata_spl.obs.merge(new_clusters, how="left", left_index=True, right_index=True)
#        print(adata_spl.shape)
#        adata_spl = adata_spl[~adata_spl.obs.cluster_spl.isna()]
#        adata_spl.obs["Cluster"] = adata_spl.obs.cluster_spl.astype(int).astype(str)
#        print(adata_spl.shape)
#
#        all_marker_introns = pd.read_csv(input[1], "\t").head(10)
#        all_marker_introns = all_marker_introns.marker_intron.values
#
#        adata_spl.X = group_normalize(adata_spl.X.toarray(), adata_spl.var.cluster.values, smooth=False)
#        adata_spl = adata_spl[:, all_marker_introns]
#
#        gene_name = pd.read_csv("output/gene_name.txt", "\t", index_col=0)
#        adata_spl.var = adata_spl.var.merge(gene_name, how="left", left_on="gene_id", right_index=True)
#        #adata_spl.var.loc[:, "id"] = adata_spl.var.gene_name.astype(str) + "_" + adata_spl.var.index
#        adata_spl.var.loc[:, "id"] = adata_spl.var.gene_name.astype(str) + "_" + adata_spl.var.prev_id.astype(str)
#        adata_spl.var = adata_spl.var.set_index("id")
#
#        marker_introns = adata_spl.var.index.values
#        print("len(marker_introns): ", len(marker_introns))
#
#        obs = adata_spl.obs
#        obs.loc[:, marker_introns] = adata_spl.X
#        obs["sample_id"] = obs.index.values
#        obs = obs.melt(id_vars=["sample_id", "Cluster"], value_vars=marker_introns, var_name="Intron", value_name="PSI")
#
#        g = sns.FacetGrid(
#            obs,
#            col="Cluster",
#            hue="Cluster",
#            row="Intron",
#            palette="tab10",
#            sharex=False,
#            sharey=True,
#            height=1.5,
#            aspect=1,
#            margin_titles=True,
#        )
#        eps = 1e-4
#        #n_bins = 10
#        n_bins = 5
#        g.map_dataframe(
#            sns.histplot,
#            y="PSI",
#            bins=np.linspace(0-eps, 1+eps, n_bins+1),
#            stat="probability",
#        )
#        g = g.map(lambda y, **kw: plt.axhline(y.mean(), color=kw["color"], ls="--"), 'PSI')
#
#        g.fig.subplots_adjust(wspace=0.1, hspace=0.12)
#        g.set_titles(col_template="Cluster {col_name}", row_template="{row_name}")
#        g.set_ylabels("PSI")
#        g.set_xlabels("")
#        g.set(xticks=[])
#        g.set(xlim=(0, 1), ylim=(0, 1))
#        #sns.despine(bottom=True)
#        sns.despine()
#        g.savefig(output[0], bbox_inches="tight")
#
#
rule plot_marker_genes_hepatocyte_clusters:
    input:
        "output/quantification/gene-expression/adata_annotated.h5ad",
        "output/differential_splicing/new_clusters/Liver/hepatocyte/expression.tsv",
        "output/gene_name.txt",
    output:
        "output/differential_splicing/new_clusters/Liver/hepatocyte/marker_genes.svg",
    run:
        adata = anndata.read_h5ad(input[0])

        new_clusters = pd.read_csv("output/comparison/Liver-hepatocyte/clusters_spl.tsv", "\t", index_col=0)
        adata.obs = adata.obs.merge(new_clusters, how="left", left_index=True, right_index=True)
        print(adata.shape)
        #adata = adata[~adata.obs.cluster_spl.isna()]
        adata = adata[(~adata.obs.cluster_spl.isna()) & (adata.obs.subtissue=="Hepatocytes")]
        #adata.obs["Cluster"] = "Cluster " + adata.obs.cluster_spl.astype(int).astype(str)
        adata.obs["Cluster"] = adata.obs.cluster_spl.astype(int).astype(str)
        print(adata.shape)

        #marker_gene_ids = pd.read_csv(input[1], "\t").head(10).gene.values
        #marker_gene_ids = ["ENSMUSG00000054932", "ENSMUSG00000055653", "ENSMUSG00000029368"]
        marker_gene_ids = ["ENSMUSG00000026473", "ENSMUSG00000025479", "ENSMUSG00000076441", "ENSMUSG00000025533", "ENSMUSG00000029368"]
        #GLUL, CYP2E1, ASS1, ASL, and ALB
        gene_name = pd.read_csv(input[2], "\t", index_col=0)
        marker_gene_names = gene_name.loc[marker_gene_ids].values.ravel()
        print(marker_gene_ids, marker_gene_names)
        adata.var = adata.var.merge(gene_name, how="left", left_index=True, right_index=True)
        print(adata.var)

        sc.pp.normalize_total(adata, target_sum=1e4)
        sc.pp.log1p(adata)

        adata = adata[:, marker_gene_ids]
        adata.var = adata.var.set_index("gene_name")

        #g = sc.pl.stacked_violin(
        #    adata, marker_gene_names, groupby='Cluster', swap_axes=True,
        #    return_fig=True, row_palette="tab10",
        #)
        #plt.tight_layout()
        #g.savefig(output[0], bbox_inches="tight")

        obs = adata.obs
        obs.loc[:, marker_gene_names] = adata.X.toarray()

        for gene_name in marker_gene_names:
            print(gene_name)
            sorted_obs = obs[gene_name].sort_values()
            print(sorted_obs.head())
            print(sorted_obs.tail())
            obs.loc[sorted_obs.head(5).index.values, gene_name] = np.nan
            obs.loc[sorted_obs.tail(5).index.values, gene_name] = np.nan
            sorted_obs = obs[gene_name].sort_values()
            print(sorted_obs.head())
            print(sorted_obs.tail())

        #raise Exception("debug")
        obs["sample_id"] = obs.index.values
        obs = obs.melt(id_vars=["sample_id", "Cluster"], value_vars=marker_gene_names, var_name="Gene", value_name="Expr.")
        print(obs)

        g = sns.catplot(
            data=obs,
            x="Cluster",
            hue="Cluster",
            y="Expr.",
            row="Gene",
            palette="tab10",
            sharex=True,
            sharey=False,
            height=1.5,
            aspect=1.5,
            margin_titles=True,
            kind="violin",
            cut=0,
            scale="area",
#                scale="width",
#                width=0.75,
        )

        g.fig.subplots_adjust(wspace=0.1, hspace=0.12)
        g.set_titles(row_template="{row_name}")
        #plt.xticks(rotation=45)
        #plt.xlabel("")
        #g.set_ylabels("PSI")
        #g.set_xlabels("")
        #g.set(xticks=[])
        #g.set(xlim=(0, 1), ylim=(0, 1))
        #sns.despine(bottom=True)
        sns.despine()
        g.savefig(output[0], bbox_inches="tight")
#
#
#rule plot_libsize_hepatocyte_clusters:
#    input:
#        "output/quantification/gene-expression/adata_annotated.h5ad",
#    output:
#        "output/differential_splicing/new_clusters/Liver/hepatocyte/libsize.svg",
#    run:
#        adata = anndata.read_h5ad(input[0])
#
#        new_clusters = pd.read_csv("output/comparison/Liver-hepatocyte/clusters_spl.tsv", "\t", index_col=0)
#        adata.obs = adata.obs.merge(new_clusters, how="left", left_index=True, right_index=True)
#        print(adata.shape)
#        adata = adata[~adata.obs.cluster_spl.isna()]
#        #adata.obs["Cluster"] = "Cluster " + adata.obs.cluster_spl.astype(int).astype(str)
#        adata.obs["Cluster"] = adata.obs.cluster_spl.astype(int).astype(str)
#        print(adata.shape)
#
#        adata.obs["libsize"] = adata.X.sum(axis=1).A1.ravel()
#
#        ax = sns.violinplot(
#            x="Cluster", y="libsize", data=adata.obs, palette="tab10",
#            cut=0,
#        )
#
#        sns.despine()
#        plt.savefig(output[0], bbox_inches="tight")
#
#
#rule plot_percent_mito_hepatocyte_clusters:
#    input:
#        "output/quantification/gene-expression/adata_annotated.h5ad",
#        "output/gene_name.txt",
#    output:
#        "output/differential_splicing/new_clusters/Liver/hepatocyte/percent_mito.svg",
#    run:
#        adata = anndata.read_h5ad(input[0])
#        gene_name = pd.read_csv(input[1], "\t", index_col=0)
#        adata.var = adata.var.merge(gene_name, how="left", left_index=True, right_index=True)
#
#        adata.var['mt'] = adata.var.gene_name.str.startswith('mt-')
#        print(adata.var.mt.value_counts())
#        sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True)
#        adata = adata[adata.obs.pct_counts_mt < 20]
#        print(adata)
#
#        new_clusters = pd.read_csv("output/comparison/Liver-hepatocyte/clusters_spl.tsv", "\t", index_col=0)
#        adata.obs = adata.obs.merge(new_clusters, how="left", left_index=True, right_index=True)
#        print(adata.shape)
#        adata = adata[~adata.obs.cluster_spl.isna()]
#        adata.obs["Cluster"] = adata.obs.cluster_spl.astype(int).astype(str)
#        print(adata.shape)
#        print(adata.obs.groupby("Cluster").pct_counts_mt.median())
#
#        ax = sns.violinplot(
#            x="Cluster", y="pct_counts_mt", data=adata.obs, palette="tab10",
#            cut=0,
#        )
#        ax.axhline(y=5, linestyle="--", color="black", label="Recommended threshold")
#        plt.legend()
#
#        sns.despine()
#        plt.savefig(output[0], bbox_inches="tight")
#

#rule differential_test_marrow_b:
#    input:
#        "output/quantification/gene-expression/adata_annotated.h5ad",
#        "output/quantification/introns-shared-acceptor/adata_annotated.h5ad",
#    output:
#        'output/differential_splicing/marrow_b/{cell_type}/expression.tsv',
#        'output/differential_splicing/marrow_b/{cell_type}/splicing.clusters.tsv',
#        'output/differential_splicing/marrow_b/{cell_type}/splicing.introns.tsv',
#    threads: workflow.cores // 4
#    run:
#        adata_exp = anndata.read_h5ad(input[0])
#        adata_exp.obs.index = adata_exp.obs.index.astype(str)
#        adata_spl = anndata.read_h5ad(input[1])
#        adata_spl.obs.index = adata_spl.obs.index.astype(str)
#        adata_spl.var.index = adata_spl.var.index.astype(str)
#        assert((adata_exp.obs.index == adata_spl.obs.index).all())
#        obs = adata_exp.obs
#        obs = obs.replace("late pro-B cell", "(1) pro-B")
#        obs = obs.replace("precursor B cell", "(2) pre-B")
#        obs = obs.replace("immature B cell", "(3) immature B")
#        obs = obs.replace("naive B cell", "(4) naive B")
#        mask = obs.cell_ontology_class.isin(cell_type_order)
#
#        cell_idx_a = np.where(mask & (obs.cell_ontology_class==wildcards["cell_type"]))[0]
#        cell_idx_b = np.where(mask & (obs.cell_ontology_class!=wildcards["cell_type"]))[0]
#
#        MIN_FEATURES = 50
#        diff_exp = run_differential_expression(adata_exp, cell_idx_a, cell_idx_b, MIN_FEATURES)
#        diff_exp.to_csv(output[0], '\t', index=False)
#        diff_spl_clusters, diff_spl_introns = run_differential_splicing(
#            adata_spl,
#            cell_idx_a,
#            cell_idx_b,
#            min_cells_per_cluster=MIN_FEATURES,
#            min_total_cells_per_intron=MIN_FEATURES,
#            n_jobs=threads,
#            do_recluster=False,
#        )
#        diff_spl_clusters.to_csv(output[1], '\t')
#        diff_spl_introns.to_csv(output[2], '\t')
#
#
#rule plot_marker_introns_dist_marrow_b:
#    input:
#        "output/quantification/introns-shared-acceptor/adata_annotated.h5ad",
#        expand('output/differential_splicing/marrow_b/{cell_type}/marker_introns.tsv', cell_type=cell_type_order),
#    output:
#        "output/differential_splicing/marrow_b/marker_introns_dist.svg",
#    run:
#        adata_spl = anndata.read_h5ad(input[0])
#        adata_spl.var["prev_id"] = adata_spl.var.index.values
#        adata_spl.var["id"] = adata_spl.var.chromosome.astype(str) + ":" + adata_spl.var.start.astype(str) + "-" + adata_spl.var.end.astype(str)
#        adata_spl.var = adata_spl.var.set_index("id")
#
#        adata_spl.obs = adata_spl.obs.replace("late pro-B cell", "(1) pro-B")
#        adata_spl.obs = adata_spl.obs.replace("precursor B cell", "(2) pre-B")
#        adata_spl.obs = adata_spl.obs.replace("immature B cell", "(3) immature B")
#        adata_spl.obs = adata_spl.obs.replace("naive B cell", "(4) naive B")
#        mask = adata_spl.obs.cell_ontology_class.isin(cell_type_order)
#        #adata_spl = adata_spl[mask]
#        adata_spl = adata_spl[mask].copy()
#
#        all_marker_introns = []
#        for input_path in input[1:]:
#            marker_introns = pd.read_csv(input_path, "\t", header=None).values.astype(str).ravel().tolist()[:5]
#            all_marker_introns += marker_introns
#        print(all_marker_introns)
#        print(len(all_marker_introns))
#        all_marker_introns = pd.unique(all_marker_introns)
#        print(len(all_marker_introns))
#        adata_spl.X = group_normalize(adata_spl.X.toarray(), adata_spl.var.cluster.values, smooth=False)
#        adata_spl = adata_spl[:, all_marker_introns]
#        for cell_type in cell_type_order:
#            print(cell_type)
#            for intron in all_marker_introns:
#                idx_cells = np.where(adata_spl.obs.cell_ontology_class==cell_type)[0]
#                n_defined = (~np.isnan(adata_spl[idx_cells, intron].X)).sum()
#                if n_defined < 10:
#                    adata_spl[idx_cells, intron].X = np.nan
#
#        gene_name = pd.read_csv("output/gene_name.txt", "\t", index_col=0)
#        adata_spl.var = adata_spl.var.merge(gene_name, how="left", left_on="gene_id", right_index=True)
#        #adata_spl.var.loc[:, "id"] = adata_spl.var.gene_name.astype(str) + "_" + adata_spl.var.index
#        adata_spl.var.loc[:, "id"] = adata_spl.var.gene_name.astype(str) + "_" + adata_spl.var.prev_id.astype(str)
#        adata_spl.var = adata_spl.var.set_index("id")
#
#        marker_introns = adata_spl.var.index.values
#        print("len(marker_introns): ", len(marker_introns))
#
#        obs = adata_spl.obs
#        obs.loc[:, marker_introns] = adata_spl.X
#        obs["sample_id"] = obs.index.values
#        obs["Cell type"] = obs.cell_ontology_class
#        obs = obs.melt(id_vars=["sample_id", "Cell type"], value_vars=marker_introns, var_name="Intron", value_name="PSI")
#
#        g = sns.FacetGrid(
#            obs,
#            col="Cell type",
#            col_order=cell_type_order,
#            hue="Cell type",
#            row="Intron",
#            palette="tab10",
#            sharex=False,
#            sharey=True,
#            height=1.5,
#            aspect=1,
#            margin_titles=True,
#        )
#        eps = 1e-4
#        #n_bins = 10
#        n_bins = 5
#        g.map_dataframe(
#            sns.histplot,
#            y="PSI",
#            bins=np.linspace(0-eps, 1+eps, n_bins+1),
#            stat="probability",
#        )
#        g = g.map(lambda y, **kw: plt.axhline(y.mean(), color=kw["color"], ls="--"), 'PSI')
#
#        g.fig.subplots_adjust(wspace=0.1, hspace=0.12)
#        g.set_titles(col_template="{col_name}", row_template="{row_name}")
#        g.set_ylabels("PSI")
#        g.set_xlabels("")
#        g.set(xticks=[])
#        g.set(xlim=(0, 1), ylim=(0, 1))
#        #sns.despine(bottom=True)
#        sns.despine()
#        g.savefig(output[0], bbox_inches="tight")
#
#
#rule plot_marker_introns_trajectory_marrow_b:
#    input:
#        "output/quantification/gene-expression/adata_annotated.h5ad",
#        "output/quantification/introns-shared-acceptor/adata_annotated.h5ad",
#        expand('output/differential_splicing/marrow_b/{cell_type}/marker_introns.tsv', cell_type=cell_type_order),
#    output:
#        "output/differential_splicing/marrow_b/marker_introns_trajectory_spl.svg",
#    run:
#        adata_exp = anndata.read_h5ad(input[0])
#
#        adata_spl = anndata.read_h5ad(input[1])
#        adata_spl.var["prev_id"] = adata_spl.var.index.values
#        adata_spl.var["id"] = adata_spl.var.chromosome.astype(str) + ":" + adata_spl.var.start.astype(str) + "-" + adata_spl.var.end.astype(str)
#        adata_spl.var = adata_spl.var.set_index("id")
#
#        adata_spl.obs = adata_spl.obs.replace("late pro-B cell", "(1)")
#        adata_spl.obs = adata_spl.obs.replace("precursor B cell", "(2)")
#        adata_spl.obs = adata_spl.obs.replace("immature B cell", "(3)")
#        adata_spl.obs = adata_spl.obs.replace("naive B cell", "(4)")
#        new_cell_type_order = ["(1)", "(2)", "(3)", "(4)"]
#        mask = adata_spl.obs.cell_ontology_class.isin(new_cell_type_order)
#        #adata_spl = adata_spl[mask]
#
#        adata_exp = adata_exp[mask].copy()
#        adata_spl = adata_spl[mask].copy()
#
#        sc.pp.normalize_total(adata_exp, target_sum=1e4)
#        sc.pp.log1p(adata_exp)
#        #X = adata.X.toarray()
#
#        all_marker_introns = []
#        i = 0
#        for input_path in input[2:]:
#            n_examples = [3, 3, 4, 5]
#            marker_introns = pd.read_csv(input_path, "\t").head(n_examples[i])
#            marker_introns["group"] = i
#            all_marker_introns.append(marker_introns)
#            if i == 3:
#                marker_introns = pd.read_csv(input_path, "\t")
#                marker_introns = marker_introns[marker_introns.marker_intron=="chr6:99260420-99266347"]
#                marker_introns["group"] = i
#                all_marker_introns.append(marker_introns)
#            i += 1
#        marker_introns = pd.concat(all_marker_introns, ignore_index=True)
#        print(marker_introns.group.value_counts())
#        marker_introns = marker_introns.drop_duplicates(["gene_id"])
#        marker_introns = marker_introns.iloc[[0, 3, 6, 9, 1, 4, 7, 10, 2, 5, 8, 11]]
#        print(marker_introns.group.value_counts())
#
#        gene_ids = marker_introns.gene_id.values
#        gene_names = marker_introns.gene_name.values
#        adata_exp = adata_exp[:, gene_ids]
#        adata_exp.X = adata_exp.X.toarray()
#
#        introns = marker_introns.marker_intron.values
#        adata_spl.X = group_normalize(adata_spl.X.toarray(), adata_spl.var.cluster.values, smooth=False)
#        adata_spl = adata_spl[:, introns]
#
#        for cell_type in new_cell_type_order:
#            print(cell_type)
#            for intron in introns:
#                idx_cells = np.where(adata_spl.obs.cell_ontology_class==cell_type)[0]
#                n_defined = (~np.isnan(adata_spl[idx_cells, intron].X)).sum()
#                if n_defined < 3:
#                    print("here")
#                    raise Exception("debug")
#                    adata_spl[idx_cells, intron].X = np.nan
#
#        gene_name = pd.read_csv("output/gene_name.txt", "\t", index_col=0)
#        adata_spl.var = adata_spl.var.merge(gene_name, how="left", left_on="gene_id", right_index=True)
#        #adata_spl.var.loc[:, "id"] = adata_spl.var.gene_name.astype(str) + "_" + adata_spl.var.index
#        adata_spl.var.loc[:, "id"] = adata_spl.var.gene_name.astype(str) + "_" + adata_spl.var.prev_id.astype(str)
#        adata_spl.var = adata_spl.var.set_index("id")
#        introns = adata_spl.var.index.values
#
#        obs = adata_spl.obs
#        #obs.loc[:, gene_names] = adata_exp.X
#        obs.loc[:, introns] = adata_spl.X
#        obs.loc[:, gene_names] = adata_exp.X.toarray()
#
#        obs["sample_id"] = obs.index.values
#        obs["Cell type"] = obs.cell_ontology_class
#        obs_melt = obs.melt(id_vars=["sample_id", "Cell type"], value_vars=introns, var_name="Intron", value_name="PSI")
#
#        color_exp = "C9"
#        color_spl = "C4"
#
#        obs_melt["foo"] = "foo"
#        g = sns.catplot(
#            data=obs_melt,
#            col="Intron",
#            col_order=introns,
#            col_wrap=4,
#            #row="Intron",
#            #row_order=introns,
#            palette=[color_spl],
#            sharex=True,
#            sharey=False,
#            #height=2.0,
#            height=1.7,
#            aspect=1.5,
#            #margin_titles=True,
#            kind="point",
#            ci=None,
#            #kind="box",
#            order=new_cell_type_order,
#            hue="foo",
#            x="Cell type",
#            y="PSI",
#            legend=False,
#        )
#        g.fig.subplots_adjust(hspace=0.3, wspace=0.7)
#
#        i = 0
#        for idx, marker_intron in marker_introns.iterrows():
#            ax = g.axes.flat[i]
#            i += 1
#            ax2 = ax.twinx()
#            mean_exp = obs.groupby("Cell type")[marker_intron.gene_name].mean().loc[new_cell_type_order].values
#            ax2.plot(ax.get_xticks(), mean_exp, color=color_exp, marker="o", linestyle="-", linewidth=3, markersize=8)
#            ax.yaxis.set_tick_params(labelsize=8)
#            ax2.yaxis.set_tick_params(labelsize=8)
#            ax.set_ylabel("Mean PSI", color=color_spl, labelpad=0.5)
#            ax2.set_ylabel("Mean expr.", color=color_exp, labelpad=0.5)
#
#        g.set_titles(col_template="{col_name}", row_template="{row_name}")
#        sns.despine(bottom=True, right=False)
#        g.savefig(output[0], bbox_inches="tight")
#
#
#rule compare_new_clusters_well:
#    input:
#        expand(
#            "output/dimensionality_reduction/all/{method}/latent.txt",
#            method=methods_compare_latent_all,
#        )
#    output:
#        directory("output/comparison/well/{tissue}-{cell_type}/"),
#    run:
#        obs = sample_info
#        cell_idx = np.where((obs.tissue==wildcards["tissue"])&(obs.cell_type==wildcards["cell_type"]))[0]
#        obs = obs.iloc[cell_idx].copy()
#        print(obs.shape)
#        latents = [np.loadtxt(input_path)[cell_idx] for input_path in input]
#
#        latent_exp = latents[0]
#        latent_spl = latents[1]
#
#        obs["cluster_spl"] = SpectralClustering(n_clusters=2, random_state=42, affinity="nearest_neighbors", n_neighbors=15).fit_predict(latent_spl)
#        print(obs.cluster_spl.value_counts())
#        obs["well_row"] = obs.index.str.split("_").str[0].str.slice(stop=1)
#        obs["well_col"] = obs.index.str.split("_").str[0].str.slice(start=1).astype(int)
#
#        latent_names = methods_compare_latent_all
#        labels_list = [obs.cell_ontology_class, obs.sex, obs["mouse.id"], obs.plate_id, obs.tissue, obs.cluster_spl, obs.well_row, obs.well_col]
#        label_names = ["Cell type", "Sex", "Individual", "Plate", "Tissue", "Cluster spl", "Well row", "Well column"]
#        projector = lambda: UMAP(min_dist=0.5, n_neighbors=15, random_state=42)
#        projector_name = "UMAP_15"
#        main_path = output[0]
#
#        if not os.path.exists(main_path):
#            os.makedirs(main_path)
#
#        path = main_path
#        plot_comparison(latents, latent_names, slice(None), labels_list, label_names, path, projector=projector, save=True)
#
#        obs = obs[obs.subtissue=="Hepatocytes"]
#        sns.countplot(
#            x="well_row", hue="cluster_spl", data=obs.sort_values(["well_row", "cluster_spl"]), palette="tab10",
#        )
#        plt.savefig(os.path.join(path, "countplot_well_row.pdf"), bbox_inches="tight")
#        plt.close()
#        sns.countplot(
#            x="well_col", hue="cluster_spl", data=obs.sort_values(["well_col", "cluster_spl"]), palette="tab10",
#        )
#        plt.savefig(os.path.join(path, "countplot_well_col.pdf"), bbox_inches="tight")
#
#
#tf_regulated = {
#    "Foxp1": [
#        "Rag1",
#        "Rag2",
#        "Pax5",
#        "Prdm1",
#        "Pou2f1",
#    ],
#    "Smarca4": [
#        "Myc",
#    ],
#}
#
#rule plot_marrow_b_tf_trajectory:
#    input:
#        "output/quantification/gene-expression/adata_annotated.h5ad",
#        "output/gene_name.txt",
#    output:
#        "output/differential_splicing/marrow_b/tf_{tf}_trajectory.svg",
#    run:
#        adata_exp = anndata.read_h5ad(input[0])
#        print("ENSMUSG00000061311" in adata_exp.var.index.values)
#        print(adata_exp.var.loc["ENSMUSG00000061311"])
#        gene_name = pd.read_csv(input[1], "\t", index_col=0)
#        adata_exp.var = adata_exp.var.merge(gene_name, how="left", left_index=True, right_index=True)
#        adata_exp.var = adata_exp.var.set_index("gene_name")
#        adata_exp.var_names_make_unique()
#        print(adata_exp.var)
#        print(adata_exp.var.loc["Rag1"])
#        print(adata_exp.var.loc["Rag2"])
#
#        adata_exp.obs = adata_exp.obs.replace("late pro-B cell", "(1)")
#        adata_exp.obs = adata_exp.obs.replace("precursor B cell", "(2)")
#        adata_exp.obs = adata_exp.obs.replace("immature B cell", "(3)")
#        adata_exp.obs = adata_exp.obs.replace("naive B cell", "(4)")
#        new_cell_type_order = ["(1)", "(2)", "(3)", "(4)"]
#        mask = adata_exp.obs.cell_ontology_class.isin(new_cell_type_order)
#
#        adata_exp = adata_exp[mask].copy()
#
#        sc.pp.normalize_total(adata_exp, target_sum=1e4)
#        sc.pp.log1p(adata_exp)
#
#        genes_to_plot = [wildcards["tf"]] + tf_regulated[wildcards["tf"]]
#        print(genes_to_plot)
#        print(adata_exp.var)
#        adata_exp = adata_exp[:, genes_to_plot]
#
#        obs = adata_exp.obs.copy()
#        print(genes_to_plot)
#        obs[genes_to_plot] = adata_exp.X.toarray()
#
#        obs["sample_id"] = obs.index.values
#        obs["Cell type"] = obs.cell_ontology_class
#        obs = obs.melt(id_vars=["sample_id", "Cell type"], value_vars=genes_to_plot, var_name="Gene", value_name="Expr.")
#        ax = sns.pointplot(
#            x="Cell type", y="Expr.", hue="Gene",
#            data=obs,
#            order=new_cell_type_order,
#        )
#        plt.savefig(output[0], bbox_inches="tight")


rule produce_features_dendrogram:
    input:
        "output/adata_cellxgene_for_dendrogram_True.h5ad",
    output:
        "output/dendrogram/{features}/features.tsv",
    run:
        # TODO: consider filtering min cells (would need to do that before)
        adata = anndata.read_h5ad(input[0])

        min_cells_per_cell_type = 30 #100
        adata.obs.cell_ontology_class = adata.obs.cell_ontology_class.astype(str)
        cell_type_counts = adata.obs.cell_ontology_class.value_counts()
        print(cell_type_counts)
        cell_types = cell_type_counts[cell_type_counts >= min_cells_per_cell_type].index.values
        print(cell_types)
        print(len(cell_types))
        print(adata.shape)
        adata = adata[adata.obs.cell_ontology_class.isin(cell_types)]
        print(adata.shape)

        adata.var["feature_type"] = "Expression"
        adata.var.index = adata.var.index.astype(str)
        adata.var.gene_name = adata.var.gene_name.astype(str)
        adata.var.loc[adata.var.index.str.contains("_chr"), "feature_type"] = "Splicing"
        adata.var.loc[adata.var.gene_name=="nan", "gene_name"] = adata.var[adata.var.gene_name=="nan"].index.values

        # obtained from tabula_muris github repo
        dissociation_gene_names = pd.read_csv("input/genes_affected_by_dissociation_unix.csv").Gene.values
        print(dissociation_gene_names)
        tf_gene_names = pd.read_csv("input/GO_term_summary_20171110_222852.csv").Symbol.unique()
        sf_gene_names = pd.read_csv("input/GO_term_summary_20171214_190641.csv").Symbol.unique()
        tf_sf_gene_names = pd.unique(np.concatenate([tf_gene_names, sf_gene_names]))

        adata = adata[:, ~(adata.var.gene_name.isin(dissociation_gene_names))]

        features = wildcards["features"]
        if features == "all_exp":
            adata = adata[:, adata.var.feature_type=="Expression"]
        elif features == "all_spl":
            adata = adata[:, adata.var.feature_type=="Splicing"]
        elif features == "tf_exp":
            adata = adata[:, (adata.var.feature_type=="Expression") & (adata.var.gene_name.isin(tf_gene_names))]
        elif features == "tf_spl":
            adata = adata[:, (adata.var.feature_type=="Splicing") & (adata.var.gene_name.isin(tf_gene_names))]
        elif features == "tf_exp_spl":
            adata = adata[:, (adata.var.gene_name.isin(tf_gene_names))]
        elif features == "sf_exp":
            adata = adata[:, (adata.var.feature_type=="Expression") & (adata.var.gene_name.isin(sf_gene_names))]
        elif features == "sf_spl":
            adata = adata[:, (adata.var.feature_type=="Splicing") & (adata.var.gene_name.isin(sf_gene_names))]
        elif features == "sf_exp_spl":
            adata = adata[:, (adata.var.gene_name.isin(sf_gene_names))]
        elif features == "tf_sf_exp":
            adata = adata[:, (adata.var.feature_type=="Expression") & (adata.var.gene_name.isin(tf_sf_gene_names))]
        elif features == "tf_sf_spl":
            adata = adata[:, (adata.var.feature_type=="Splicing") & (adata.var.gene_name.isin(tf_sf_gene_names))]
        elif features == "tf_sf_exp_spl":
            adata = adata[:, (adata.var.gene_name.isin(tf_sf_gene_names))]
        print(adata.shape)

        #adata.obs["tct"] = adata.obs.tissue.astype(str) + "_" + adata.obs.cell_ontology_class.astype(str)
        adata.obs = adata.obs.filter(items=["cell_ontology_class"])
        adata.obs[adata.var.index.values] = adata.X
        groupby = adata.obs.groupby("cell_ontology_class").mean()   # this is slow when using all genes. could use parallel version.
        print(groupby)
        groupby.to_csv(output[0], "\t")


rule get_dendrogram_entanglement:
    input:
        "output/dendrogram/{features1}/features.tsv",
        "output/dendrogram/{features2}/features.tsv",
    output:
        "output/dendrogram/{features1}-{scale1}-{features2}-{scale2}/entanglement.txt",
    shell:
        "Rscript compute_entanglement.R {input[0]} {wildcards.scale1} {input[1]} {wildcards.scale2} {output}"


rule cell_type_classification_variable_selection:
    input:
        "output/quantification/gene-expression/adata_annotated.h5ad",
        "output/quantification/introns-shared-acceptor/adata_annotated.h5ad",
        "output/gene_name.txt",
    output:
        "output/cell_type_classification/{tissue}/{cell_type}/variables.tsv",
    run:
        gene_name = pd.read_csv(input[2], "\t", index_col=0)
        adata_exp = anndata.read_h5ad(input[0])
        adata_exp.var["feature_type"] = "Expression"
        adata_exp = adata_exp[adata_exp.obs.tissue==wildcards["tissue"]]
        adata_exp.var = adata_exp.var.merge(gene_name, how="left", left_index=True, right_index=True)
        adata_exp.var["gene_id"] = adata_exp.var.index.values
        adata_exp.var = adata_exp.var.set_index("gene_name", drop=False)
        adata_exp.var_names_make_unique()
        adata_exp.obs.index = adata_exp.obs.index.astype(str)
        adata_spl = anndata.read_h5ad(input[1])
        adata_spl.var["feature_type"] = "Splicing"
        adata_spl = adata_spl[adata_spl.obs.tissue==wildcards["tissue"]]
        adata_spl = filter_min_cells_per_feature(adata_spl, 100)
        adata_spl.var = adata_spl.var.merge(gene_name, how="left", left_on="gene_id", right_index=True)
        adata_spl.var["id"] = adata_spl.var.gene_name + "_" + adata_spl.var.chromosome.astype(str) + ":" + adata_spl.var.start.astype(str) + "-" + adata_spl.var.end.astype(str)
        adata_spl.var = adata_spl.var.set_index("id", drop=False)
        adata_spl.obs.index = adata_spl.obs.index.astype(str)
        adata_spl.var.index = adata_spl.var.index.astype(str)
        assert((adata_exp.obs.index == adata_spl.obs.index).all())
        sc.pp.normalize_total(adata_exp, target_sum=1e4)
        sc.pp.log1p(adata_exp)
        sc.pp.filter_genes(adata_exp, min_cells=100)

        dissociation_gene_names = pd.read_csv("input/genes_affected_by_dissociation_unix.csv").Gene.values
        tf_gene_names = pd.read_csv("input/GO_term_summary_20171110_222852.csv").Symbol.unique()
        gene_names_to_use = list(set(tf_gene_names) - set(dissociation_gene_names))
        adata_exp = adata_exp[:, adata_exp.var.gene_name.isin(gene_names_to_use)]
        adata_spl = adata_spl[:, adata_spl.var.gene_name.isin(gene_names_to_use)]
        adata_spl = filter_singletons(adata_spl)

        adata_exp.X = adata_exp.X.toarray()
        adata_spl.X = group_normalize(adata_spl.X.toarray(), adata_spl.var.cluster.values, smooth=True)

        intron_clusters = adata_spl.var.cluster.values
        all_intron_clusters = np.unique(intron_clusters)
        first_indices_dict = {}
        not_first_indices = []
        for i, c in enumerate(intron_clusters):
            if c not in first_indices_dict:
                first_indices_dict[c] = i
            else:
                not_first_indices.append(i)
        first_indices = np.array([first_indices_dict[c] for c in all_intron_clusters])
        not_first_indices = np.array(not_first_indices)
        new_idx = adata_spl.var.index.values[not_first_indices]
        adata_spl = adata_spl[:, new_idx]

        print(adata_exp.shape, adata_spl.shape)
        print(adata_exp.X.shape, adata_spl.X.shape)
        print(type(adata_exp.X), type(adata_spl.X))

        X = np.hstack((adata_exp.X.toarray(), adata_spl.X))
        print(adata_exp.shape, adata_spl.shape, X.shape)
        obs = adata_exp.obs
        var = pd.concat([adata_exp.var, adata_spl.var])
        adata = anndata.AnnData(X=X, obs=obs, var=var)
        print(adata.var.feature_type.value_counts())
        #adata = adata[:, adata.var.feature_type=="Expression"]
        print(adata.var.feature_type.value_counts())

        y = (adata.obs.cell_type == wildcards["cell_type"]).values
        X = adata.X
        print(X.shape, y.shape)

        #estimator = LogisticRegression()
        #selector = RFECV(estimator, step=0.05, cv=5, verbose=1, n_jobs=32)
        #selector = selector.fit(X, Y)
        # support = selector.support_

        #estimator = LogisticRegressionCV(penalty="l1", n_jobs=32, solver="liblinear")
        #selector = SelectFromModel(estimator=estimator).fit(X, Y)
        #support = selector.get_support()
        #coeffs = selector.estimator_.coef_.ravel()
        #support = np.abs(coeffs) > 1e-5
        seed = 42

        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.33, random_state=seed, stratify=y,
        )
        #clf = LogisticRegression(random_state=seed, max_iter=10000)
        clf = LogisticRegressionCV(penalty="l1", n_jobs=32, solver="liblinear", random_state=seed)
        clf.fit(X_train, y_train)
        y_pred = clf.predict(X_test)
        y_proba = clf.predict_proba(X_test)
        accuracy, f1, roc_auc = accuracy_score(y_test, y_pred), f1_score(y_test, y_pred), roc_auc_score(y_test, y_proba[:, 1])
        print(accuracy, f1, roc_auc)

        #adata.var["support"] = support
        #print(adata.var[adata.var.support].feature_type.value_counts())
