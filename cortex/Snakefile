import csv
import gzip
import itertools
import json
import os
import re
from collections import Counter, defaultdict
from functools import reduce
from pathlib import Path
from shutil import copyfile

import anndata
import matplotlib
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import scanpy as sc
import scipy.sparse as sp_sparse
import seaborn as sns
from Bio.Seq import Seq
from scipy.stats import chi2_contingency, spearmanr
from sklearn.decomposition import NMF, PCA
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, f1_score, roc_auc_score
from sklearn.model_selection import train_test_split
from statsmodels.stats.multitest import multipletests
import umap.umap_ as umap
UMAP = umap.UMAP

from scquint.differential_splicing import run_differential_splicing
from scquint.dimensionality_reduction import run_pca
from scquint.utils import (filter_min_cells_per_cluster,
                            filter_min_cells_per_feature, filter_singletons,
                            group_normalize, relabel,
                            run_differential_expression)

matplotlib.use('pdf')

sns.set(style="white")
#sns.set_palette("muted")

flatten = lambda l: [item for sublist in l for item in sublist]

configfile: 'config.yaml'


genome_fasta_path = config["genome_fasta_path"]
full_gtf_path = config["gtf_path"]
chrom_sizes_path = config["chrom_sizes_path"]
encode_blacklist_path = config["encode_blacklist_path"]
sjdb_path = config["sjdb_path"]  # maybe should be created in this workflow
groupings = ["nontransitive", "transitive", "gene"]


genes_bam_merge = {
    "Slmap": {
        "region": ["chr14", 26410803, 26537837],
        "cell_types": ["Lamp5", "L5_IT"],
    },
    "Aspg": {
        "region": ["chr12", 112105842, 112128423],
        "cell_types": ["L6_CT", "L6_IT"],
    },
    "Anapc11": {
        "region": ["chr11", 120598421, 120608198],
        "cell_types": ["Vip", "L6_CT", "L5slash6_NP"],
    },
    "Rbfox1": {
        "region": ["chr16", 5661490, 7505109],
        "cell_types": ["L6b", "L6_CT", "L2slash3_IT", "Lamp5"],
    },
    "Nrxn1": {
        "region": ["chr17", 89990948, 91110697],
        "cell_types": ["Vip", "L6_IT"],
    },
    "Rida": {
        "region": ["chr15", 34483518, 34495265],
        "cell_types": ["Sst", "L6_IT"],
    },
    "Pgm2": {
        "region": ["chr5", 64092081, 64129179],
        "cell_types": ["Sst", "L6b"],
    },
}


sample_info = pd.read_csv("obs.txt.gz", "\t", index_col=0)
sample_info = sample_info.sample(frac=1, random_state=42)  # shuffling so there's no order
sample_ids = sample_info.index.values
sample_info["Cell type"] = sample_info.subclass_label
sample_info.loc[:, "subclass_label"] = sample_info.subclass_label.str.replace(" ", "_").str.replace("/", "slash")
subclass_labels = sample_info.subclass_label.unique()


slop_amount = 100
n_cells_per_cell_type_assembly = 84


motif1 = "AAGCAGTGGTATCAACGCAGAGT"
motif2 = "ACTTTTTTTTTTTTTTTTTTTTTTTTTTTTTT"
motif3 = "AAGCAGTGGTATCAACGCAGAGTACGGG"
motif1_rc = str(Seq(motif1).reverse_complement())
motif2_rc = str(Seq(motif2).reverse_complement())
motif3_rc = str(Seq(motif3).reverse_complement())


# excluding Sncg which has < 100 cells.
cell_type_order = ["L5 IT", "L2/3 IT", "L6 IT", "L6 CT", "L6b", "L5/6 NP", "Pvalb", "Sst", "Vip", "Lamp5"]

introns_to_plot = [
    "chr17:90597630-90620865",  # Nrxn1
    "chr16:5763912-6173605",  # Rbfox1
    "chr5:64095936-64096979",  # Pgm2
]

genes_to_plot = [
    "ENSMUSG00000024109",  # Nrxn1
    "ENSMUSG00000008658",  # Rbfox1
    "ENSMUSG00000029171",  # Pgm2
]


rule all:
    input:
        expand('output/diff_spl/subclass_label/{subclass_label}/splicing.significant.tsv', subclass_label=subclass_labels),
        "output/adata_cellxgene.h5ad",
        'output/diff_spl/null/cdf.pdf',
        "output/dimensionality_reduction/classification_score.svg",
        'output/diff_spl/subclass_label/marker_introns.svg',
        expand("output/plots/{gene}.svg", gene=genes_to_plot),
        expand("output/plots/{intron}.svg", intron=introns_to_plot),
        "output/comparison/shuffled/cell_type.pdf",
        "output/comparison/exp_spl/cell_type.svg",
        "output/diff_spl/subclass_label/merged_significant_all.svg",
        'output/L5_IT/summary.tsv',


rule download:
    output:
        "output/fastq_raw/{sample_id}_R1.fastq.gz",
        "output/fastq_raw/{sample_id}_R2.fastq.gz",
    shell:
        "wget http://data.nemoarchive.org/biccn/lab/zeng/transcriptome/scell/SMARTer/raw/MOp/{wildcards.sample_id}.fastq.tar -O - | tar -x -C output/fastq_raw"


rule trim_adapters:
    input:
        "output/fastq_raw/{sample_id}_R1.fastq.gz",
        "output/fastq_raw/{sample_id}_R2.fastq.gz",
    output:
        "output/fastq/{sample_id}_R1.fastq.gz",
        "output/fastq/{sample_id}_R2.fastq.gz",
    shell:
        "cutadapt -g {motif1} -g {motif2} -g {motif3} -a {motif1_rc} -a {motif2_rc} -a {motif3_rc} -G {motif1} -G {motif2} -G {motif3} -A {motif1_rc} -A {motif2_rc} -A {motif3_rc} -m30 -n 4 -o {output[0]} -p {output[1]} {input[0]} {input[1]}"


rule produce_fastq_paths:
    input:
        expand("output/fastq/{sample_id}_R{pair}.fastq.gz", sample_id=sample_ids, pair=[1, 2]),
    output:
        "output/fastq_paths.txt"
    run:
        df = pd.DataFrame(sample_ids, columns=["sample_id"])
        base_path = os.path.join(os.getcwd(), "output/fastq/")
        df["fastq_1"] = base_path + df.sample_id + "_R1.fastq.gz"
        df["fastq_2"] = base_path + df.sample_id + "_R2.fastq.gz"
        df.to_csv(output[0], "\t", index=False, header=False)


rule read_mapping:
    input:
        "output/fastq_paths.txt",
        full_gtf_path
    threads: workflow.cores
    priority: 100
    output:
        expand("output/mapping/mapping_second_pass/{sample_id}/Aligned.rmdup.out.bam", sample_id=sample_ids)
    shell:
        "python -m scquint.quantification.run read_mapping/Snakefile --cores {threads} -d output/mapping/ --config min_cells_per_intron=30 fastq_paths=../fastq_paths.txt fasta_path={genome_fasta_path} gtf_path={full_gtf_path} sjdb_overhang=49 seedSearchStartLmax=30"


rule process_encode_blacklist:
    input:
        encode_blacklist_path
    output:
        "output/encode_blacklist.bed"
    shell:
        "set +o pipefail; cut -f1-3 {input} | bedtools sort -i stdin | uniq > {output}"


rule filter_bam:
    input:
        "output/mapping/mapping_second_pass/{sample_id}/Aligned.rmdup.out.bam",
        "output/encode_blacklist.bed"
    output:
        protected("output/filtered_bams/{sample_id}.bam"),
    shell:
        "bedtools intersect -split -sorted -a {input[0]} -b {input[1]} -v > {output}"


rule make_bam_paths:
    input:
        expand("output/filtered_bams/{sample_id}.bam", sample_id=sample_ids)
    output:
        "output/bam_paths.txt",
    run:
        cwd = os.getcwd()
        pd.DataFrame(dict(sample_id=sample_ids, bam_path=[f"{cwd}/output/filtered_bams/{sample_id}.bam" for sample_id in sample_ids])).to_csv(output[0], "\t", index=False, header=False)


rule prepare_chromosomes_file:
    input:
        "output/interested.gtf",
    output:
        "output/chromosomes.txt"
    shell:
        "cut -f1 {input} | grep -v \# | grep -v GL | grep -v JH | sort | uniq > {output}"


rule gene_expression_quantification:
    input:
        "output/bam_paths.txt",
        full_gtf_path,
    threads: workflow.cores
    output:
        "output/quantification/gene-expression/adata.h5ad"
    shell:
        "python -m scquint.quantification.run genes/Snakefile --cores all -q -d output/quantification/gene-expression/ --config min_cells_per_gene=30 gtf_path={full_gtf_path} bam_paths=../../bam_paths.txt"


rule intron_quantification:
    input:
        "output/bam_paths.txt",
        "output/chromosomes.txt",
        full_gtf_path,
        sjdb_path,
        chrom_sizes_path
    threads: workflow.cores
    output:
        "output/quantification/introns/output/introns-shared-acceptor/adata.h5ad",
    shell:
        "python -m scquint.quantification.run introns/Snakefile --cores {threads} -d output/quantification/introns/ --config min_cells_per_intron=30 bam_paths=../../bam_paths.txt chromosomes_path=../../chromosomes.txt fasta_path={genome_fasta_path} gtf_path={full_gtf_path} chrom_sizes_path={chrom_sizes_path} sjdb_path={sjdb_path}"


rule extract_intron_quantification:
    input:
        "output/quantification/introns/output/introns-{grouping}/adata.h5ad"
    output:
        "output/quantification/introns-{grouping}/adata.h5ad"
    shell:
        "cp {input} {output}"


rule add_metadata:
    input:
        "output/quantification/{quantification}/adata.h5ad",
    output:
        "output/quantification/{quantification}/adata_annotated.h5ad",
    run:
        adata = anndata.read_h5ad(input[0])
        print(adata.obs)
        adata.obs = sample_info.loc[adata.obs.index.values]
        print(adata.obs)
        adata.write(output[0], compression="gzip")


rule filter_bam_to_region:
    input:
        "output/filtered_bams/{sample_id}.bam"
    output:
        temp("output/bam_regions/{gene}/{sample_id}.bam")
    run:
        chromosome, start, end = genes_bam_merge[wildcards["gene"]]["region"]
        shell(f"bamtools filter -region {chromosome}:{start}..{end} -in {input} -out {output}")


rule make_bam_paths_gene:
    input:
        lambda wildcards: expand(f"output/bam_regions/{wildcards['gene']}/{{sample_id}}.bam", sample_id=sample_ids[sample_info.subclass_label==wildcards["cell_type"]])
    output:
        "output/bam_paths-{gene}-{cell_type}.txt"
    run:
        pd.DataFrame(input).to_csv(output[0], "\t", index=False, header=False)


rule merge_bams:
    input:
        "output/bam_paths-{gene}-{cell_type}.txt",
        lambda wildcards: expand(f"output/bam_regions/{wildcards['gene']}/{{sample_id}}.bam", sample_id=sample_ids[sample_info.subclass_label==wildcards["cell_type"]])
    output:
        "output/bam_regions/{gene}/{cell_type}/merged.bam"
    threads:
        workflow.cores
    priority: 10
    shell:
        "samtools merge --threads {threads} -b {input[0]} {output}"


rule make_bam_paths_subclass:
    input:
        expand("output/filtered_bams/{sample_id}.bam", sample_id=sample_ids)
    output:
        "output/bam_paths_{subclass}.txt",
    run:
        s_ids = sample_ids[np.where(sample_info.subclass_label==wildcards["subclass"])[0]]
        print(wildcards["subclass"], len(s_ids))
        cwd = os.getcwd()
        pd.DataFrame(dict(sample_id=s_ids, bam_path=[f"{cwd}/output/filtered_bams/{sample_id}.bam" for sample_id in s_ids])).to_csv(output[0], "\t", index=False, header=False)


rule make_coverage_track_bigwig:
    input:
        "output/bam_paths_{subclass}.txt",
    output:
        "output/coverage_track/{subclass}/coverage.bw",
    threads: workflow.cores // 4
    shell:
        "python -m scquint.quantification.run coverage_track/Snakefile --cores {threads} -d output/coverage_track/{wildcards.subclass}/ --config bam_paths=../../bam_paths_{wildcards.subclass}.txt chrom_sizes_path={chrom_sizes_path}"


rule differential_test_null:
    input:
        "output/quantification/gene-expression/adata_annotated.h5ad",
        "output/quantification/introns-shared-acceptor/adata_annotated.h5ad",
    output:
        'output/diff_spl/null/expression.csv',
        'output/diff_spl/null/splicing.clusters.csv',
        'output/diff_spl/null/splicing.introns.csv',
    threads: workflow.cores
    run:
        adata_exp = anndata.read_h5ad(input[0])
        adata_exp.obs.index = adata_exp.obs.index.astype(str)
        adata_spl = anndata.read_h5ad(input[1])
        adata_spl.obs.index = adata_spl.obs.index.astype(str)
        adata_spl.var.index = adata_spl.var.index.astype(str)
        assert((adata_exp.obs.index == adata_spl.obs.index).all())
        obs = adata_exp.obs
        print("threads: ", threads)
        np.random.seed(100)
        cell_idx = np.arange(len(obs))
        cell_idx_perm = np.random.permutation(cell_idx)
        cell_idx_a = cell_idx_perm[:len(cell_idx)//2]
        cell_idx_b = cell_idx_perm[len(cell_idx)//2:]
        #cell_idx_a = cell_idx_a[:1000]
        #cell_idx_b = cell_idx_b[:1000]
        diff_exp = run_differential_expression(adata_exp, cell_idx_a, cell_idx_b, config["min_total_cells_per_gene"])
        print(diff_exp)
        diff_exp.to_csv(output[0], '\t', index=False)
        diff_spl_clusters, diff_spl_introns = run_differential_splicing(
            adata_spl,
            cell_idx_a,
            cell_idx_b,
            min_cells_per_cluster=config["min_cells_per_cluster"],
            min_total_cells_per_intron=config["min_total_cells_per_intron"],
            n_jobs=threads,
        )
        diff_spl_clusters.to_csv(output[1], '\t')
        diff_spl_introns.to_csv(output[2], '\t')


rule plot_dist_under_null:
    input:
        'output/diff_spl/null/splicing.clusters.csv',
    output:
        'output/diff_spl/null/cdf.pdf',
    run:
        df = pd.read_csv(input[0], "\t")
        plt.plot([0, 1], [0, 1], color="gray", linestyle="--")
        ax = plt.gca()
        sns.ecdfplot(df.p_value, ax=ax)
        plt.xlabel("p-value")
        plt.ylabel("cdf")
        plt.xlim([0, 1])
        plt.ylim([0, 1])
        plt.gca().set_aspect('equal', adjustable='box')
        plt.tight_layout()
        plt.draw()
        plt.savefig(output[0], bbox_inches='tight')


rule differential_test_subclass:
    input:
        "output/quantification/gene-expression/adata_annotated.h5ad",
        "output/quantification/introns-shared-acceptor/adata_annotated.h5ad",
    output:
        'output/diff_spl/subclass_label/{subclass_label}/expression.csv',
        'output/diff_spl/subclass_label/{subclass_label}/splicing.clusters.csv',
        'output/diff_spl/subclass_label/{subclass_label}/splicing.introns.csv',
    threads: workflow.cores // 4
    run:
        adata_exp = anndata.read_h5ad(input[0])
        adata_exp.obs.index = adata_exp.obs.index.astype(str)
        adata_spl = anndata.read_h5ad(input[1])
        adata_spl.obs.index = adata_spl.obs.index.astype(str)
        adata_spl.var.index = adata_spl.var.index.astype(str)
        assert((adata_exp.obs.index == adata_spl.obs.index).all())
        obs = adata_exp.obs

        MIN_FEATURES = 50
        cell_idx_a = np.where((obs.subclass_label==wildcards["subclass_label"]))[0]
        cell_idx_b = np.where((obs.subclass_label!=wildcards["subclass_label"]))[0]
        diff_exp = run_differential_expression(adata_exp, cell_idx_a, cell_idx_b, MIN_FEATURES)
        diff_exp.to_csv(output[0], '\t', index=False)
        diff_spl_clusters, diff_spl_introns = run_differential_splicing(
            adata_spl,
            cell_idx_a,
            cell_idx_b,
            min_cells_per_cluster=MIN_FEATURES,
            min_total_cells_per_intron=MIN_FEATURES,
            n_jobs=threads,
        )
        diff_spl_clusters.to_csv(output[1], '\t')
        diff_spl_introns.to_csv(output[2], '\t')


rule extract_gene_cds:
    input:
        full_gtf_path
    output:
        "output/gene_cds.txt"
    run:
        df = pd.read_csv(
            input[0], '\t', header=None, comment="#",
            names=['chromosome', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attribute'],
           )
        print(df.shape)
        df = df[df.feature=="CDS"]
        print(df.shape)
        df['gene_id'] = df.attribute.str.extract(r'gene_id "([^;]*)";')
        res = df.groupby("gene_id").agg({"chromosome": "first", "start": "min", "end": "max", "strand": "first"})
        print(res)
        res.to_csv(output[0], "\t")


rule extract_gene_name:
    input:
        full_gtf_path
    output:
        "output/gene_name.txt"
    run:
        df = pd.read_csv(
            input[0], '\t', header=None, comment="#",
            names=['chromosome', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attribute'],
           )
        print(df.shape)
        df = df[df.feature=="gene"]
        print(df.shape)
        df['gene_id'] = df.attribute.str.extract(r'gene_id "([^;]*)";')
        df['gene_name'] = df.attribute.str.extract(r'gene_name "([^;]*)";')
        res = df.groupby("gene_id").gene_name.first()
        print(res)
        res.to_csv(output[0], "\t")


rule filter_diff_spl_significant:
    input:
        'output/diff_spl/subclass_label/{subclass_label}/expression.csv',
        'output/diff_spl/subclass_label/{subclass_label}/splicing.clusters.csv',
        'output/diff_spl/subclass_label/{subclass_label}/splicing.introns.csv',
        "output/gene_cds.txt",
        "output/gene_name.txt",
    output:
        'output/diff_spl/subclass_label/{subclass_label}/splicing.significant.tsv',
    run:
        diff_exp = pd.read_csv(input[0], "\t", index_col=0)
        diff_spl_cluster = pd.read_csv(input[1], "\t", index_col=0)
        diff_spl_intron = pd.read_csv(input[2], "\t", index_col=0)
        gene_cds = pd.read_csv(input[3], "\t", index_col=0)
        gene_name = pd.read_csv(input[4], "\t", index_col=0)

        assert(set(diff_spl_cluster.index.values) == set(diff_spl_intron.cluster.unique()))

        print(diff_spl_cluster.shape)
        diff_spl_cluster = diff_spl_cluster[
            ((diff_spl_cluster.p_value_adj <= config["fdr"]) &
             (diff_spl_cluster.max_abs_delta_psi >= config["min_abs_delta_psi"]))
        ]
        print(diff_spl_cluster.shape)
        diff_spl_cluster = diff_spl_cluster.merge(gene_name, how="left", left_on="gene_id", right_index=True)
        print(diff_spl_cluster.shape)
        def max_abs_lfc_psi_unannotated(row_cluster):
            introns = diff_spl_intron[diff_spl_intron.cluster==row_cluster.name]
            return (introns.abs_lfc_psi * (~introns.annotated).astype(int)).max()
        diff_spl_cluster["max_abs_lfc_psi_unannotated"] = diff_spl_cluster.apply(max_abs_lfc_psi_unannotated, axis=1)
        #diff_spl_cluster["Annotated"] = diff_spl_cluster.max_abs_lfc_psi_unannotated < config["min_abs_lfc"]
        def max_abs_delta_psi_unannotated(row_cluster):
            introns = diff_spl_intron[diff_spl_intron.cluster==row_cluster.name]
            return (introns.abs_delta_psi * (~introns.annotated).astype(int)).max()
        diff_spl_cluster["max_abs_delta_psi_unannotated"] = diff_spl_cluster.apply(max_abs_delta_psi_unannotated, axis=1)
        diff_spl_cluster["Annotated"] = diff_spl_cluster.max_abs_delta_psi_unannotated < config["min_abs_delta_psi"]

        coordinates = diff_spl_intron.groupby("cluster").agg({"chromosome": "first", "start": "unique", "end": "unique"})
        diff_spl_cluster = diff_spl_cluster.merge(coordinates, how="left", left_index=True, right_index=True)

        print(diff_spl_cluster.Annotated.value_counts())
        def get_diff_exp_rank(row_cluster):
            try:
                return diff_exp.loc[row_cluster.gene_id].ranking
            except KeyError:
                return np.nan
        diff_spl_cluster["diff_exp_rank"] = diff_spl_cluster.apply(get_diff_exp_rank, axis=1)
        def check_region(row_cluster):
            try:
                cds = gene_cds.loc[row_cluster.gene_id]
            except KeyError:
                return "Non-coding"
            introns = diff_spl_intron[diff_spl_intron.cluster==row_cluster.name]
            cluster_start = introns.start.min()
            cluster_end = introns.end.max()
            if cds.strand == "+":
                if cluster_start < cds.start:
                    return "5' UTR"
                if cluster_start < cds.end:
                    return "CDS"
                return "3' UTR"
            elif cds.strand == "-":
                if cluster_start < cds.start:
                    return "3' UTR"
                if cluster_start < cds.end:
                    return "CDS"
                return "5' UTR"
            else:
                raise Exception("strand not implemented")
        diff_spl_cluster["Region"] = diff_spl_cluster.apply(check_region, axis=1)
        print(diff_spl_cluster.Region.value_counts())
        diff_spl_cluster.max_abs_delta_psi = diff_spl_cluster.max_abs_delta_psi.round(decimals=3)

        #def signif(x, p):
        #    x = np.asarray(x)
        #    x_positive = np.where(np.isfinite(x) & (x != 0), np.abs(x), 10**(p-1))
        #    mags = 10 ** (p - 1 - np.floor(np.log10(x_positive)))
        #    return np.round(x * mags) / mags

        #diff_spl_cluster.p_value = signif(diff_spl_cluster.p_value.values, 3)
        #diff_spl_cluster.p_value_adj = signif(diff_spl_cluster.p_value_adj.values, 3)

        diff_spl_cluster.to_csv(
            output[0], "\t",
            columns=["gene_id", "gene_name", "p_value_adj", "max_abs_delta_psi", "Annotated", "Region", "diff_exp_rank", "p_value", "chromosome", "start", "end"],
        )


rule merge_significant:
    input:
        expand('output/diff_spl/subclass_label/{subclass_label}/splicing.significant.tsv', subclass_label=subclass_labels),
    output:
        "output/diff_spl/subclass_label/merged_significant.txt",
    run:
        dfs = []
        for subclass_label, input_path in zip(subclass_labels, input):
            df = pd.read_csv(input_path, "\t")
            df["Cell type"] = subclass_label.replace("_", " ").replace("slash", "/")
            dfs.append(df)
        df = pd.concat(dfs, ignore_index=True)
        df = df.sort_values("p_value_adj")
        df.to_csv(output[0], "\t", index=False)


rule plot_significant:
    input:
        "output/diff_spl/subclass_label/merged_significant.txt",
    output:
        "output/diff_spl/subclass_label/merged_significant_all.svg",
        "output/diff_spl/subclass_label/merged_significant_5p.svg",
        "output/diff_spl/subclass_label/merged_significant_cds.svg",
        "output/diff_spl/subclass_label/merged_significant_3p.svg",
        "output/diff_spl/subclass_label/merged_significant_aggregate.svg",
    run:
        df_all = pd.read_csv(input[0], "\t")
        df_all = df_all[df_all["Cell type"].isin(cell_type_order)]
        df_all["Type"] = df_all.Annotated
        df_all.Type = df_all.Type.replace(True, "Annotated").replace(False, "Novel")
        df_all.Region = df_all.Region.replace("Non-coding", "Non-coding RNA")

        def plot_counts(df, output_path):
            df_plot = df.groupby(["Type", "Cell type"]).size().reset_index().pivot(columns='Type', index='Cell type', values=0)
            print(df_plot)
            df_plot = df_plot.loc[cell_type_order]
            print(df_plot)
            g = df_plot.plot(kind='bar', stacked=True)
            g.set_xticklabels(g.get_xticklabels(), rotation=45, horizontalalignment='right')
            #g.set(xlabel='Cell type', ylabel='Diff. spl. events')
            g.set(xlabel="", ylabel='Diff. spl. events')
            sns.despine(left=True)
            plt.legend(loc='upper right')
            plt.savefig(output_path, bbox_inches='tight')
            plt.close()
        plot_counts(df_all, output[0])
        plot_counts(df_all[df_all.Region=="5' UTR"], output[1])
        plot_counts(df_all[df_all.Region=="CDS"], output[2])
        plot_counts(df_all[df_all.Region=="3' UTR"], output[3])
        df = df_all
        df_plot = df.groupby(["Type", "Region"]).size().reset_index().pivot(columns='Type', index='Region', values=0).loc[["5' UTR", "CDS", "3' UTR", "Non-coding RNA"]]
        g = df_plot.plot(kind='bar', stacked=True)
        g.set_xticklabels(g.get_xticklabels(), rotation=45, horizontalalignment='right')
        #g.set(xlabel='Region', ylabel='Diff. spl. events')
        g.set(xlabel="", ylabel='Diff. spl. events')
        sns.despine(left=True)
        plt.legend(loc='upper right')
        plt.savefig(output[4], bbox_inches='tight')


rule dimensionality_reduction_expression:
    input:
        "output/quantification/gene-expression/adata_annotated.h5ad",
    output:
        "output/dimensionality_reduction/expression/PCA/latent.txt",
    run:
        adata = anndata.read_h5ad(input[0])
        sc.pp.normalize_total(adata, target_sum=1e4)
        sc.pp.log1p(adata)
        X = adata.X.toarray()
        latent = PCA(n_components=20).fit_transform(X)
        np.savetxt(output[0], latent)


rule dimensionality_reduction_splicing_pca:
    input:
        "output/quantification/introns-shared-acceptor/adata_annotated.h5ad",
    output:
        "output/dimensionality_reduction/splicing/PCA/latent.txt",
    run:
        adata = anndata.read_h5ad(input[0])
        latent = run_pca(adata, 20)
        np.savetxt(output[0], latent)


rule dimensionality_reduction_splicing_shuffled_pca:
    input:
        "output/quantification/introns-shared-acceptor-shuffled/adata_annotated.h5ad",
    output:
        "output/dimensionality_reduction/splicing-shuffled/PCA/latent.txt",
    run:
        adata = anndata.read_h5ad(input[0])
        latent = run_pca(adata, 20)
        np.savetxt(output[0], latent)


rule compare_latent_exp_spl:
    input:
        "output/dimensionality_reduction/expression/PCA/latent.txt",
        "output/dimensionality_reduction/splicing/PCA/latent.txt",
    output:
        "output/comparison/exp_spl/cell_type.svg",
    run:
        dfs = []
        for name, input_path in zip(["Expression", "Splicing"], input):
            df = sample_info.copy()
            latent = np.loadtxt(input_path)
            #proj = UMAP(min_dist=1.0, n_neighbors=15, random_state=42).fit_transform(latent)
            proj = UMAP(min_dist=0.5, n_neighbors=15, random_state=42).fit_transform(latent)
            df["UMAP 1"] = proj[:, 0]
            df["UMAP 2"] = proj[:, 1]
            df["Quantification"] = name
            dfs.append(df)
        df = pd.concat(dfs)
        df = df[df["Cell type"].isin(cell_type_order)]
        g = sns.relplot(
            data=df,
            x="UMAP 1",
            y="UMAP 2",
            hue="Cell type",
            hue_order=cell_type_order,
            col="Quantification",
            col_order=["Expression", "Splicing"],
            kind="scatter",
            facet_kws={'sharey': False, 'sharex': False},
            height=3,
            palette="tab10",
            edgecolor="none",
            s=4,
        )
        g.set_titles(col_template="{col_name} latent space")
        g.fig.subplots_adjust(wspace=0.1)
        for ax in g.axes.flat:
            ax.set_xticks([])
            ax.set_yticks([])
            ax.set_ylabel("UMAP 2")
        sns.despine()
        plt.savefig(output[0], bbox_inches='tight')


rule shuffle_counts:
    input:
        "output/quantification/{quantification}/adata_annotated.h5ad",
    output:
        "output/quantification/{quantification}-shuffled/adata_annotated.h5ad",
    run:
        adata = anndata.read_h5ad(input[0])
        adata.X = adata.X.toarray()
        clusters = adata.var.cluster.values
        print(clusters.max())

        cluster_introns_idx = defaultdict(list)
        for i, cluster in enumerate(clusters):
            cluster_introns_idx[cluster].append(i)

        for c in range(clusters.max()+1):
            if c % 1000 == 0: print(c)
            idx = cluster_introns_idx[c]
            p = len(idx)
            # probs = np.full(p, 1/p)
            probs = np.random.dirichlet(np.ones(p))
            sums = adata.X[:,idx].sum(axis=1)
            for i in range(adata.X.shape[0]):
                adata.X[i,idx] = np.random.multinomial(sums[i], probs)

        adata.X = sp_sparse.csr_matrix(adata.X)
        adata.write(output[0], compression="gzip")


rule compare_latent_shuffled:
    input:
        "output/dimensionality_reduction/splicing/PCA/latent.txt",
        "output/dimensionality_reduction/splicing-shuffled/PCA/latent.txt",
    output:
        "output/comparison/shuffled/cell_type.pdf",
    run:
        dfs = []
        for name, input_path in zip(["Splicing", "Splicing (shuffled)"], input):
            df = sample_info.copy()
            latent = np.loadtxt(input_path)
            proj = UMAP(min_dist=0.5, n_neighbors=15, random_state=42).fit_transform(latent)
            df["UMAP 1"] = proj[:, 0]
            df["UMAP 2"] = proj[:, 1]
            df["Quantification"] = name
            dfs.append(df)
        df = pd.concat(dfs)
        df = df[df["Cell type"].isin(cell_type_order)]
        g = sns.relplot(
            data=df,
            x="UMAP 1",
            y="UMAP 2",
            hue="Cell type",
            hue_order=cell_type_order,
            col="Quantification",
            col_order=["Splicing", "Splicing (shuffled)"],
            kind="scatter",
            facet_kws={'sharey': False, 'sharex': False},
            height=3,
            palette="tab10",
            edgecolor="none",
            s=4,
        )
        g.set_titles(col_template="{col_name}")
        g.fig.subplots_adjust(wspace=0.1)
        for ax in g.axes.flat:
            ax.set_xticks([])
            ax.set_yticks([])
            ax.set_ylabel("UMAP 2")
        sns.despine()
        plt.savefig(output[0], bbox_inches='tight')


rule psi_plot:
    input:
        "output/quantification/introns-shared-acceptor/adata_annotated.h5ad",
    output:
        expand("output/plots/{intron}.svg", intron=introns_to_plot),
    run:
        adata = anndata.read_h5ad(input[0])
        print(adata.var.iloc[8066])
        print(adata.shape)
        adata.obs["Cell type"] = sample_info.subclass_label.str.replace("_", " ").str.replace("slash", "/")
        adata = adata[adata.obs["Cell type"].isin(cell_type_order)]
        print(adata.shape)
        X = group_normalize(adata.X.toarray(), adata.var.cluster.values, smooth=False)
        var = adata.var.copy()
        var["position"] = np.arange(len(var))
        var["id"] = var.chromosome.astype(str) + ":" + var.start.astype(str) + "-" + var.end.astype(str)
        var = var.set_index("id")
        for i, intron in enumerate(introns_to_plot):
            obs = adata.obs.copy()
            print("position: ", var.loc[intron].position)
            obs["PSI"] = X[:, var.loc[intron].position].ravel()
            print(obs.groupby("Cell type").PSI.mean())
            print(obs.PSI.isna().sum())

            g = sns.FacetGrid(
                obs,
                col="Cell type",
                col_order=cell_type_order,
                hue="Cell type",
                hue_order=cell_type_order,
                palette="tab10",
                sharex=False,
                sharey=True,
                #height=1.5,
                height=1.5,
                aspect=0.5,
            )
            eps = 1e-4
            g.map_dataframe(
                sns.histplot,
                y="PSI",
                bins=np.linspace(0-eps, 1+eps, 11),
                stat="probability",
            )
            g.fig.subplots_adjust(wspace=0)
            g.set_titles(col_template="{col_name}")
            g.set_ylabels("PSI")
            g.set(xticks=[])
            g.set(xlim=(0, 1), ylim=(0, 1))
            sns.despine(bottom=True)
            plt.savefig(output[i], bbox_inches='tight')


rule exp_plot:
    input:
        "output/quantification/gene-expression/adata_annotated.h5ad",
    output:
        expand("output/plots/{gene}.svg", gene=genes_to_plot),
    run:
        adata = anndata.read_h5ad(input[0])
        print(adata.shape)
        adata.obs["Cell type"] = sample_info.subclass_label.str.replace("_", " ").str.replace("slash", "/")
        adata = adata[adata.obs["Cell type"].isin(cell_type_order)]
        print(adata.shape)
        sc.pp.normalize_total(adata, target_sum=1e4)
        sc.pp.log1p(adata)
        for i, gene in enumerate(genes_to_plot):
            obs = adata.obs.copy()
            obs["log norm. expression"] = adata[:, gene].X.toarray().ravel()
            plt.figure(figsize=(3, 2))
            g = sns.violinplot(
                data=obs,
                x="Cell type",
                y="log norm. expression",
                order=cell_type_order,
                #hue="Cell type",
                #hue_order=cell_type_order,
                palette="tab10",
                cut=0.05,
                scale="width",
                width=0.75,
            )
            g.set(xlabel=None)
            sns.despine(bottom=True)
            plt.xticks(rotation=45)
            plt.savefig(output[i], bbox_inches='tight')
            plt.close()
            plt.clf()


rule diff_test_summary:
    input:
        'output/{anything}/expression.csv',
        'output/{anything}/splicing.clusters.csv',
    output:
        'output/{anything}/summary.tsv',
    run:
        df_exp = pd.read_csv(input[0], "\t")
        df_spl = pd.read_csv(input[1], "\t")
        n_genes_exp = ((df_exp.p_value_adj < config["fdr"]) & (df_exp.abs_lfc > config["min_abs_lfc"])).sum()
        n_genes_spl = len(df_spl[(df_spl.p_value_adj < config["fdr"]) & (df_spl.max_abs_delta_psi > config["min_abs_delta_psi"])].gene_id.unique())
        ratio = n_genes_spl / n_genes_exp
        intersection = len(list(set(df_exp.gene.unique()[:100]).intersection(set(df_spl.gene_id.unique()[:100]))))
        print(n_genes_exp, n_genes_spl, ratio, intersection)
        res = pd.DataFrame([[n_genes_exp, n_genes_spl, ratio, intersection]], columns=["n_genes_exp", "n_genes_spl", "ratio", "top100_intersection"])
        res.to_csv(output[0], "\t", index=False)



rule get_marker_introns:
    input:
        'output/{anything}/splicing.clusters.csv',
        'output/{anything}/splicing.introns.csv',
    output:
        'output/{anything}/marker_introns.tsv',
    run:
        groups = pd.read_csv(input[0], "\t")
        introns = pd.read_csv(input[1], "\t")
        introns["id"] = introns.chromosome.astype(str) + ":" + introns.start.astype(str) + "-" + introns.end.astype(str)
        introns = introns.set_index("id")
        groups = groups[(groups.p_value_adj < config["fdr"])].sort_values("max_abs_delta_psi", ascending=False).head(10)
        print(groups.max_abs_delta_psi)
        marker_introns = groups.cluster.apply(lambda x: introns[introns.cluster==x].delta_psi.idxmax())
        print(marker_introns)
        marker_introns.to_csv(output[0], index=False, header=False)


rule plot_marker_introns:
    input:
        "output/quantification/introns-shared-acceptor/adata_annotated.h5ad",
        expand('output/diff_spl/subclass_label/{subclass_label}/marker_introns.tsv', subclass_label=subclass_labels),
    output:
        'output/diff_spl/subclass_label/marker_introns.svg',
    run:
        adata_spl = anndata.read_h5ad(input[0])
        adata_spl.var["prev_id"] = adata_spl.var.index.values
        adata_spl.var["id"] = adata_spl.var.chromosome.astype(str) + ":" + adata_spl.var.start.astype(str) + "-" + adata_spl.var.end.astype(str)
        adata_spl.var = adata_spl.var.set_index("id")

        all_marker_introns = []
        for cell_type in cell_type_order:
            subclass_label = cell_type.replace(" ", "_").replace("/", "slash")
            marker_introns = pd.read_csv(f"output/diff_spl/subclass_label/{subclass_label}/marker_introns.tsv", "\t", header=None).values.astype(str).ravel().tolist()[:5]
            all_marker_introns += marker_introns
        print(all_marker_introns)
        print(len(all_marker_introns))
        all_marker_introns = pd.unique(all_marker_introns)
        print(len(all_marker_introns))
        adata_spl.X = group_normalize(adata_spl.X.toarray(), adata_spl.var.cluster.values, smooth=False)
        adata_spl.obs["Cell type"] = adata_spl.obs.subclass_label.str.replace("_", " ").str.replace("slash", "/")
        adata_spl = adata_spl[adata_spl.obs["Cell type"].isin(cell_type_order)]
        adata_spl = adata_spl[:, all_marker_introns]
        for cell_type in cell_type_order:
            print(cell_type)
            for intron in all_marker_introns:
                idx_cells = np.where(adata_spl.obs["Cell type"]==cell_type)[0]
                n_defined = (~np.isnan(adata_spl[idx_cells, intron].X)).sum()
                if n_defined < 10:
                    adata_spl[idx_cells, intron].X = np.nan
        gene_name = pd.read_csv("output/gene_name.txt", "\t", index_col=0)
        adata_spl.var = adata_spl.var.merge(gene_name, how="left", left_on="gene_id", right_index=True)
        #adata_spl.var.loc[:, "id"] = adata_spl.var.gene_name.astype(str) + "_" + adata_spl.var.index
        adata_spl.var.loc[:, "id"] = adata_spl.var.gene_name.astype(str) + "_" + adata_spl.var.prev_id.astype(str)
        adata_spl.var = adata_spl.var.set_index("id")

        g = sc.pl.matrixplot(
            adata_spl,
            adata_spl.var.index.values,
            groupby='Cell type',
            categories_order=cell_type_order,
            return_fig=True, vmin=0.0, vmax=1.0, cmap='bwr', swap_axes=True, colorbar_title="Mean PSI")
        plt.tight_layout()
        g.savefig(output[0], bbox_inches="tight")


def calculate_classification_metrics(latent, classes, idx, seed=None):
    latent = latent[idx]
    classes = classes[idx]
    all_classes = np.unique(classes)

    try:
        X_train, X_test, y_train, y_test = train_test_split(
            latent, classes, test_size=0.33, random_state=seed, stratify=classes
        )
    except:
        X_train, X_test, y_train, y_test = train_test_split(
            latent, classes, test_size=0.33, random_state=seed, stratify=None
        )
        print("not stratifying")

    clf = LogisticRegression(random_state=seed, max_iter=10000)
    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)
    y_proba = clf.predict_proba(X_test)
    return accuracy_score(y_test, y_pred), f1_score(y_test, y_pred), roc_auc_score(y_test, y_proba[:, 1])


rule get_classification_score:
    input:
        "output/dimensionality_reduction/expression/PCA/latent.txt",
        "output/dimensionality_reduction/splicing/PCA/latent.txt",
    output:
        "output/dimensionality_reduction/classification_score.tsv",
    run:
        latent_exp = np.loadtxt(input[0])
        latent_spl = np.loadtxt(input[1])

        idx = slice(None)
        results = []
        for cell_type in cell_type_order:
            print(cell_type)
            labels = sample_info["Cell type"] == cell_type
            for seed in range(30):
                results.append((cell_type, "Expression", seed, *calculate_classification_metrics(latent_exp, labels, idx, seed)))
                results.append((cell_type, "Splicing", seed, *calculate_classification_metrics(latent_spl, labels, idx, seed)))
        results = pd.DataFrame(results, columns=['Cell type', 'Latent space', 'seed', 'accuracy', 'F1 score', "AUC"])
        results.to_csv(output[0], "\t", index=False)


rule plot_classification_score:
    input:
        "output/dimensionality_reduction/classification_score.tsv",
    output:
        "output/dimensionality_reduction/classification_score.svg",
    run:
        df = pd.read_csv(input[0], "\t")
        g = sns.barplot(x="Cell type", y="AUC", hue="Latent space", order=cell_type_order, data=df, ci='sd', palette="Accent");
        g.set_xticklabels(g.get_xticklabels(), rotation=45,  horizontalalignment='right')
        g.set(xlabel="")
        sns.despine()
        #plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., title="latent space");
        plt.tight_layout()
        plt.savefig(output[0], bbox_inches="tight")


rule prepare_adata_for_cellxgene:
    input:
        "output/quantification/gene-expression/adata_annotated.h5ad",
        "output/quantification/introns-shared-acceptor/adata_annotated.h5ad",
        "output/gene_name.txt",
    output:
        "output/adata_cellxgene.h5ad",
    run:
        gene_name = pd.read_csv(input[2], "\t", index_col=0)
        adata_exp = anndata.read_h5ad(input[0])
        adata_exp.var = adata_exp.var.merge(gene_name, how="left", left_index=True, right_index=True)
        adata_exp.var["gene_id"] = adata_exp.var.index.values
        adata_exp.var = adata_exp.var.set_index("gene_name")
        adata_exp.var_names_make_unique()
        adata_exp.obs.index = adata_exp.obs.index.astype(str)
        adata_spl = anndata.read_h5ad(input[1])
        adata_spl.var = adata_spl.var.merge(gene_name, how="left", left_on="gene_id", right_index=True)
        adata_spl.var["id"] = adata_spl.var.gene_name + "_" + adata_spl.var.chromosome.astype(str) + ":" + adata_spl.var.start.astype(str) + "-" + adata_spl.var.end.astype(str)
        adata_spl.var = adata_spl.var.set_index("id", drop=False)
        adata_spl.obs.index = adata_spl.obs.index.astype(str)
        adata_spl.var.index = adata_spl.var.index.astype(str)
        assert((adata_exp.obs.index == adata_spl.obs.index).all())
        sc.pp.normalize_total(adata_exp, target_sum=1e4)
        sc.pp.log1p(adata_exp)
        adata_exp.X = adata_exp.X.toarray()
        adata_spl.X = group_normalize(adata_spl.X.toarray(), adata_spl.var.cluster.values, smooth=False)
        latent = PCA(n_components=40).fit_transform(adata_exp.X)
        proj = UMAP(min_dist=0.5, n_neighbors=15, random_state=42).fit_transform(latent)

        X = np.hstack((adata_exp.X, adata_spl.X))
        print(adata_exp.shape, adata_spl.shape, X.shape)
        obs = adata_exp.obs
        var = pd.concat([adata_exp.var, adata_spl.var])
        adata = anndata.AnnData(X=X, obs=obs, var=var)
        adata.obsm["X_umap"] = proj
        adata.write_h5ad(output[0], compression="gzip")
